{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 12 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 23:15:11.348118: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 23:15:11.537113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756595711.610807    3742 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756595711.631962    3742 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756595711.789299    3742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756595711.789521    3742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756595711.789526    3742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756595711.789528    3742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-30 23:15:11.812139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently training on seed: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "learning rate: 6.5e-03\n",
      "num_dense_nodes: 126\n",
      "dropout: 0.5566555292798582\n",
      "optimizer_type: Adam\n",
      "epochs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756021373.675338   25624 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756021409.052979   26350 service.cc:152] XLA service 0x7feb24004dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756021409.053017   26350 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-24 07:43:30.152468: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756021415.185634   26350 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "2025-08-24 07:43:43.477484: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:43:43.624276: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:43:43.969134: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:43:44.112496: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/52\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58:21\u001b[0m 69s/step - accuracy: 0.5000 - loss: 0.8106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756021445.810115   26350 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5236 - loss: 1.6312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 07:44:24.454916: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:44:24.600960: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:44:24.907499: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 07:44:25.049633: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 969ms/step - accuracy: 0.5205 - loss: 1.2978 - val_accuracy: 0.5000 - val_loss: 95877922291712.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5205 - loss: 0.9916 - val_accuracy: 0.5000 - val_loss: 24762564608.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.5024 - loss: 0.8201 - val_accuracy: 0.5000 - val_loss: 18897180.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5411 - loss: 0.7247 - val_accuracy: 0.5012 - val_loss: 85748.2500\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5157 - loss: 0.6846 - val_accuracy: 0.5085 - val_loss: 7172.6523\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5483 - loss: 0.6694 - val_accuracy: 0.5882 - val_loss: 6645.1138\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5423 - loss: 0.6671 - val_accuracy: 0.6679 - val_loss: 3534.1794\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5459 - loss: 0.7096 - val_accuracy: 0.7331 - val_loss: 494.5091\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5411 - loss: 0.6781 - val_accuracy: 0.7307 - val_loss: 81.2607\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5290 - loss: 0.6895 - val_accuracy: 0.6763 - val_loss: 11.0978\n",
      "\n",
      "Accuracy: 67.63%\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 193.0095\n",
      "Function value obtained: -0.6763\n",
      "Current minimum: -0.6763\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "learning rate: 3.3e-06\n",
      "num_dense_nodes: 133\n",
      "dropout: 0.5045491789129737\n",
      "optimizer_type: SGD\n",
      "epochs: 14\n",
      "Epoch 1/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 689ms/step - accuracy: 0.5072 - loss: 0.7321 - val_accuracy: 0.4988 - val_loss: 0.7185\n",
      "Epoch 2/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.4988 - loss: 0.7472 - val_accuracy: 0.5205 - val_loss: 0.7081\n",
      "Epoch 3/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.5145 - loss: 0.7293 - val_accuracy: 0.5447 - val_loss: 0.6924\n",
      "Epoch 4/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5072 - loss: 0.7136 - val_accuracy: 0.5628 - val_loss: 0.6843\n",
      "Epoch 5/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5350 - loss: 0.7123 - val_accuracy: 0.5749 - val_loss: 0.6837\n",
      "Epoch 6/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5399 - loss: 0.7181 - val_accuracy: 0.5737 - val_loss: 0.6839\n",
      "Epoch 7/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5507 - loss: 0.7107 - val_accuracy: 0.5773 - val_loss: 0.6803\n",
      "Epoch 8/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5447 - loss: 0.7085 - val_accuracy: 0.5857 - val_loss: 0.6762\n",
      "Epoch 9/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.5688 - loss: 0.6860 - val_accuracy: 0.5906 - val_loss: 0.6722\n",
      "Epoch 10/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5507 - loss: 0.7005 - val_accuracy: 0.5978 - val_loss: 0.6676\n",
      "Epoch 11/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 0.5749 - loss: 0.6866 - val_accuracy: 0.6027 - val_loss: 0.6634\n",
      "Epoch 12/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5785 - loss: 0.6748 - val_accuracy: 0.6099 - val_loss: 0.6590\n",
      "Epoch 13/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5725 - loss: 0.6903 - val_accuracy: 0.6123 - val_loss: 0.6548\n",
      "Epoch 14/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.5749 - loss: 0.6697 - val_accuracy: 0.6304 - val_loss: 0.6508\n",
      "\n",
      "Accuracy: 63.04%\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 180.4350\n",
      "Function value obtained: -0.6304\n",
      "Current minimum: -0.6763\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "learning rate: 1.6e-04\n",
      "num_dense_nodes: 201\n",
      "dropout: 0.3116595410317906\n",
      "optimizer_type: SGD\n",
      "epochs: 15\n",
      "Epoch 1/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 715ms/step - accuracy: 0.6171 - loss: 0.6511 - val_accuracy: 0.6473 - val_loss: 0.6193\n",
      "Epoch 2/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.8031 - loss: 0.4231 - val_accuracy: 0.6727 - val_loss: 0.6470\n",
      "Epoch 3/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.8659 - loss: 0.3112 - val_accuracy: 0.8382 - val_loss: 0.3689\n",
      "Epoch 4/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.9034 - loss: 0.2257 - val_accuracy: 0.8430 - val_loss: 0.3444\n",
      "Epoch 5/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.9263 - loss: 0.1973 - val_accuracy: 0.8635 - val_loss: 0.3311\n",
      "Epoch 6/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.9795 - loss: 0.0850 - val_accuracy: 0.8527 - val_loss: 0.3548\n",
      "Epoch 7/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9746 - loss: 0.0700 - val_accuracy: 0.8490 - val_loss: 0.3857\n",
      "Epoch 8/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9734 - loss: 0.0669 - val_accuracy: 0.8551 - val_loss: 0.4035\n",
      "Epoch 9/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9867 - loss: 0.0431 - val_accuracy: 0.8514 - val_loss: 0.4377\n",
      "Epoch 10/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9940 - loss: 0.0284 - val_accuracy: 0.8514 - val_loss: 0.4612\n",
      "Epoch 11/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9771 - loss: 0.0510 - val_accuracy: 0.8261 - val_loss: 0.5847\n",
      "Epoch 12/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9867 - loss: 0.0555 - val_accuracy: 0.8539 - val_loss: 0.4277\n",
      "Epoch 13/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9843 - loss: 0.0474 - val_accuracy: 0.8418 - val_loss: 0.4456\n",
      "Epoch 14/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9855 - loss: 0.0345 - val_accuracy: 0.8527 - val_loss: 0.5591\n",
      "Epoch 15/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9819 - loss: 0.0607 - val_accuracy: 0.8575 - val_loss: 0.4457\n",
      "\n",
      "Accuracy: 85.75%\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 188.4369\n",
      "Function value obtained: -0.8575\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "learning rate: 1.1e-03\n",
      "num_dense_nodes: 169\n",
      "dropout: 0.43489997830597915\n",
      "optimizer_type: SGD\n",
      "epochs: 7\n",
      "Epoch 1/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 720ms/step - accuracy: 0.6969 - loss: 0.5716 - val_accuracy: 0.6667 - val_loss: 0.5635\n",
      "Epoch 2/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.8551 - loss: 0.3693 - val_accuracy: 0.7089 - val_loss: 0.5142\n",
      "Epoch 3/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8816 - loss: 0.2853 - val_accuracy: 0.8080 - val_loss: 0.4063\n",
      "Epoch 4/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9312 - loss: 0.1970 - val_accuracy: 0.8357 - val_loss: 0.3643\n",
      "Epoch 5/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9420 - loss: 0.1448 - val_accuracy: 0.8200 - val_loss: 0.4047\n",
      "Epoch 6/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9686 - loss: 0.0951 - val_accuracy: 0.8466 - val_loss: 0.3565\n",
      "Epoch 7/7\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.9795 - loss: 0.0713 - val_accuracy: 0.8333 - val_loss: 0.4538\n",
      "\n",
      "Accuracy: 83.33%\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 130.8872\n",
      "Function value obtained: -0.8333\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "learning rate: 3.6e-03\n",
      "num_dense_nodes: 60\n",
      "dropout: 0.21883668455156408\n",
      "optimizer_type: Adam\n",
      "epochs: 16\n",
      "Epoch 1/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 855ms/step - accuracy: 0.6063 - loss: 0.7340 - val_accuracy: 0.5000 - val_loss: 348833856.0000\n",
      "Epoch 2/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.6715 - loss: 0.6352 - val_accuracy: 0.6896 - val_loss: 1.4346\n",
      "Epoch 3/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7524 - loss: 0.5454 - val_accuracy: 0.6715 - val_loss: 2.2698\n",
      "Epoch 4/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7899 - loss: 0.4840 - val_accuracy: 0.5000 - val_loss: 0.8551\n",
      "Epoch 5/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.6570 - loss: 0.5929 - val_accuracy: 0.6969 - val_loss: 625.3657\n",
      "Epoch 6/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.7790 - loss: 0.5407 - val_accuracy: 0.3913 - val_loss: 1102.3197\n",
      "Epoch 7/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7742 - loss: 0.4711 - val_accuracy: 0.7633 - val_loss: 2.9449\n",
      "Epoch 8/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7778 - loss: 0.5233 - val_accuracy: 0.5012 - val_loss: 22567.8809\n",
      "Epoch 9/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8213 - loss: 0.4392 - val_accuracy: 0.5000 - val_loss: 42.8435\n",
      "Epoch 10/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7754 - loss: 0.4486 - val_accuracy: 0.4662 - val_loss: 0.7163\n",
      "Epoch 11/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7633 - loss: 0.4252 - val_accuracy: 0.3551 - val_loss: 0.9367\n",
      "Epoch 12/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7790 - loss: 0.4177 - val_accuracy: 0.6014 - val_loss: 0.5645\n",
      "Epoch 13/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8164 - loss: 0.3854 - val_accuracy: 0.7041 - val_loss: 0.6224\n",
      "Epoch 14/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8213 - loss: 0.3827 - val_accuracy: 0.7633 - val_loss: 0.7770\n",
      "Epoch 15/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8200 - loss: 0.3911 - val_accuracy: 0.7959 - val_loss: 4.7046\n",
      "Epoch 16/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8321 - loss: 0.3968 - val_accuracy: 0.5012 - val_loss: 2.2544\n",
      "\n",
      "Accuracy: 50.12%\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 223.2014\n",
      "Function value obtained: -0.5012\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "learning rate: 2.9e-05\n",
      "num_dense_nodes: 204\n",
      "dropout: 0.7062028178286491\n",
      "optimizer_type: SGD\n",
      "epochs: 19\n",
      "Epoch 1/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 712ms/step - accuracy: 0.4903 - loss: 0.8067 - val_accuracy: 0.4952 - val_loss: 0.7464\n",
      "Epoch 2/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.5254 - loss: 0.7695 - val_accuracy: 0.5302 - val_loss: 0.7060\n",
      "Epoch 3/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5254 - loss: 0.7431 - val_accuracy: 0.5821 - val_loss: 0.6820\n",
      "Epoch 4/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5362 - loss: 0.7199 - val_accuracy: 0.5930 - val_loss: 0.6694\n",
      "Epoch 5/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5507 - loss: 0.7070 - val_accuracy: 0.6135 - val_loss: 0.6604\n",
      "Epoch 6/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5857 - loss: 0.6970 - val_accuracy: 0.6522 - val_loss: 0.6431\n",
      "Epoch 7/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.6135 - loss: 0.6763 - val_accuracy: 0.6763 - val_loss: 0.6274\n",
      "Epoch 8/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5833 - loss: 0.6671 - val_accuracy: 0.6848 - val_loss: 0.6176\n",
      "Epoch 9/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6135 - loss: 0.6692 - val_accuracy: 0.7089 - val_loss: 0.6093\n",
      "Epoch 10/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5966 - loss: 0.6769 - val_accuracy: 0.7150 - val_loss: 0.6004\n",
      "Epoch 11/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6486 - loss: 0.6308 - val_accuracy: 0.7258 - val_loss: 0.5931\n",
      "Epoch 12/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6473 - loss: 0.6288 - val_accuracy: 0.7391 - val_loss: 0.5838\n",
      "Epoch 13/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.6594 - loss: 0.6122 - val_accuracy: 0.7464 - val_loss: 0.5770\n",
      "Epoch 14/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.6413 - loss: 0.6232 - val_accuracy: 0.7621 - val_loss: 0.5688\n",
      "Epoch 15/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.6715 - loss: 0.6024 - val_accuracy: 0.7705 - val_loss: 0.5618\n",
      "Epoch 16/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.6558 - loss: 0.6094 - val_accuracy: 0.7766 - val_loss: 0.5543\n",
      "Epoch 17/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6655 - loss: 0.6068 - val_accuracy: 0.7886 - val_loss: 0.5456\n",
      "Epoch 18/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6800 - loss: 0.5849 - val_accuracy: 0.7862 - val_loss: 0.5391\n",
      "Epoch 19/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.7017 - loss: 0.5696 - val_accuracy: 0.7886 - val_loss: 0.5333\n",
      "\n",
      "Accuracy: 78.86%\n",
      "\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 218.1609\n",
      "Function value obtained: -0.7886\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "learning rate: 4.9e-03\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.1\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 740ms/step - accuracy: 0.7512 - loss: 0.5162 - val_accuracy: 0.5000 - val_loss: 9.8915\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8092 - loss: 0.4317 - val_accuracy: 0.5000 - val_loss: 56226.5156\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.8007 - loss: 0.4911 - val_accuracy: 0.5000 - val_loss: 2987143.5000\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7609 - loss: 0.5002 - val_accuracy: 0.5000 - val_loss: 4659383.5000\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7778 - loss: 0.4994 - val_accuracy: 0.5000 - val_loss: 3188898.2500\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 115.1384\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-06\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.8\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 807ms/step - accuracy: 0.5024 - loss: 0.7854 - val_accuracy: 0.4819 - val_loss: 0.7288\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.4734 - loss: 0.7890 - val_accuracy: 0.4915 - val_loss: 0.7169\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.5060 - loss: 0.7634 - val_accuracy: 0.4915 - val_loss: 0.7064\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.4601 - loss: 0.7975 - val_accuracy: 0.5048 - val_loss: 0.6993\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.4843 - loss: 0.8106 - val_accuracy: 0.5157 - val_loss: 0.6991\n",
      "\n",
      "Accuracy: 51.57%\n",
      "\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.6072\n",
      "Function value obtained: -0.5157\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "learning rate: 2.7e-03\n",
      "num_dense_nodes: 216\n",
      "dropout: 0.76278465975501\n",
      "optimizer_type: SGD\n",
      "epochs: 18\n",
      "Epoch 1/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 757ms/step - accuracy: 0.6981 - loss: 0.6036 - val_accuracy: 0.5000 - val_loss: 39.6797\n",
      "Epoch 2/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7850 - loss: 0.4625 - val_accuracy: 0.5000 - val_loss: 63.8604\n",
      "Epoch 3/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.7874 - loss: 0.4446 - val_accuracy: 0.5000 - val_loss: 100.2695\n",
      "Epoch 4/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.8128 - loss: 0.4257 - val_accuracy: 0.4746 - val_loss: 11.6318\n",
      "Epoch 5/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.8213 - loss: 0.4269 - val_accuracy: 0.7947 - val_loss: 0.9457\n",
      "Epoch 6/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8285 - loss: 0.4053 - val_accuracy: 0.7597 - val_loss: 1.6748\n",
      "Epoch 7/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8152 - loss: 0.4188 - val_accuracy: 0.7971 - val_loss: 0.6122\n",
      "Epoch 8/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8406 - loss: 0.3635 - val_accuracy: 0.8092 - val_loss: 0.4794\n",
      "Epoch 9/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8490 - loss: 0.3642 - val_accuracy: 0.8031 - val_loss: 0.4822\n",
      "Epoch 10/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8539 - loss: 0.3427 - val_accuracy: 0.7572 - val_loss: 0.5264\n",
      "Epoch 11/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8563 - loss: 0.3363 - val_accuracy: 0.5918 - val_loss: 0.7218\n",
      "Epoch 12/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8599 - loss: 0.3177 - val_accuracy: 0.7391 - val_loss: 0.5461\n",
      "Epoch 13/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8575 - loss: 0.3310 - val_accuracy: 0.7210 - val_loss: 0.4695\n",
      "Epoch 14/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8768 - loss: 0.3066 - val_accuracy: 0.7464 - val_loss: 0.5132\n",
      "Epoch 15/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8889 - loss: 0.2775 - val_accuracy: 0.8273 - val_loss: 0.5314\n",
      "Epoch 16/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8998 - loss: 0.2453 - val_accuracy: 0.8140 - val_loss: 0.4659\n",
      "Epoch 17/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8998 - loss: 0.2436 - val_accuracy: 0.8333 - val_loss: 0.4954\n",
      "Epoch 18/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9251 - loss: 0.2167 - val_accuracy: 0.8249 - val_loss: 0.5808\n",
      "\n",
      "Accuracy: 82.49%\n",
      "\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 214.2640\n",
      "Function value obtained: -0.8249\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-06\n",
      "num_dense_nodes: 191\n",
      "dropout: 0.8\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 874ms/step - accuracy: 0.4831 - loss: 0.9214 - val_accuracy: 0.4976 - val_loss: 0.7573\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.4674 - loss: 0.9158 - val_accuracy: 0.5060 - val_loss: 0.7363\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5085 - loss: 0.8766 - val_accuracy: 0.5254 - val_loss: 0.7303\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5000 - loss: 0.9116 - val_accuracy: 0.5169 - val_loss: 0.7316\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4903 - loss: 0.9113 - val_accuracy: 0.5133 - val_loss: 0.7318\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4988 - loss: 0.8849 - val_accuracy: 0.5266 - val_loss: 0.7307\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4903 - loss: 0.8847 - val_accuracy: 0.5133 - val_loss: 0.7329\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4988 - loss: 0.8688 - val_accuracy: 0.5072 - val_loss: 0.7347\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4964 - loss: 0.9072 - val_accuracy: 0.5000 - val_loss: 0.7341\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4879 - loss: 0.9037 - val_accuracy: 0.5036 - val_loss: 0.7340\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4771 - loss: 0.9113 - val_accuracy: 0.5048 - val_loss: 0.7325\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5374 - loss: 0.8617 - val_accuracy: 0.5012 - val_loss: 0.7324\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5121 - loss: 0.8743 - val_accuracy: 0.5024 - val_loss: 0.7330\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4928 - loss: 0.9019 - val_accuracy: 0.5012 - val_loss: 0.7336\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5036 - loss: 0.8615 - val_accuracy: 0.5036 - val_loss: 0.7331\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5266 - loss: 0.8692 - val_accuracy: 0.5024 - val_loss: 0.7334\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4964 - loss: 0.9248 - val_accuracy: 0.5036 - val_loss: 0.7334\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4891 - loss: 0.9146 - val_accuracy: 0.5024 - val_loss: 0.7332\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.4952 - loss: 0.8893 - val_accuracy: 0.5000 - val_loss: 0.7333\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5145 - loss: 0.8736 - val_accuracy: 0.5000 - val_loss: 0.7325\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 261.8516\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "learning rate: 4.3e-04\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.5844568016563746\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 765ms/step - accuracy: 0.6473 - loss: 0.6363 - val_accuracy: 0.5157 - val_loss: 0.8846\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8164 - loss: 0.3984 - val_accuracy: 0.7355 - val_loss: 0.5344\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8780 - loss: 0.2823 - val_accuracy: 0.8249 - val_loss: 0.3849\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9239 - loss: 0.2205 - val_accuracy: 0.8309 - val_loss: 0.4021\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.9444 - loss: 0.1798 - val_accuracy: 0.8394 - val_loss: 0.3491\n",
      "\n",
      "Accuracy: 83.94%\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 117.2445\n",
      "Function value obtained: -0.8394\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "learning rate: 3.9e-04\n",
      "num_dense_nodes: 167\n",
      "dropout: 0.35068723804460356\n",
      "optimizer_type: SGD\n",
      "epochs: 19\n",
      "Epoch 1/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 777ms/step - accuracy: 0.6836 - loss: 0.5979 - val_accuracy: 0.6244 - val_loss: 0.6122\n",
      "Epoch 2/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8345 - loss: 0.3915 - val_accuracy: 0.7729 - val_loss: 0.4683\n",
      "Epoch 3/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.8841 - loss: 0.2998 - val_accuracy: 0.8357 - val_loss: 0.3562\n",
      "Epoch 4/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9179 - loss: 0.2146 - val_accuracy: 0.8466 - val_loss: 0.3421\n",
      "Epoch 5/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9469 - loss: 0.1372 - val_accuracy: 0.8357 - val_loss: 0.3691\n",
      "Epoch 6/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9638 - loss: 0.0985 - val_accuracy: 0.8333 - val_loss: 0.4047\n",
      "Epoch 7/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9807 - loss: 0.0696 - val_accuracy: 0.8261 - val_loss: 0.4898\n",
      "Epoch 8/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9662 - loss: 0.0945 - val_accuracy: 0.8454 - val_loss: 0.4225\n",
      "Epoch 9/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9771 - loss: 0.0673 - val_accuracy: 0.8237 - val_loss: 0.5160\n",
      "Epoch 10/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9855 - loss: 0.0405 - val_accuracy: 0.8382 - val_loss: 0.4576\n",
      "Epoch 11/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9734 - loss: 0.0756 - val_accuracy: 0.8635 - val_loss: 0.3918\n",
      "Epoch 12/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9807 - loss: 0.0466 - val_accuracy: 0.8623 - val_loss: 0.4549\n",
      "Epoch 13/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9891 - loss: 0.0324 - val_accuracy: 0.8382 - val_loss: 0.4926\n",
      "Epoch 14/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9855 - loss: 0.0464 - val_accuracy: 0.8514 - val_loss: 0.4558\n",
      "Epoch 15/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9783 - loss: 0.0623 - val_accuracy: 0.8273 - val_loss: 0.5143\n",
      "Epoch 16/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9903 - loss: 0.0384 - val_accuracy: 0.8394 - val_loss: 0.5359\n",
      "Epoch 17/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9903 - loss: 0.0277 - val_accuracy: 0.8635 - val_loss: 0.4820\n",
      "Epoch 18/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9952 - loss: 0.0209 - val_accuracy: 0.8756 - val_loss: 0.4482\n",
      "Epoch 19/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9903 - loss: 0.0330 - val_accuracy: 0.8454 - val_loss: 0.5350\n",
      "\n",
      "Accuracy: 84.54%\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 224.1836\n",
      "Function value obtained: -0.8454\n",
      "Current minimum: -0.8575\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "learning rate: 1.1e-03\n",
      "num_dense_nodes: 169\n",
      "dropout: 0.6405764859221289\n",
      "optimizer_type: SGD\n",
      "epochs: 15\n",
      "Epoch 1/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 770ms/step - accuracy: 0.6630 - loss: 0.6082 - val_accuracy: 0.7271 - val_loss: 0.5217\n",
      "Epoch 2/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - accuracy: 0.8128 - loss: 0.3918 - val_accuracy: 0.7705 - val_loss: 0.4490\n",
      "Epoch 3/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.8744 - loss: 0.2820 - val_accuracy: 0.8213 - val_loss: 0.3803\n",
      "Epoch 4/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.8973 - loss: 0.2553 - val_accuracy: 0.8514 - val_loss: 0.3715\n",
      "Epoch 5/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9203 - loss: 0.1901 - val_accuracy: 0.8394 - val_loss: 0.3379\n",
      "Epoch 6/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.9324 - loss: 0.1689 - val_accuracy: 0.8309 - val_loss: 0.3984\n",
      "Epoch 7/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9529 - loss: 0.1143 - val_accuracy: 0.8454 - val_loss: 0.3874\n",
      "Epoch 8/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9650 - loss: 0.1113 - val_accuracy: 0.8539 - val_loss: 0.4071\n",
      "Epoch 9/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9626 - loss: 0.1001 - val_accuracy: 0.8551 - val_loss: 0.4815\n",
      "Epoch 10/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9783 - loss: 0.0641 - val_accuracy: 0.8647 - val_loss: 0.4590\n",
      "Epoch 11/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9795 - loss: 0.0556 - val_accuracy: 0.8418 - val_loss: 0.3956\n",
      "Epoch 12/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9867 - loss: 0.0406 - val_accuracy: 0.8599 - val_loss: 0.4186\n",
      "Epoch 13/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9843 - loss: 0.0490 - val_accuracy: 0.8430 - val_loss: 0.5113\n",
      "Epoch 14/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9795 - loss: 0.0522 - val_accuracy: 0.8575 - val_loss: 0.7846\n",
      "Epoch 15/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.9891 - loss: 0.0377 - val_accuracy: 0.8684 - val_loss: 0.5011\n",
      "\n",
      "Accuracy: 86.84%\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 196.2008\n",
      "Function value obtained: -0.8684\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "learning rate: 4.8e-05\n",
      "num_dense_nodes: 180\n",
      "dropout: 0.1\n",
      "optimizer_type: SGD\n",
      "epochs: 8\n",
      "Epoch 1/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 732ms/step - accuracy: 0.4855 - loss: 0.7159 - val_accuracy: 0.4795 - val_loss: 0.7386\n",
      "Epoch 2/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5580 - loss: 0.6846 - val_accuracy: 0.5507 - val_loss: 0.6850\n",
      "Epoch 3/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.5821 - loss: 0.6632 - val_accuracy: 0.5978 - val_loss: 0.6519\n",
      "Epoch 4/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - accuracy: 0.6570 - loss: 0.6381 - val_accuracy: 0.6353 - val_loss: 0.6355\n",
      "Epoch 5/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.6896 - loss: 0.6112 - val_accuracy: 0.6679 - val_loss: 0.6156\n",
      "Epoch 6/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.7222 - loss: 0.5957 - val_accuracy: 0.7101 - val_loss: 0.5966\n",
      "Epoch 7/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.7850 - loss: 0.5699 - val_accuracy: 0.7210 - val_loss: 0.5775\n",
      "Epoch 8/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.7621 - loss: 0.5588 - val_accuracy: 0.7548 - val_loss: 0.5586\n",
      "\n",
      "Accuracy: 75.48%\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 141.3074\n",
      "Function value obtained: -0.7548\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "learning rate: 9.2e-05\n",
      "num_dense_nodes: 92\n",
      "dropout: 0.4884419794135373\n",
      "optimizer_type: Adam\n",
      "epochs: 11\n",
      "Epoch 1/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 878ms/step - accuracy: 0.7778 - loss: 0.4840 - val_accuracy: 0.6570 - val_loss: 0.7341\n",
      "Epoch 2/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8841 - loss: 0.2561 - val_accuracy: 0.8406 - val_loss: 0.3748\n",
      "Epoch 3/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9457 - loss: 0.1701 - val_accuracy: 0.8454 - val_loss: 0.3855\n",
      "Epoch 4/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.9577 - loss: 0.1193 - val_accuracy: 0.8502 - val_loss: 0.4254\n",
      "Epoch 5/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9505 - loss: 0.1107 - val_accuracy: 0.8575 - val_loss: 0.5035\n",
      "Epoch 6/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9771 - loss: 0.0581 - val_accuracy: 0.8684 - val_loss: 0.6036\n",
      "Epoch 7/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9819 - loss: 0.0498 - val_accuracy: 0.8708 - val_loss: 0.5119\n",
      "Epoch 8/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9819 - loss: 0.0548 - val_accuracy: 0.8068 - val_loss: 0.7598\n",
      "Epoch 9/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9831 - loss: 0.0520 - val_accuracy: 0.8551 - val_loss: 0.6426\n",
      "Epoch 10/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.9867 - loss: 0.0450 - val_accuracy: 0.8587 - val_loss: 0.6848\n",
      "Epoch 11/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.9843 - loss: 0.0439 - val_accuracy: 0.8514 - val_loss: 0.6035\n",
      "\n",
      "Accuracy: 85.14%\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 191.9274\n",
      "Function value obtained: -0.8514\n",
      "Current minimum: -0.8684\n",
      "Seed:  11\n",
      "BEST ACCURACY:  {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.8683574795722961, 12: 0.0, 13: 0.0, 14: 0.0}\n",
      "hyper_params  [0.0010798427788517471, 0.6405764859221289, 0.9081783891734511, 0.9126940277078837, 0.9938707691366083, np.int64(15), np.int64(169), np.str_('SGD')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 11\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756595736.012450    3742 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 11\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756595759.869092    6409 service.cc:152] XLA service 0x7fa798018ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756595759.869502    6409 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-30 23:16:00.021303: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756595761.247297    6409 cuda_dnn.cc:529] Loaded cuDNN version 91200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/13\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756595767.761999    6409 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 763ms/step\n",
      "[[np.float32(0.9749831), np.float32(0.025016904)], [np.float32(0.9994251), np.float32(0.0005748868)], [np.float32(0.99993026), np.float32(6.9737434e-05)], [np.float32(0.9993832), np.float32(0.00061678886)], [np.float32(0.9858206), np.float32(0.014179409)], [np.float32(0.9999895), np.float32(1.04904175e-05)], [np.float32(0.9997527), np.float32(0.00024729967)], [np.float32(0.90475446), np.float32(0.09524554)], [np.float32(0.99994075), np.float32(5.9247017e-05)], [np.float32(0.99869883), np.float32(0.0013011694)], [np.float32(0.9999995), np.float32(4.7683716e-07)], [np.float32(0.9999759), np.float32(2.4080276e-05)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.99660856), np.float32(0.0033914447)], [np.float32(0.98603326), np.float32(0.013966739)], [np.float32(0.25242743), np.float32(0.74757254)], [np.float32(0.9993312), np.float32(0.0006688237)], [np.float32(0.51230776), np.float32(0.48769224)], [np.float32(0.99839765), np.float32(0.0016023517)], [np.float32(0.8243308), np.float32(0.1756692)], [np.float32(0.26258713), np.float32(0.73741287)], [np.float32(0.054994136), np.float32(0.9450059)], [np.float32(0.9941413), np.float32(0.0058587193)], [np.float32(0.17773077), np.float32(0.8222692)], [np.float32(0.99962103), np.float32(0.00037896633)], [np.float32(0.84215665), np.float32(0.15784335)], [np.float32(0.80165005), np.float32(0.19834995)], [np.float32(0.8409747), np.float32(0.15902531)], [np.float32(0.7211702), np.float32(0.2788298)], [np.float32(0.9999051), np.float32(9.4890594e-05)], [np.float32(0.99796045), np.float32(0.0020395517)], [np.float32(0.99992704), np.float32(7.2956085e-05)], [np.float32(0.970193), np.float32(0.029806972)], [np.float32(0.898283), np.float32(0.101716995)], [np.float32(0.12824833), np.float32(0.87175167)], [np.float32(0.9718097), np.float32(0.028190315)], [np.float32(0.99999905), np.float32(9.536743e-07)], [np.float32(0.9999422), np.float32(5.7816505e-05)], [np.float32(0.977118), np.float32(0.022881985)], [np.float32(0.94913715), np.float32(0.05086285)], [np.float32(0.9998312), np.float32(0.00016880035)], [np.float32(0.99923956), np.float32(0.00076043606)], [np.float32(0.99884856), np.float32(0.0011514425)], [np.float32(0.19735985), np.float32(0.80264014)], [np.float32(0.9999014), np.float32(9.858608e-05)], [np.float32(0.83436614), np.float32(0.16563386)], [np.float32(0.9904896), np.float32(0.009510398)], [np.float32(0.9999701), np.float32(2.9921532e-05)], [np.float32(0.9960609), np.float32(0.003939092)], [np.float32(0.99997175), np.float32(2.8252602e-05)], [np.float32(0.9999994), np.float32(5.9604645e-07)], [np.float32(0.99682355), np.float32(0.0031764507)], [np.float32(0.99996006), np.float32(3.9935112e-05)], [np.float32(0.05414853), np.float32(0.94585145)], [np.float32(0.8585284), np.float32(0.14147162)], [np.float32(0.9995422), np.float32(0.00045782328)], [np.float32(0.9989206), np.float32(0.0010793805)], [np.float32(0.014027223), np.float32(0.98597276)], [np.float32(0.99863285), np.float32(0.0013671517)], [np.float32(0.99969596), np.float32(0.0003040433)], [np.float32(0.9807043), np.float32(0.019295692)], [np.float32(0.99027246), np.float32(0.009727538)], [np.float32(0.023916772), np.float32(0.9760832)], [np.float32(0.99999464), np.float32(5.364418e-06)], [np.float32(0.9991622), np.float32(0.0008378029)], [np.float32(0.999856), np.float32(0.00014400482)], [np.float32(0.9980349), np.float32(0.0019651055)], [np.float32(0.91501045), np.float32(0.08498955)], [np.float32(0.9998685), np.float32(0.00013148785)], [np.float32(0.9159468), np.float32(0.08405322)], [np.float32(0.9854263), np.float32(0.014573693)], [np.float32(0.9991617), np.float32(0.0008382797)], [np.float32(0.9999672), np.float32(3.2782555e-05)], [np.float32(0.99102134), np.float32(0.008978665)], [np.float32(0.9999994), np.float32(5.9604645e-07)], [np.float32(0.99999714), np.float32(2.861023e-06)], [np.float32(0.96776986), np.float32(0.03223014)], [np.float32(0.9919259), np.float32(0.008074105)], [np.float32(0.9999362), np.float32(6.377697e-05)], [np.float32(0.99999046), np.float32(9.536743e-06)], [np.float32(0.9992437), np.float32(0.00075632334)], [np.float32(0.53428155), np.float32(0.46571845)], [np.float32(0.9635776), np.float32(0.036422372)], [np.float32(0.99997973), np.float32(2.026558e-05)], [np.float32(0.9456341), np.float32(0.054365873)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9995498), np.float32(0.00045019388)], [np.float32(0.9999752), np.float32(2.4795532e-05)], [np.float32(0.99275887), np.float32(0.00724113)], [np.float32(0.99987185), np.float32(0.00012814999)], [np.float32(0.003858813), np.float32(0.9961412)], [np.float32(0.22631338), np.float32(0.77368665)], [np.float32(0.9999497), np.float32(5.030632e-05)], [np.float32(0.99327433), np.float32(0.006725669)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.57503366), np.float32(0.42496634)], [np.float32(0.9999777), np.float32(2.2292137e-05)], [np.float32(0.99947035), np.float32(0.0005296469)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99984443), np.float32(0.00015556812)], [np.float32(0.76120156), np.float32(0.23879844)], [np.float32(0.9988882), np.float32(0.0011118054)], [np.float32(0.98237145), np.float32(0.01762855)], [np.float32(0.98159516), np.float32(0.018404841)], [np.float32(0.99973243), np.float32(0.00026756525)], [np.float32(0.16805755), np.float32(0.83194244)], [np.float32(0.99998784), np.float32(1.21593475e-05)], [np.float32(0.99999917), np.float32(8.34465e-07)], [np.float32(0.9210906), np.float32(0.0789094)], [np.float32(0.9845488), np.float32(0.015451193)], [np.float32(0.24279547), np.float32(0.75720453)], [np.float32(0.9940978), np.float32(0.005902171)], [np.float32(0.99118245), np.float32(0.0088175535)], [np.float32(0.98694587), np.float32(0.013054132)], [np.float32(0.99621916), np.float32(0.0037808418)], [np.float32(0.99873036), np.float32(0.0012696385)], [np.float32(0.9989976), np.float32(0.0010023713)], [np.float32(0.0002927545), np.float32(0.9997072)], [np.float32(0.805924), np.float32(0.194076)], [np.float32(0.92085063), np.float32(0.079149365)], [np.float32(0.99562776), np.float32(0.004372239)], [np.float32(0.9796489), np.float32(0.020351112)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9998822), np.float32(0.00011777878)], [np.float32(0.99954647), np.float32(0.00045353174)], [np.float32(0.9999776), np.float32(2.2411346e-05)], [np.float32(0.9945748), np.float32(0.005425215)], [np.float32(0.99989974), np.float32(0.00010025501)], [np.float32(0.99988604), np.float32(0.00011396408)], [np.float32(0.9835655), np.float32(0.01643449)], [np.float32(0.99753237), np.float32(0.0024676323)], [np.float32(0.9977087), np.float32(0.0022913218)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9997796), np.float32(0.00022041798)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99737406), np.float32(0.0026259422)], [np.float32(0.9185509), np.float32(0.08144909)], [np.float32(0.99480313), np.float32(0.0051968694)], [np.float32(0.9817144), np.float32(0.018285573)], [np.float32(0.9856806), np.float32(0.01431942)], [np.float32(0.9999989), np.float32(1.0728836e-06)], [np.float32(0.99951756), np.float32(0.00048244)], [np.float32(0.9997802), np.float32(0.00021982193)], [np.float32(0.99999785), np.float32(2.1457672e-06)], [np.float32(0.9897508), np.float32(0.0102491975)], [np.float32(0.9515758), np.float32(0.048424184)], [np.float32(0.77113134), np.float32(0.22886866)], [np.float32(0.99999714), np.float32(2.861023e-06)], [np.float32(0.99999857), np.float32(1.4305115e-06)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.08063), np.float32(0.91937)], [np.float32(0.74655), np.float32(0.25344998)], [np.float32(0.99999857), np.float32(1.4305115e-06)], [np.float32(0.9995492), np.float32(0.00045078993)], [np.float32(0.8547256), np.float32(0.1452744)], [np.float32(0.999752), np.float32(0.00024801493)], [np.float32(0.99980915), np.float32(0.00019085407)], [np.float32(0.996308), np.float32(0.0036919713)], [np.float32(0.99988484), np.float32(0.000115156174)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99595624), np.float32(0.004043758)], [np.float32(0.99988043), np.float32(0.00011956692)], [np.float32(0.9996936), np.float32(0.00030642748)], [np.float32(0.999866), np.float32(0.00013399124)], [np.float32(0.9174632), np.float32(0.08253682)], [np.float32(0.998855), np.float32(0.0011450052)], [np.float32(0.9999758), np.float32(2.4199486e-05)], [np.float32(0.77418214), np.float32(0.22581786)], [np.float32(0.037535075), np.float32(0.9624649)], [np.float32(0.99999356), np.float32(6.4373016e-06)], [np.float32(0.9999989), np.float32(1.0728836e-06)], [np.float32(0.99541736), np.float32(0.0045826435)], [np.float32(0.99808025), np.float32(0.0019197464)], [np.float32(0.8998772), np.float32(0.10012281)], [np.float32(0.93465763), np.float32(0.06534237)], [np.float32(0.9999094), np.float32(9.059906e-05)], [np.float32(0.98998266), np.float32(0.010017335)], [np.float32(0.9566232), np.float32(0.043376803)], [np.float32(0.9998778), np.float32(0.00012218952)], [np.float32(0.99988794), np.float32(0.00011205673)], [np.float32(0.99981356), np.float32(0.00018644333)], [np.float32(0.9958256), np.float32(0.0041744113)], [np.float32(0.9449097), np.float32(0.05509031)], [np.float32(0.9999944), np.float32(5.6028366e-06)], [np.float32(0.99979305), np.float32(0.00020694733)], [np.float32(0.029488677), np.float32(0.9705113)], [np.float32(0.9999932), np.float32(6.7949295e-06)], [np.float32(0.9818625), np.float32(0.018137515)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.9990414), np.float32(0.0009586215)], [np.float32(0.99979556), np.float32(0.00020444393)], [np.float32(0.99982834), np.float32(0.00017166138)], [np.float32(0.99999726), np.float32(2.7418137e-06)], [np.float32(0.9698299), np.float32(0.030170083)], [np.float32(0.9999293), np.float32(7.069111e-05)], [np.float32(0.9976415), np.float32(0.0023584962)], [np.float32(0.9269394), np.float32(0.07306057)], [np.float32(0.17549542), np.float32(0.8245046)], [np.float32(0.998273), np.float32(0.001726985)], [np.float32(0.9900479), np.float32(0.009952128)], [np.float32(0.0035716358), np.float32(0.9964284)], [np.float32(0.00011973084), np.float32(0.99988025)], [np.float32(0.025384627), np.float32(0.9746154)], [np.float32(0.000706656), np.float32(0.9992933)], [np.float32(5.8854293e-06), np.float32(0.9999941)], [np.float32(9.5338777e-07), np.float32(0.99999905)], [np.float32(0.95704734), np.float32(0.042952657)], [np.float32(0.005334416), np.float32(0.99466556)], [np.float32(4.068267e-07), np.float32(0.9999996)], [np.float32(6.9131906e-06), np.float32(0.9999931)], [np.float32(0.06595101), np.float32(0.934049)], [np.float32(0.99999726), np.float32(2.7418137e-06)], [np.float32(0.45541832), np.float32(0.54458165)], [np.float32(0.6436743), np.float32(0.3563257)], [np.float32(0.04169405), np.float32(0.95830595)], [np.float32(9.441858e-07), np.float32(0.99999905)], [np.float32(0.025299557), np.float32(0.97470045)], [np.float32(0.0054153968), np.float32(0.9945846)], [np.float32(0.6001886), np.float32(0.3998114)], [np.float32(0.0003632045), np.float32(0.99963677)], [np.float32(0.00015249879), np.float32(0.9998475)], [np.float32(3.9502197e-06), np.float32(0.99999607)], [np.float32(0.42585087), np.float32(0.57414913)], [np.float32(9.490205e-05), np.float32(0.9999051)], [np.float32(9.0626534e-05), np.float32(0.9999094)], [np.float32(0.9054017), np.float32(0.09459829)], [np.float32(0.99215966), np.float32(0.007840335)], [np.float32(6.812708e-05), np.float32(0.9999319)], [np.float32(0.7741238), np.float32(0.22587621)], [np.float32(0.18344301), np.float32(0.816557)], [np.float32(0.97533166), np.float32(0.024668336)], [np.float32(0.99933344), np.float32(0.00066655874)], [np.float32(0.013731409), np.float32(0.9862686)], [np.float32(0.0021813968), np.float32(0.9978186)], [np.float32(0.5338103), np.float32(0.46618968)], [np.float32(2.6854984e-06), np.float32(0.9999973)], [np.float32(3.4039992e-06), np.float32(0.9999966)], [np.float32(2.3670224e-05), np.float32(0.99997634)], [np.float32(1.145856e-06), np.float32(0.99999887)], [np.float32(0.00013511872), np.float32(0.9998649)], [np.float32(0.0010530073), np.float32(0.99894696)], [np.float32(0.0034442951), np.float32(0.9965557)], [np.float32(0.32997754), np.float32(0.6700225)], [np.float32(6.2372936e-05), np.float32(0.99993765)], [np.float32(9.189571e-06), np.float32(0.9999908)], [np.float32(0.0042779343), np.float32(0.99572206)], [np.float32(8.399372e-05), np.float32(0.999916)], [np.float32(0.9049791), np.float32(0.09502089)], [np.float32(1.401985e-06), np.float32(0.99999857)], [np.float32(0.01040148), np.float32(0.9895985)], [np.float32(5.163926e-05), np.float32(0.9999484)], [np.float32(0.0009886562), np.float32(0.99901134)], [np.float32(1.549377e-05), np.float32(0.9999845)], [np.float32(0.000661432), np.float32(0.99933857)], [np.float32(0.001230925), np.float32(0.9987691)], [np.float32(0.033579677), np.float32(0.9664203)], [np.float32(0.0074944505), np.float32(0.99250555)], [np.float32(3.7459093e-05), np.float32(0.99996257)], [np.float32(0.13558738), np.float32(0.8644126)], [np.float32(0.94742435), np.float32(0.052575648)], [np.float32(0.00035600597), np.float32(0.999644)], [np.float32(0.0031757986), np.float32(0.9968242)], [np.float32(0.01638249), np.float32(0.9836175)], [np.float32(0.9927725), np.float32(0.0072274804)], [np.float32(0.013534548), np.float32(0.98646545)], [np.float32(0.0011234591), np.float32(0.9988765)], [np.float32(0.0001263368), np.float32(0.99987364)], [np.float32(5.1914376e-05), np.float32(0.9999481)], [np.float32(0.00091858336), np.float32(0.99908143)], [np.float32(9.479107e-06), np.float32(0.9999905)], [np.float32(0.99971455), np.float32(0.00028544664)], [np.float32(0.32692498), np.float32(0.673075)], [np.float32(0.15921423), np.float32(0.84078574)], [np.float32(1.7023807e-05), np.float32(0.99998295)], [np.float32(0.7999618), np.float32(0.2000382)], [np.float32(1.4295779e-06), np.float32(0.99999857)], [np.float32(3.0620402e-07), np.float32(0.9999997)], [np.float32(2.8795072e-05), np.float32(0.9999712)], [np.float32(4.6159606e-05), np.float32(0.99995387)], [np.float32(0.00058422243), np.float32(0.99941576)], [np.float32(0.16384155), np.float32(0.83615845)], [np.float32(0.0040000463), np.float32(0.99599993)], [np.float32(0.07224773), np.float32(0.92775226)], [np.float32(0.17501694), np.float32(0.82498306)], [np.float32(0.00028071046), np.float32(0.99971926)], [np.float32(0.9825041), np.float32(0.01749587)], [np.float32(3.5738667e-05), np.float32(0.99996424)], [np.float32(0.0009805664), np.float32(0.99901944)], [np.float32(0.0015205982), np.float32(0.9984794)], [np.float32(7.4744516e-06), np.float32(0.99999255)], [np.float32(6.798804e-06), np.float32(0.9999932)], [np.float32(5.2827335e-07), np.float32(0.99999946)], [np.float32(4.7878395e-05), np.float32(0.99995214)], [np.float32(1.5095164e-05), np.float32(0.9999849)], [np.float32(0.0001206783), np.float32(0.9998793)], [np.float32(0.0007053562), np.float32(0.99929464)], [np.float32(0.016024366), np.float32(0.98397565)], [np.float32(0.019142076), np.float32(0.9808579)], [np.float32(7.134278e-05), np.float32(0.99992865)], [np.float32(0.0024808734), np.float32(0.99751914)], [np.float32(0.015650047), np.float32(0.98434997)], [np.float32(2.6056728e-08), np.float32(1.0)], [np.float32(1.570918e-06), np.float32(0.99999845)], [np.float32(0.000280359), np.float32(0.9997196)], [np.float32(0.5705274), np.float32(0.42947263)], [np.float32(6.90029e-05), np.float32(0.999931)], [np.float32(1.63642e-05), np.float32(0.9999836)], [np.float32(0.00044976815), np.float32(0.9995502)], [np.float32(5.0495317e-05), np.float32(0.9999495)], [np.float32(1.8465313e-05), np.float32(0.9999815)], [np.float32(0.00013387995), np.float32(0.9998661)], [np.float32(5.1057664e-06), np.float32(0.9999949)], [np.float32(1.9604922e-05), np.float32(0.9999804)], [np.float32(0.00010945899), np.float32(0.99989057)], [np.float32(3.3506905e-07), np.float32(0.99999964)], [np.float32(0.0064260075), np.float32(0.99357396)], [np.float32(0.06472931), np.float32(0.93527067)], [np.float32(3.52311e-06), np.float32(0.9999965)], [np.float32(0.0009013879), np.float32(0.9990986)], [np.float32(1.9141115e-08), np.float32(1.0)], [np.float32(4.844405e-07), np.float32(0.9999995)], [np.float32(0.8406225), np.float32(0.15937752)], [np.float32(0.023253493), np.float32(0.9767465)], [np.float32(0.95897776), np.float32(0.04102224)], [np.float32(0.003202919), np.float32(0.9967971)], [np.float32(0.0029150585), np.float32(0.9970849)], [np.float32(4.8565875e-05), np.float32(0.9999514)], [np.float32(0.0005443531), np.float32(0.99945563)], [np.float32(1.5028742e-06), np.float32(0.9999985)], [np.float32(0.00070013304), np.float32(0.9992999)], [np.float32(0.00017880398), np.float32(0.9998212)], [np.float32(0.00085207605), np.float32(0.99914795)], [np.float32(7.9789396e-07), np.float32(0.9999992)], [np.float32(6.640246e-05), np.float32(0.9999336)], [np.float32(0.35187683), np.float32(0.64812315)], [np.float32(0.00090406387), np.float32(0.9990959)], [np.float32(0.9900598), np.float32(0.009940207)], [np.float32(0.00070408074), np.float32(0.9992959)], [np.float32(0.0026456749), np.float32(0.9973543)], [np.float32(7.411284e-05), np.float32(0.9999259)], [np.float32(0.0048816726), np.float32(0.9951183)], [np.float32(0.0012539702), np.float32(0.99874604)], [np.float32(0.9266775), np.float32(0.073322475)], [np.float32(0.00037414767), np.float32(0.99962586)], [np.float32(0.99956447), np.float32(0.00043553114)], [np.float32(0.90733945), np.float32(0.09266055)], [np.float32(0.011646675), np.float32(0.9883533)], [np.float32(6.362792e-05), np.float32(0.9999364)], [np.float32(0.00023118663), np.float32(0.9997688)], [np.float32(0.21925338), np.float32(0.78074664)], [np.float32(0.09217912), np.float32(0.9078209)], [np.float32(0.9992795), np.float32(0.00072050095)], [np.float32(0.0007241525), np.float32(0.99927586)], [np.float32(3.4427518e-05), np.float32(0.99996555)], [np.float32(0.00035261337), np.float32(0.9996474)], [np.float32(0.0972666), np.float32(0.9027334)], [np.float32(0.0028131786), np.float32(0.99718684)], [np.float32(3.2696968e-05), np.float32(0.9999673)], [np.float32(6.576925e-07), np.float32(0.99999934)], [np.float32(0.3976991), np.float32(0.6023009)], [np.float32(0.0077108894), np.float32(0.9922891)], [np.float32(0.0012053221), np.float32(0.9987947)], [np.float32(0.019210715), np.float32(0.9807893)], [np.float32(0.00077472185), np.float32(0.99922526)], [np.float32(4.5840516e-05), np.float32(0.99995416)], [np.float32(9.889456e-05), np.float32(0.9999011)], [np.float32(7.94734e-06), np.float32(0.9999921)], [np.float32(0.00064274005), np.float32(0.9993573)], [np.float32(0.14204592), np.float32(0.8579541)], [np.float32(7.694773e-05), np.float32(0.99992305)], [np.float32(1.13913e-06), np.float32(0.99999887)], [np.float32(3.1023534e-05), np.float32(0.999969)], [np.float32(0.04487798), np.float32(0.955122)], [np.float32(0.00012757645), np.float32(0.99987245)], [np.float32(0.02438976), np.float32(0.97561026)], [np.float32(0.009501304), np.float32(0.9904987)], [np.float32(0.8298453), np.float32(0.17015469)], [np.float32(0.04696398), np.float32(0.953036)], [np.float32(1.6351251e-07), np.float32(0.9999998)], [np.float32(2.5924131e-05), np.float32(0.9999741)], [np.float32(0.2531384), np.float32(0.7468616)], [np.float32(7.377065e-05), np.float32(0.9999262)], [np.float32(0.00019123538), np.float32(0.9998088)], [np.float32(0.50010157), np.float32(0.49989843)], [np.float32(1.1242815e-05), np.float32(0.99998873)], [np.float32(9.2301666e-11), np.float32(1.0)], [np.float32(0.0012448025), np.float32(0.9987552)], [np.float32(2.5849728e-05), np.float32(0.99997413)], [np.float32(1.8038199e-06), np.float32(0.9999982)], [np.float32(0.6034508), np.float32(0.39654922)], [np.float32(9.587742e-05), np.float32(0.9999041)], [np.float32(0.000784878), np.float32(0.9992151)], [np.float32(0.0040312465), np.float32(0.99596876)], [np.float32(0.0069435653), np.float32(0.9930564)], [np.float32(3.6032976e-05), np.float32(0.99996394)], [np.float32(3.46635e-05), np.float32(0.9999653)], [np.float32(0.0071350797), np.float32(0.9928649)], [np.float32(3.188865e-07), np.float32(0.9999997)], [np.float32(0.0040176613), np.float32(0.99598235)], [np.float32(1.5828065e-05), np.float32(0.99998415)]]\n",
      "Unseen set\n",
      "      ID        Dx         % Mel     % Nev\n",
      "0      0  Melanoma  9.749831e-01  0.025017\n",
      "1      1  Melanoma  9.994251e-01  0.000575\n",
      "2      2  Melanoma  9.999303e-01  0.000070\n",
      "3      3  Melanoma  9.993832e-01  0.000617\n",
      "4      4  Melanoma  9.858206e-01  0.014179\n",
      "..   ...       ...           ...       ...\n",
      "395  395     Nevus  3.466350e-05  0.999965\n",
      "396  396     Nevus  7.135080e-03  0.992865\n",
      "397  397     Nevus  3.188865e-07  1.000000\n",
      "398  398     Nevus  4.017661e-03  0.995982\n",
      "399  399     Nevus  1.582807e-05  0.999984\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
