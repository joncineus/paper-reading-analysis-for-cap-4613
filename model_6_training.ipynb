{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 6 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 22:39:39.109597: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 22:39:39.123114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756593579.141139    6954 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756593579.146145    6954 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756593579.157739    6954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593579.157762    6954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593579.157764    6954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593579.157766    6954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-30 22:39:39.161551: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently training on seed: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "learning rate: 6.3e-03\n",
      "num_dense_nodes: 155\n",
      "dropout: 0.5285541302186968\n",
      "optimizer_type: SGD\n",
      "epochs: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755999063.627198  116812 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755999088.164284  117616 service.cc:152] XLA service 0x7f09b0001a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755999088.164316  117616 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-24 01:31:28.917410: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755999091.652230  117616 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "2025-08-24 01:31:39.804473: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:31:39.951957: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:31:40.303127: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:31:40.446796: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/52\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:27\u001b[0m 52s/step - accuracy: 0.4375 - loss: 0.7627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755999119.480332  117616 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6722 - loss: 0.6136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 01:32:15.084564: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:32:15.230959: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:32:15.552638: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 01:32:15.696056: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 917ms/step - accuracy: 0.7464 - loss: 0.5198 - val_accuracy: 0.6377 - val_loss: 0.6864\n",
      "Epoch 2/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8261 - loss: 0.3811 - val_accuracy: 0.8176 - val_loss: 0.4074\n",
      "Epoch 3/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 165ms/step - accuracy: 0.8539 - loss: 0.3301 - val_accuracy: 0.8575 - val_loss: 0.3425\n",
      "Epoch 4/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8925 - loss: 0.2644 - val_accuracy: 0.6969 - val_loss: 0.6195\n",
      "Epoch 5/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9287 - loss: 0.1771 - val_accuracy: 0.8635 - val_loss: 0.4108\n",
      "Epoch 6/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9275 - loss: 0.1916 - val_accuracy: 0.7645 - val_loss: 0.6901\n",
      "Epoch 7/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9432 - loss: 0.1426 - val_accuracy: 0.8478 - val_loss: 0.4181\n",
      "Epoch 8/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9577 - loss: 0.1230 - val_accuracy: 0.8587 - val_loss: 0.5538\n",
      "Epoch 9/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.9505 - loss: 0.1265 - val_accuracy: 0.7512 - val_loss: 0.7121\n",
      "Epoch 10/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9662 - loss: 0.0939 - val_accuracy: 0.8575 - val_loss: 0.7037\n",
      "Epoch 11/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.9819 - loss: 0.0630 - val_accuracy: 0.8708 - val_loss: 0.4217\n",
      "Epoch 12/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9577 - loss: 0.1234 - val_accuracy: 0.8357 - val_loss: 0.5602\n",
      "Epoch 13/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9903 - loss: 0.0471 - val_accuracy: 0.8200 - val_loss: 0.6239\n",
      "Epoch 14/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9734 - loss: 0.1183 - val_accuracy: 0.8647 - val_loss: 0.3939\n",
      "Epoch 15/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9795 - loss: 0.0596 - val_accuracy: 0.8599 - val_loss: 0.4620\n",
      "Epoch 16/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9807 - loss: 0.0687 - val_accuracy: 0.8406 - val_loss: 0.4437\n",
      "Epoch 17/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9915 - loss: 0.0244 - val_accuracy: 0.8551 - val_loss: 0.5868\n",
      "Epoch 18/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9940 - loss: 0.0213 - val_accuracy: 0.8406 - val_loss: 0.5485\n",
      "Epoch 19/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.8804 - val_loss: 0.4802\n",
      "\n",
      "Accuracy: 88.04%\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 250.3480\n",
      "Function value obtained: -0.8804\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "learning rate: 2.8e-04\n",
      "num_dense_nodes: 183\n",
      "dropout: 0.7764387889852206\n",
      "optimizer_type: SGD\n",
      "epochs: 14\n",
      "Epoch 1/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 773ms/step - accuracy: 0.5906 - loss: 0.7163 - val_accuracy: 0.6884 - val_loss: 0.5420\n",
      "Epoch 2/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7899 - loss: 0.4462 - val_accuracy: 0.7754 - val_loss: 0.4520\n",
      "Epoch 3/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8345 - loss: 0.3836 - val_accuracy: 0.8273 - val_loss: 0.5331\n",
      "Epoch 4/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8684 - loss: 0.3156 - val_accuracy: 0.8213 - val_loss: 0.4042\n",
      "Epoch 5/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8804 - loss: 0.2787 - val_accuracy: 0.8321 - val_loss: 0.3641\n",
      "Epoch 6/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9070 - loss: 0.2258 - val_accuracy: 0.8164 - val_loss: 0.4582\n",
      "Epoch 7/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9517 - loss: 0.1438 - val_accuracy: 0.8333 - val_loss: 0.4928\n",
      "Epoch 8/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9420 - loss: 0.1628 - val_accuracy: 0.7440 - val_loss: 1.2084\n",
      "Epoch 9/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9469 - loss: 0.1513 - val_accuracy: 0.6655 - val_loss: 2.0256\n",
      "Epoch 10/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9565 - loss: 0.1236 - val_accuracy: 0.6812 - val_loss: 1.3533\n",
      "Epoch 11/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9614 - loss: 0.1054 - val_accuracy: 0.8430 - val_loss: 0.4477\n",
      "Epoch 12/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9626 - loss: 0.1058 - val_accuracy: 0.8297 - val_loss: 0.5496\n",
      "Epoch 13/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9758 - loss: 0.0629 - val_accuracy: 0.8418 - val_loss: 0.6012\n",
      "Epoch 14/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9867 - loss: 0.0427 - val_accuracy: 0.8563 - val_loss: 0.7707\n",
      "\n",
      "Accuracy: 85.63%\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 188.4537\n",
      "Function value obtained: -0.8563\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "learning rate: 1.7e-03\n",
      "num_dense_nodes: 181\n",
      "dropout: 0.17263589396854986\n",
      "optimizer_type: SGD\n",
      "epochs: 11\n",
      "Epoch 1/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 772ms/step - accuracy: 0.7379 - loss: 0.4978 - val_accuracy: 0.7355 - val_loss: 0.5263\n",
      "Epoch 2/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8551 - loss: 0.3255 - val_accuracy: 0.7343 - val_loss: 0.5257\n",
      "Epoch 3/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - accuracy: 0.9046 - loss: 0.2301 - val_accuracy: 0.8418 - val_loss: 0.3752\n",
      "Epoch 4/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9481 - loss: 0.1530 - val_accuracy: 0.8430 - val_loss: 0.4600\n",
      "Epoch 5/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9481 - loss: 0.1407 - val_accuracy: 0.7995 - val_loss: 0.5138\n",
      "Epoch 6/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9432 - loss: 0.1608 - val_accuracy: 0.8370 - val_loss: 0.4449\n",
      "Epoch 7/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9662 - loss: 0.0858 - val_accuracy: 0.7935 - val_loss: 0.6527\n",
      "Epoch 8/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9879 - loss: 0.0388 - val_accuracy: 0.8647 - val_loss: 0.4347\n",
      "Epoch 9/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9855 - loss: 0.0453 - val_accuracy: 0.8792 - val_loss: 0.5229\n",
      "Epoch 10/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9807 - loss: 0.0657 - val_accuracy: 0.8394 - val_loss: 0.5825\n",
      "Epoch 11/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9481 - loss: 0.1219 - val_accuracy: 0.6220 - val_loss: 1.2752\n",
      "\n",
      "Accuracy: 62.20%\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 185.8813\n",
      "Function value obtained: -0.6220\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "learning rate: 8.2e-06\n",
      "num_dense_nodes: 114\n",
      "dropout: 0.19429700349786136\n",
      "optimizer_type: SGD\n",
      "epochs: 14\n",
      "Epoch 1/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 789ms/step - accuracy: 0.4758 - loss: 0.7504 - val_accuracy: 0.5338 - val_loss: 0.7199\n",
      "Epoch 2/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.4964 - loss: 0.7326 - val_accuracy: 0.5242 - val_loss: 0.7341\n",
      "Epoch 3/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: 0.7308 - val_accuracy: 0.4903 - val_loss: 0.7340\n",
      "Epoch 4/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5060 - loss: 0.7260 - val_accuracy: 0.5133 - val_loss: 0.7249\n",
      "Epoch 5/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5012 - loss: 0.7187 - val_accuracy: 0.5242 - val_loss: 0.7060\n",
      "Epoch 6/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5592 - loss: 0.6942 - val_accuracy: 0.5435 - val_loss: 0.6962\n",
      "Epoch 7/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5507 - loss: 0.6944 - val_accuracy: 0.5700 - val_loss: 0.6811\n",
      "Epoch 8/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5676 - loss: 0.6885 - val_accuracy: 0.5809 - val_loss: 0.6747\n",
      "Epoch 9/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5749 - loss: 0.6772 - val_accuracy: 0.5918 - val_loss: 0.6697\n",
      "Epoch 10/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5652 - loss: 0.6899 - val_accuracy: 0.6051 - val_loss: 0.6638\n",
      "Epoch 11/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.5773 - loss: 0.6776 - val_accuracy: 0.6147 - val_loss: 0.6585\n",
      "Epoch 12/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5882 - loss: 0.6709 - val_accuracy: 0.6268 - val_loss: 0.6534\n",
      "Epoch 13/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.5882 - loss: 0.6649 - val_accuracy: 0.6316 - val_loss: 0.6485\n",
      "Epoch 14/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.6196 - loss: 0.6445 - val_accuracy: 0.6449 - val_loss: 0.6443\n",
      "\n",
      "Accuracy: 64.49%\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 191.5148\n",
      "Function value obtained: -0.6449\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "learning rate: 3.1e-06\n",
      "num_dense_nodes: 217\n",
      "dropout: 0.21116883235951855\n",
      "optimizer_type: Adam\n",
      "epochs: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 901ms/step - accuracy: 0.5604 - loss: 0.6888 - val_accuracy: 0.5072 - val_loss: 0.7080\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.6522 - loss: 0.6266 - val_accuracy: 0.6208 - val_loss: 0.6493\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7452 - loss: 0.5585 - val_accuracy: 0.6957 - val_loss: 0.5911\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7911 - loss: 0.5133 - val_accuracy: 0.7500 - val_loss: 0.5394\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.8116 - loss: 0.4777 - val_accuracy: 0.7947 - val_loss: 0.4981\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.8176 - loss: 0.4388 - val_accuracy: 0.8019 - val_loss: 0.4667\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.8551 - loss: 0.4047 - val_accuracy: 0.7995 - val_loss: 0.4437\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.8418 - loss: 0.3902 - val_accuracy: 0.8068 - val_loss: 0.4232\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8816 - loss: 0.3473 - val_accuracy: 0.8152 - val_loss: 0.4058\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8816 - loss: 0.3440 - val_accuracy: 0.8213 - val_loss: 0.3921\n",
      "\n",
      "Accuracy: 82.13%\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 188.6642\n",
      "Function value obtained: -0.8213\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "learning rate: 3.6e-06\n",
      "num_dense_nodes: 155\n",
      "dropout: 0.6176183260648371\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 726ms/step - accuracy: 0.5000 - loss: 0.8957 - val_accuracy: 0.5036 - val_loss: 0.8175\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5072 - loss: 0.8582 - val_accuracy: 0.5036 - val_loss: 0.7411\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5133 - loss: 0.7973 - val_accuracy: 0.5580 - val_loss: 0.6917\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5278 - loss: 0.7663 - val_accuracy: 0.5773 - val_loss: 0.6719\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5278 - loss: 0.7378 - val_accuracy: 0.6365 - val_loss: 0.6522\n",
      "\n",
      "Accuracy: 63.65%\n",
      "\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 112.5934\n",
      "Function value obtained: -0.6365\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "learning rate: 7.0e-04\n",
      "num_dense_nodes: 65\n",
      "dropout: 0.49382716817209316\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 755ms/step - accuracy: 0.6522 - loss: 0.6333 - val_accuracy: 0.6123 - val_loss: 0.6407\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8140 - loss: 0.4224 - val_accuracy: 0.8043 - val_loss: 0.4180\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8901 - loss: 0.2951 - val_accuracy: 0.8611 - val_loss: 0.3190\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8937 - loss: 0.2542 - val_accuracy: 0.8587 - val_loss: 0.3707\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9275 - loss: 0.1919 - val_accuracy: 0.8732 - val_loss: 0.3149\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9360 - loss: 0.1842 - val_accuracy: 0.8623 - val_loss: 0.3747\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9626 - loss: 0.1259 - val_accuracy: 0.8671 - val_loss: 0.3523\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9686 - loss: 0.0953 - val_accuracy: 0.8152 - val_loss: 0.5117\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9771 - loss: 0.0695 - val_accuracy: 0.8684 - val_loss: 0.3902\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9819 - loss: 0.0555 - val_accuracy: 0.8539 - val_loss: 0.4650\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9879 - loss: 0.0432 - val_accuracy: 0.8720 - val_loss: 0.3810\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9903 - loss: 0.0398 - val_accuracy: 0.8599 - val_loss: 0.4074\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9843 - loss: 0.0572 - val_accuracy: 0.8671 - val_loss: 0.4160\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9819 - loss: 0.0629 - val_accuracy: 0.8466 - val_loss: 0.4466\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9783 - loss: 0.0914 - val_accuracy: 0.8756 - val_loss: 0.4114\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9807 - loss: 0.0549 - val_accuracy: 0.8671 - val_loss: 0.3516\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9879 - loss: 0.0332 - val_accuracy: 0.8684 - val_loss: 0.3903\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9915 - loss: 0.0283 - val_accuracy: 0.8816 - val_loss: 0.4176\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9928 - loss: 0.0307 - val_accuracy: 0.8720 - val_loss: 0.5111\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9952 - loss: 0.0233 - val_accuracy: 0.8744 - val_loss: 0.4807\n",
      "\n",
      "Accuracy: 87.44%\n",
      "\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 231.5898\n",
      "Function value obtained: -0.8744\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.7807078391620889\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 716ms/step - accuracy: 0.7476 - loss: 0.5439 - val_accuracy: 0.8068 - val_loss: 0.5093\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.7923 - loss: 0.4440 - val_accuracy: 0.7669 - val_loss: 0.4970\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8249 - loss: 0.3603 - val_accuracy: 0.8297 - val_loss: 0.3641\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8587 - loss: 0.3293 - val_accuracy: 0.8333 - val_loss: 0.4115\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8563 - loss: 0.3004 - val_accuracy: 0.7826 - val_loss: 0.4179\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8937 - loss: 0.2391 - val_accuracy: 0.7415 - val_loss: 0.5163\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8865 - loss: 0.2748 - val_accuracy: 0.7246 - val_loss: 0.4989\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.8877 - loss: 0.2774 - val_accuracy: 0.8370 - val_loss: 0.3875\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9263 - loss: 0.1945 - val_accuracy: 0.8418 - val_loss: 0.4116\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9287 - loss: 0.1688 - val_accuracy: 0.8188 - val_loss: 0.4862\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9493 - loss: 0.1519 - val_accuracy: 0.5447 - val_loss: 1.8536\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9444 - loss: 0.1737 - val_accuracy: 0.6655 - val_loss: 1.0045\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9408 - loss: 0.1513 - val_accuracy: 0.8140 - val_loss: 0.4539\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9686 - loss: 0.0866 - val_accuracy: 0.7512 - val_loss: 1.0700\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9758 - loss: 0.0988 - val_accuracy: 0.8647 - val_loss: 0.4795\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9469 - loss: 0.1284 - val_accuracy: 0.7476 - val_loss: 0.6872\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9626 - loss: 0.1043 - val_accuracy: 0.8406 - val_loss: 0.4181\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9915 - loss: 0.0394 - val_accuracy: 0.8430 - val_loss: 1.0284\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9795 - loss: 0.0719 - val_accuracy: 0.7512 - val_loss: 0.8929\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9843 - loss: 0.0462 - val_accuracy: 0.7850 - val_loss: 0.7177\n",
      "\n",
      "Accuracy: 78.50%\n",
      "\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 231.2986\n",
      "Function value obtained: -0.7850\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "learning rate: 2.4e-05\n",
      "num_dense_nodes: 59\n",
      "dropout: 0.6233866980468427\n",
      "optimizer_type: SGD\n",
      "epochs: 16\n",
      "Epoch 1/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 717ms/step - accuracy: 0.5060 - loss: 0.8073 - val_accuracy: 0.5097 - val_loss: 0.7217\n",
      "Epoch 2/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5833 - loss: 0.6828 - val_accuracy: 0.5652 - val_loss: 0.6722\n",
      "Epoch 3/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.6486 - loss: 0.6212 - val_accuracy: 0.6739 - val_loss: 0.6048\n",
      "Epoch 4/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7403 - loss: 0.5534 - val_accuracy: 0.7705 - val_loss: 0.5313\n",
      "Epoch 5/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7645 - loss: 0.5153 - val_accuracy: 0.7947 - val_loss: 0.4768\n",
      "Epoch 6/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8128 - loss: 0.4579 - val_accuracy: 0.8188 - val_loss: 0.4359\n",
      "Epoch 7/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8056 - loss: 0.4497 - val_accuracy: 0.8225 - val_loss: 0.4083\n",
      "Epoch 8/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.7983 - loss: 0.4271 - val_accuracy: 0.8333 - val_loss: 0.3863\n",
      "Epoch 9/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8430 - loss: 0.3745 - val_accuracy: 0.8382 - val_loss: 0.3703\n",
      "Epoch 10/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8502 - loss: 0.3530 - val_accuracy: 0.8514 - val_loss: 0.3596\n",
      "Epoch 11/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8394 - loss: 0.3601 - val_accuracy: 0.8454 - val_loss: 0.3522\n",
      "Epoch 12/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.8551 - loss: 0.3275 - val_accuracy: 0.8442 - val_loss: 0.3461\n",
      "Epoch 13/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8744 - loss: 0.3159 - val_accuracy: 0.8490 - val_loss: 0.3390\n",
      "Epoch 14/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8829 - loss: 0.3081 - val_accuracy: 0.8454 - val_loss: 0.3358\n",
      "Epoch 15/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.8816 - loss: 0.2858 - val_accuracy: 0.8430 - val_loss: 0.3335\n",
      "Epoch 16/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9058 - loss: 0.2545 - val_accuracy: 0.8454 - val_loss: 0.3308\n",
      "\n",
      "Accuracy: 84.54%\n",
      "\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 199.5008\n",
      "Function value obtained: -0.8454\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "learning rate: 4.8e-03\n",
      "num_dense_nodes: 184\n",
      "dropout: 0.18863896188041598\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 846ms/step - accuracy: 0.5193 - loss: 1.0666 - val_accuracy: 0.5000 - val_loss: 1702603008.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5556 - loss: 0.6660 - val_accuracy: 0.5000 - val_loss: 3172.0830\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5628 - loss: 0.6920 - val_accuracy: 0.6969 - val_loss: 13.4498\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.6401 - loss: 0.6326 - val_accuracy: 0.7778 - val_loss: 213.0649\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6413 - loss: 0.6350 - val_accuracy: 0.7307 - val_loss: 379.3428\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6739 - loss: 0.6021 - val_accuracy: 0.5857 - val_loss: 13.2954\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6896 - loss: 0.6005 - val_accuracy: 0.6473 - val_loss: 0.6263\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.7415 - loss: 0.5531 - val_accuracy: 0.5000 - val_loss: 2046.7815\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7585 - loss: 0.5168 - val_accuracy: 0.4964 - val_loss: 94.3990\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7850 - loss: 0.5084 - val_accuracy: 0.4348 - val_loss: 8.3662\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7814 - loss: 0.4866 - val_accuracy: 0.6872 - val_loss: 0.6072\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7778 - loss: 0.4804 - val_accuracy: 0.7476 - val_loss: 0.5823\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7766 - loss: 0.4628 - val_accuracy: 0.5447 - val_loss: 4.4085\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7790 - loss: 0.4795 - val_accuracy: 0.7452 - val_loss: 1.7533\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7850 - loss: 0.4985 - val_accuracy: 0.7065 - val_loss: 1.2899\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8043 - loss: 0.4336 - val_accuracy: 0.7995 - val_loss: 0.5165\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7947 - loss: 0.4098 - val_accuracy: 0.7862 - val_loss: 0.8348\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7838 - loss: 0.4313 - val_accuracy: 0.5193 - val_loss: 0.6912\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.7959 - loss: 0.4154 - val_accuracy: 0.7572 - val_loss: 0.7985\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8056 - loss: 0.4173 - val_accuracy: 0.6208 - val_loss: 0.7538\n",
      "\n",
      "Accuracy: 62.08%\n",
      "\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 258.9835\n",
      "Function value obtained: -0.6208\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "learning rate: 2.0e-05\n",
      "num_dense_nodes: 219\n",
      "dropout: 0.40733191368921173\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 835ms/step - accuracy: 0.6630 - loss: 0.6180 - val_accuracy: 0.5990 - val_loss: 0.6628\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8490 - loss: 0.3771 - val_accuracy: 0.7319 - val_loss: 0.5409\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8611 - loss: 0.3208 - val_accuracy: 0.7899 - val_loss: 0.4418\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9010 - loss: 0.2361 - val_accuracy: 0.8430 - val_loss: 0.3734\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9312 - loss: 0.1848 - val_accuracy: 0.8563 - val_loss: 0.3455\n",
      "\n",
      "Accuracy: 85.63%\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 136.7176\n",
      "Function value obtained: -0.8563\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "learning rate: 1.9e-03\n",
      "num_dense_nodes: 53\n",
      "dropout: 0.11806227271741757\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 887ms/step - accuracy: 0.7258 - loss: 0.6320 - val_accuracy: 0.5000 - val_loss: 162229.3281\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6353 - loss: 0.6147 - val_accuracy: 0.5000 - val_loss: 676109.0625\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6159 - loss: 0.6220 - val_accuracy: 0.5193 - val_loss: 11840.2695\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.7355 - loss: 0.5381 - val_accuracy: 0.7222 - val_loss: 156.0797\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7415 - loss: 0.5189 - val_accuracy: 0.8116 - val_loss: 0.4711\n",
      "\n",
      "Accuracy: 81.16%\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 142.1639\n",
      "Function value obtained: -0.8116\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "learning rate: 6.9e-05\n",
      "num_dense_nodes: 154\n",
      "dropout: 0.7160678239749436\n",
      "optimizer_type: Adam\n",
      "epochs: 6\n",
      "Epoch 1/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 865ms/step - accuracy: 0.6787 - loss: 0.5900 - val_accuracy: 0.6751 - val_loss: 0.5926\n",
      "Epoch 2/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8490 - loss: 0.3591 - val_accuracy: 0.8213 - val_loss: 0.3775\n",
      "Epoch 3/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9179 - loss: 0.2244 - val_accuracy: 0.8502 - val_loss: 0.3846\n",
      "Epoch 4/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9517 - loss: 0.1576 - val_accuracy: 0.8708 - val_loss: 0.3872\n",
      "Epoch 5/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9795 - loss: 0.0769 - val_accuracy: 0.8671 - val_loss: 0.4703\n",
      "Epoch 6/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9746 - loss: 0.0617 - val_accuracy: 0.8684 - val_loss: 0.5147\n",
      "\n",
      "Accuracy: 86.84%\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 148.1821\n",
      "Function value obtained: -0.8684\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "learning rate: 4.7e-06\n",
      "num_dense_nodes: 176\n",
      "dropout: 0.6025533395398094\n",
      "optimizer_type: Adam\n",
      "epochs: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 855ms/step - accuracy: 0.5568 - loss: 0.7164 - val_accuracy: 0.5399 - val_loss: 0.7102\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6329 - loss: 0.6557 - val_accuracy: 0.6401 - val_loss: 0.6160\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.6969 - loss: 0.5881 - val_accuracy: 0.7053 - val_loss: 0.5590\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.7150 - loss: 0.5618 - val_accuracy: 0.7536 - val_loss: 0.5148\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7802 - loss: 0.4859 - val_accuracy: 0.7850 - val_loss: 0.4772\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.7790 - loss: 0.4694 - val_accuracy: 0.8080 - val_loss: 0.4451\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8128 - loss: 0.4354 - val_accuracy: 0.8345 - val_loss: 0.4175\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8333 - loss: 0.4034 - val_accuracy: 0.8394 - val_loss: 0.3969\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8466 - loss: 0.3686 - val_accuracy: 0.8382 - val_loss: 0.3824\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8563 - loss: 0.3520 - val_accuracy: 0.8394 - val_loss: 0.3724\n",
      "\n",
      "Accuracy: 83.94%\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 182.7535\n",
      "Function value obtained: -0.8394\n",
      "Current minimum: -0.8804\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "learning rate: 5.3e-03\n",
      "num_dense_nodes: 123\n",
      "dropout: 0.8\n",
      "optimizer_type: Adam\n",
      "epochs: 16\n",
      "Epoch 1/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 902ms/step - accuracy: 0.5290 - loss: 1.2429 - val_accuracy: 0.5000 - val_loss: 29592291115008.0000\n",
      "Epoch 2/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5109 - loss: 0.8358 - val_accuracy: 0.5000 - val_loss: 573210.5625\n",
      "Epoch 3/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5012 - loss: 0.6833 - val_accuracy: 0.5109 - val_loss: 1373.1823\n",
      "Epoch 4/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5447 - loss: 0.6981 - val_accuracy: 0.5978 - val_loss: 13.1245\n",
      "Epoch 5/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5169 - loss: 0.6939 - val_accuracy: 0.5495 - val_loss: 2.6850\n",
      "Epoch 6/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5169 - loss: 0.7014 - val_accuracy: 0.6111 - val_loss: 1.0078\n",
      "Epoch 7/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5000 - loss: 0.6941 - val_accuracy: 0.6063 - val_loss: 0.9709\n",
      "Epoch 8/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4976 - loss: 0.6954 - val_accuracy: 0.5411 - val_loss: 0.6987\n",
      "Epoch 9/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5133 - loss: 0.6918 - val_accuracy: 0.5350 - val_loss: 0.7178\n",
      "Epoch 10/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5121 - loss: 0.6922 - val_accuracy: 0.7198 - val_loss: 8.0170\n",
      "Epoch 11/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4807 - loss: 0.6927 - val_accuracy: 0.7198 - val_loss: 4.9230\n",
      "Epoch 12/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5024 - loss: 0.6952 - val_accuracy: 0.7536 - val_loss: 29.2646\n",
      "Epoch 13/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4771 - loss: 0.6947 - val_accuracy: 0.4843 - val_loss: 0.7045\n",
      "Epoch 14/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4734 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 1.3360\n",
      "Epoch 15/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4819 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 16/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4952 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 230.4855\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8804\n",
      "Seed:  5\n",
      "BEST ACCURACY:  {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.8804348111152649, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0}\n",
      "hyper_params  [0.0063107062439323545, 0.5285541302186968, 0.8529056339857591, 0.986762523875516, 0.9947422657149726, np.int64(19), np.int64(155), 'SGD']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 5\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 22:40:48.281198: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 5\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756593708.104064    8604 service.cc:152] XLA service 0x7f81b4055930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756593708.104102    8604 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-08-30 22:41:48.177159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756593710.050550    8604 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step \n",
      "[[np.float32(0.61474705), np.float32(0.38525295)], [np.float32(0.9999975), np.float32(2.503395e-06)], [np.float32(0.99987113), np.float32(0.00012886524)], [np.float32(0.999985), np.float32(1.50203705e-05)], [np.float32(0.0032033967), np.float32(0.9967966)], [np.float32(0.9997533), np.float32(0.00024670362)], [np.float32(0.99908054), np.float32(0.00091946125)], [np.float32(0.9909016), np.float32(0.009098411)], [np.float32(0.9999697), np.float32(3.027916e-05)], [np.float32(0.9396838), np.float32(0.060316205)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.9992655), np.float32(0.00073450804)], [np.float32(0.9999726), np.float32(2.7418137e-05)], [np.float32(0.9974623), np.float32(0.0025377274)], [np.float32(0.948442), np.float32(0.051558018)], [np.float32(0.109600656), np.float32(0.89039934)], [np.float32(0.9911761), np.float32(0.008823872)], [np.float32(0.9185669), np.float32(0.08143312)], [np.float32(0.99594766), np.float32(0.004052341)], [np.float32(0.92061776), np.float32(0.07938224)], [np.float32(0.96598655), np.float32(0.03401345)], [np.float32(0.0032495016), np.float32(0.9967505)], [np.float32(0.9949892), np.float32(0.0050107837)], [np.float32(0.53295904), np.float32(0.46704096)], [np.float32(0.9995204), np.float32(0.00047957897)], [np.float32(0.9524684), np.float32(0.047531605)], [np.float32(0.9977956), np.float32(0.0022044182)], [np.float32(0.9888821), np.float32(0.011117876)], [np.float32(0.35648936), np.float32(0.64351064)], [np.float32(0.99999833), np.float32(1.66893e-06)], [np.float32(0.99961346), np.float32(0.00038653612)], [np.float32(0.99228597), np.float32(0.007714033)], [np.float32(0.9835202), np.float32(0.01647979)], [np.float32(0.99832124), np.float32(0.0016787648)], [np.float32(0.45424667), np.float32(0.54575336)], [np.float32(0.9460519), np.float32(0.053948104)], [np.float32(0.9998524), np.float32(0.0001475811)], [np.float32(0.99974054), np.float32(0.00025945902)], [np.float32(0.9985291), np.float32(0.0014709234)], [np.float32(0.8701187), np.float32(0.12988132)], [np.float32(0.9971896), np.float32(0.0028104186)], [np.float32(0.9999956), np.float32(4.4107437e-06)], [np.float32(0.98286545), np.float32(0.017134547)], [np.float32(0.8544284), np.float32(0.14557159)], [np.float32(0.99999857), np.float32(1.4305115e-06)], [np.float32(0.7645466), np.float32(0.23545343)], [np.float32(0.99997854), np.float32(2.1457672e-05)], [np.float32(0.018768175), np.float32(0.9812318)], [np.float32(0.74516404), np.float32(0.25483596)], [np.float32(0.99765426), np.float32(0.0023457408)], [np.float32(0.99990594), np.float32(9.405613e-05)], [np.float32(0.0029240334), np.float32(0.997076)], [np.float32(0.9999541), np.float32(4.5895576e-05)], [np.float32(0.9835581), np.float32(0.016441882)], [np.float32(0.99257773), np.float32(0.0074222684)], [np.float32(0.9999207), np.float32(7.927418e-05)], [np.float32(0.99868053), np.float32(0.001319468)], [np.float32(0.0072886874), np.float32(0.9927113)], [np.float32(0.99965847), np.float32(0.00034153461)], [np.float32(0.9999695), np.float32(3.0517578e-05)], [np.float32(0.90768737), np.float32(0.092312634)], [np.float32(0.9966234), np.float32(0.0033766031)], [np.float32(0.9593633), np.float32(0.04063672)], [np.float32(0.9973374), np.float32(0.002662599)], [np.float32(0.99951935), np.float32(0.00048065186)], [np.float32(0.9999802), np.float32(1.9788742e-05)], [np.float32(0.9895499), np.float32(0.010450125)], [np.float32(0.28015223), np.float32(0.7198478)], [np.float32(0.9991456), np.float32(0.000854373)], [np.float32(0.757783), np.float32(0.242217)], [np.float32(0.99741757), np.float32(0.0025824308)], [np.float32(0.99992967), np.float32(7.033348e-05)], [np.float32(0.9999763), np.float32(2.3722649e-05)], [np.float32(0.29340705), np.float32(0.7065929)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.99888283), np.float32(0.0011171699)], [np.float32(0.90503216), np.float32(0.09496784)], [np.float32(0.9271384), np.float32(0.07286161)], [np.float32(0.99972004), np.float32(0.00027996302)], [np.float32(0.9920666), np.float32(0.007933378)], [np.float32(0.9999697), np.float32(3.027916e-05)], [np.float32(0.9999989), np.float32(1.0728836e-06)], [np.float32(0.54066306), np.float32(0.45933694)], [np.float32(0.9895929), np.float32(0.01040709)], [np.float32(0.9885676), np.float32(0.011432409)], [np.float32(0.9999988), np.float32(1.1920929e-06)], [np.float32(0.9998374), np.float32(0.00016260147)], [np.float32(0.9874858), np.float32(0.012514174)], [np.float32(0.99641466), np.float32(0.0035853386)], [np.float32(0.997619), np.float32(0.0023810267)], [np.float32(0.95965815), np.float32(0.040341854)], [np.float32(0.2217961), np.float32(0.7782039)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.023121057), np.float32(0.97687894)], [np.float32(0.9974426), np.float32(0.002557397)], [np.float32(0.6565027), np.float32(0.34349728)], [np.float32(0.99999845), np.float32(1.5497208e-06)], [np.float32(0.9978193), np.float32(0.0021806955)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.97321624), np.float32(0.026783764)], [np.float32(0.981805), np.float32(0.018194973)], [np.float32(0.8990999), np.float32(0.10090011)], [np.float32(0.99864596), np.float32(0.0013540387)], [np.float32(0.92968345), np.float32(0.07031655)], [np.float32(0.9436179), np.float32(0.05638212)], [np.float32(0.41573876), np.float32(0.58426124)], [np.float32(0.99998), np.float32(2.002716e-05)], [np.float32(0.99999774), np.float32(2.2649765e-06)], [np.float32(0.96968925), np.float32(0.03031075)], [np.float32(0.73196876), np.float32(0.26803124)], [np.float32(0.99969816), np.float32(0.00030183792)], [np.float32(0.99791807), np.float32(0.0020819306)], [np.float32(0.9225311), np.float32(0.07746887)], [np.float32(0.97651654), np.float32(0.023483455)], [np.float32(0.98943895), np.float32(0.010561049)], [np.float32(0.9978607), np.float32(0.0021392703)], [np.float32(0.99952555), np.float32(0.00047445297)], [np.float32(0.031695757), np.float32(0.9683042)], [np.float32(0.993842), np.float32(0.0061579943)], [np.float32(0.51779044), np.float32(0.48220956)], [np.float32(0.50999415), np.float32(0.49000585)], [np.float32(0.9893875), np.float32(0.010612488)], [np.float32(0.9997191), np.float32(0.0002809167)], [np.float32(0.9933694), np.float32(0.0066305995)], [np.float32(0.91462624), np.float32(0.08537376)], [np.float32(0.99968827), np.float32(0.0003117323)], [np.float32(0.9922616), np.float32(0.0077384114)], [np.float32(0.9999893), np.float32(1.0728836e-05)], [np.float32(0.99997354), np.float32(2.6464462e-05)], [np.float32(0.9609819), np.float32(0.039018095)], [np.float32(0.027119858), np.float32(0.9728801)], [np.float32(0.99996936), np.float32(3.0636787e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99983656), np.float32(0.00016343594)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99997604), np.float32(2.3961067e-05)], [np.float32(0.9860481), np.float32(0.013951898)], [np.float32(0.9844439), np.float32(0.015556097)], [np.float32(0.9999089), np.float32(9.10759e-05)], [np.float32(0.9942932), np.float32(0.005706787)], [np.float32(0.9997919), np.float32(0.00020807981)], [np.float32(0.99771404), np.float32(0.0022859573)], [np.float32(0.9999522), np.float32(4.7802925e-05)], [np.float32(0.9970498), np.float32(0.0029501915)], [np.float32(0.9995047), np.float32(0.0004953146)], [np.float32(0.98409975), np.float32(0.015900254)], [np.float32(0.99589086), np.float32(0.004109144)], [np.float32(0.99923503), np.float32(0.000764966)], [np.float32(0.999508), np.float32(0.00049197674)], [np.float32(0.9992853), np.float32(0.0007147193)], [np.float32(0.9983962), np.float32(0.0016037822)], [np.float32(0.043821976), np.float32(0.956178)], [np.float32(0.99987495), np.float32(0.00012505054)], [np.float32(0.9933693), np.float32(0.0066307187)], [np.float32(0.52609926), np.float32(0.47390074)], [np.float32(0.99991775), np.float32(8.225441e-05)], [np.float32(0.9997012), np.float32(0.00029879808)], [np.float32(0.99995196), np.float32(4.8041344e-05)], [np.float32(0.99650264), np.float32(0.0034973621)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.98100317), np.float32(0.018996835)], [np.float32(0.99998295), np.float32(1.7046928e-05)], [np.float32(0.9999995), np.float32(4.7683716e-07)], [np.float32(0.57426107), np.float32(0.42573893)], [np.float32(0.9999902), np.float32(9.775162e-06)], [np.float32(0.99342704), np.float32(0.006572962)], [np.float32(0.9998989), np.float32(0.00010108948)], [np.float32(0.99307114), np.float32(0.006928861)], [np.float32(0.9917454), np.float32(0.008254588)], [np.float32(0.99999905), np.float32(9.536743e-07)], [np.float32(0.9998123), np.float32(0.00018769503)], [np.float32(0.8905729), np.float32(0.109427094)], [np.float32(0.9779921), np.float32(0.022007883)], [np.float32(0.93582654), np.float32(0.06417346)], [np.float32(0.99839216), np.float32(0.0016078353)], [np.float32(0.9997881), np.float32(0.00021189451)], [np.float32(0.9870228), np.float32(0.012977183)], [np.float32(0.99997973), np.float32(2.026558e-05)], [np.float32(0.9999927), np.float32(7.2717667e-06)], [np.float32(0.93142325), np.float32(0.06857675)], [np.float32(0.19379975), np.float32(0.80620027)], [np.float32(0.99057555), np.float32(0.009424448)], [np.float32(0.9015623), np.float32(0.09843773)], [np.float32(0.99975854), np.float32(0.00024145842)], [np.float32(0.9999993), np.float32(7.1525574e-07)], [np.float32(0.24887244), np.float32(0.75112754)], [np.float32(0.29294297), np.float32(0.707057)], [np.float32(0.2764063), np.float32(0.7235937)], [np.float32(0.9999993), np.float32(7.1525574e-07)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99971074), np.float32(0.00028926134)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.99999), np.float32(1.001358e-05)], [np.float32(0.99999285), np.float32(7.1525574e-06)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99997234), np.float32(2.7656555e-05)], [np.float32(0.9997769), np.float32(0.00022310019)], [np.float32(0.1680665), np.float32(0.8319335)], [np.float32(0.99786747), np.float32(0.002132535)], [np.float32(0.99986935), np.float32(0.00013065338)], [np.float32(1.0213506e-07), np.float32(0.9999999)], [np.float32(7.7297596e-16), np.float32(1.0)], [np.float32(0.1341699), np.float32(0.86583006)], [np.float32(0.98755497), np.float32(0.012445033)], [np.float32(1.0265809e-15), np.float32(1.0)], [np.float32(1.742623e-05), np.float32(0.9999826)], [np.float32(0.0016865082), np.float32(0.9983135)], [np.float32(0.02899663), np.float32(0.97100335)], [np.float32(3.1349676e-10), np.float32(1.0)], [np.float32(6.204288e-12), np.float32(1.0)], [np.float32(0.07921664), np.float32(0.92078334)], [np.float32(0.23417601), np.float32(0.76582396)], [np.float32(0.0010944506), np.float32(0.99890554)], [np.float32(0.97175074), np.float32(0.028249264)], [np.float32(8.6827676e-08), np.float32(0.99999994)], [np.float32(1.3384896e-08), np.float32(1.0)], [np.float32(7.082466e-08), np.float32(0.99999994)], [np.float32(1.5452173e-07), np.float32(0.9999998)], [np.float32(0.007097604), np.float32(0.9929024)], [np.float32(2.5564526e-07), np.float32(0.99999976)], [np.float32(0.00046048078), np.float32(0.9995395)], [np.float32(0.00044428444), np.float32(0.9995557)], [np.float32(0.19228667), np.float32(0.8077133)], [np.float32(0.14415343), np.float32(0.8558466)], [np.float32(2.5404139e-05), np.float32(0.9999746)], [np.float32(0.9088036), np.float32(0.09119642)], [np.float32(0.99796706), np.float32(0.0020329356)], [np.float32(0.00019333167), np.float32(0.99980664)], [np.float32(0.9995055), np.float32(0.00049448013)], [np.float32(0.06947388), np.float32(0.93052614)], [np.float32(0.49848813), np.float32(0.5015119)], [np.float32(0.9848663), np.float32(0.015133679)], [np.float32(0.00013189211), np.float32(0.9998681)], [np.float32(0.000587566), np.float32(0.9994124)], [np.float32(0.7164513), np.float32(0.2835487)], [np.float32(0.0006000312), np.float32(0.99939996)], [np.float32(3.8704556e-12), np.float32(1.0)], [np.float32(0.00736667), np.float32(0.99263334)], [np.float32(1.1625312e-07), np.float32(0.9999999)], [np.float32(1.6818594e-05), np.float32(0.9999832)], [np.float32(0.027971126), np.float32(0.97202885)], [np.float32(7.802081e-05), np.float32(0.999922)], [np.float32(0.022355275), np.float32(0.97764474)], [np.float32(0.0014113864), np.float32(0.9985886)], [np.float32(2.6570935e-06), np.float32(0.9999973)], [np.float32(0.11015971), np.float32(0.8898403)], [np.float32(2.4363807e-09), np.float32(1.0)], [np.float32(0.985036), np.float32(0.0149639845)], [np.float32(1.1893759e-09), np.float32(1.0)], [np.float32(0.00083923514), np.float32(0.99916077)], [np.float32(1.5931742e-05), np.float32(0.9999841)], [np.float32(3.2311178e-05), np.float32(0.9999677)], [np.float32(0.00036067958), np.float32(0.99963933)], [np.float32(0.0025981066), np.float32(0.9974019)], [np.float32(0.005228804), np.float32(0.9947712)], [np.float32(2.8535269e-05), np.float32(0.99997145)], [np.float32(0.00048404397), np.float32(0.99951595)], [np.float32(2.4019551e-20), np.float32(1.0)], [np.float32(0.102376655), np.float32(0.89762336)], [np.float32(0.9740431), np.float32(0.025956929)], [np.float32(0.00022268116), np.float32(0.9997773)], [np.float32(0.0013127725), np.float32(0.9986872)], [np.float32(0.00010372931), np.float32(0.9998963)], [np.float32(0.006480356), np.float32(0.99351966)], [np.float32(1.3229232e-05), np.float32(0.99998677)], [np.float32(0.00019452618), np.float32(0.99980545)], [np.float32(8.6023746e-08), np.float32(0.99999994)], [np.float32(0.0004631741), np.float32(0.9995368)], [np.float32(0.00013761788), np.float32(0.9998624)], [np.float32(7.6972984e-10), np.float32(1.0)], [np.float32(0.8131615), np.float32(0.18683851)], [np.float32(2.717429e-06), np.float32(0.99999726)], [np.float32(0.28648376), np.float32(0.71351624)], [np.float32(1.1648545e-10), np.float32(1.0)], [np.float32(0.00080536277), np.float32(0.9991946)], [np.float32(0.028194495), np.float32(0.9718055)], [np.float32(1.3207776e-05), np.float32(0.99998677)], [np.float32(1.051959e-06), np.float32(0.9999989)], [np.float32(2.001904e-05), np.float32(0.99998)], [np.float32(0.03024627), np.float32(0.96975374)], [np.float32(0.7362137), np.float32(0.26378632)], [np.float32(2.209142e-08), np.float32(1.0)], [np.float32(0.010333219), np.float32(0.98966676)], [np.float32(0.008123334), np.float32(0.99187666)], [np.float32(8.793724e-07), np.float32(0.9999991)], [np.float32(0.95914614), np.float32(0.040853858)], [np.float32(5.5434107e-08), np.float32(0.99999994)], [np.float32(7.99044e-10), np.float32(1.0)], [np.float32(0.0002524369), np.float32(0.9997476)], [np.float32(1.900996e-11), np.float32(1.0)], [np.float32(0.011934265), np.float32(0.9880657)], [np.float32(0.00032036484), np.float32(0.9996796)], [np.float32(1.643696e-13), np.float32(1.0)], [np.float32(0.08573905), np.float32(0.914261)], [np.float32(4.8402762e-06), np.float32(0.9999952)], [np.float32(6.94042e-08), np.float32(0.99999994)], [np.float32(6.9726135e-05), np.float32(0.99993026)], [np.float32(4.0986015e-05), np.float32(0.999959)], [np.float32(3.4580125e-07), np.float32(0.99999964)], [np.float32(6.7864676e-05), np.float32(0.9999321)], [np.float32(0.006671699), np.float32(0.9933283)], [np.float32(2.0111423e-07), np.float32(0.9999998)], [np.float32(3.2105416e-10), np.float32(1.0)], [np.float32(5.6228787e-06), np.float32(0.9999944)], [np.float32(0.005170151), np.float32(0.99482983)], [np.float32(7.572848e-10), np.float32(1.0)], [np.float32(0.016156428), np.float32(0.98384356)], [np.float32(3.361037e-08), np.float32(0.99999994)], [np.float32(5.8878624e-13), np.float32(1.0)], [np.float32(2.6412499e-08), np.float32(1.0)], [np.float32(0.043402668), np.float32(0.9565973)], [np.float32(4.877922e-10), np.float32(1.0)], [np.float32(2.3511872e-07), np.float32(0.99999976)], [np.float32(3.8432132e-05), np.float32(0.99996156)], [np.float32(6.284887e-08), np.float32(0.99999994)], [np.float32(0.0024419937), np.float32(0.997558)], [np.float32(0.27981105), np.float32(0.720189)], [np.float32(2.8696974e-08), np.float32(1.0)], [np.float32(8.3430496e-07), np.float32(0.99999917)], [np.float32(2.0583359e-10), np.float32(1.0)], [np.float32(1.1172689e-08), np.float32(1.0)], [np.float32(0.9593478), np.float32(0.040652215)], [np.float32(0.0017809685), np.float32(0.998219)], [np.float32(0.020423342), np.float32(0.97957665)], [np.float32(0.0016466265), np.float32(0.99835336)], [np.float32(0.0004689296), np.float32(0.9995311)], [np.float32(7.2465883e-13), np.float32(1.0)], [np.float32(1.6783216e-10), np.float32(1.0)], [np.float32(1.1486247e-05), np.float32(0.9999885)], [np.float32(0.0047296933), np.float32(0.9952703)], [np.float32(0.00012411892), np.float32(0.9998759)], [np.float32(2.8155563e-08), np.float32(1.0)], [np.float32(2.2578364e-05), np.float32(0.9999774)], [np.float32(0.00017965057), np.float32(0.99982035)], [np.float32(0.019262007), np.float32(0.980738)], [np.float32(0.0007754664), np.float32(0.99922454)], [np.float32(0.43031824), np.float32(0.56968176)], [np.float32(0.00017405073), np.float32(0.99982595)], [np.float32(0.016330512), np.float32(0.98366946)], [np.float32(1.0916689e-11), np.float32(1.0)], [np.float32(0.0023162025), np.float32(0.9976838)], [np.float32(9.574283e-08), np.float32(0.9999999)], [np.float32(0.6800132), np.float32(0.31998682)], [np.float32(0.022652695), np.float32(0.9773473)], [np.float32(0.95320857), np.float32(0.046791434)], [np.float32(0.9797223), np.float32(0.020277679)], [np.float32(0.0032253575), np.float32(0.9967746)], [np.float32(4.20115e-05), np.float32(0.999958)], [np.float32(0.00092314364), np.float32(0.99907684)], [np.float32(0.001716104), np.float32(0.9982839)], [np.float32(0.0058178906), np.float32(0.9941821)], [np.float32(0.04807763), np.float32(0.95192236)], [np.float32(0.0026085714), np.float32(0.9973914)], [np.float32(0.0009754322), np.float32(0.99902457)], [np.float32(0.10825513), np.float32(0.89174485)], [np.float32(0.0010948615), np.float32(0.9989051)], [np.float32(0.031555004), np.float32(0.968445)], [np.float32(2.2041556e-22), np.float32(1.0)], [np.float32(1.5791632e-06), np.float32(0.99999845)], [np.float32(0.22976051), np.float32(0.7702395)], [np.float32(0.11516699), np.float32(0.884833)], [np.float32(4.132393e-05), np.float32(0.9999587)], [np.float32(0.00022436009), np.float32(0.99977565)], [np.float32(1.4076491e-07), np.float32(0.9999999)], [np.float32(7.73327e-07), np.float32(0.9999992)], [np.float32(3.0851666e-08), np.float32(0.99999994)], [np.float32(0.00031353603), np.float32(0.9996865)], [np.float32(2.8701214e-10), np.float32(1.0)], [np.float32(0.19984052), np.float32(0.80015945)], [np.float32(1.3001677e-07), np.float32(0.9999999)], [np.float32(1.1057856e-06), np.float32(0.99999887)], [np.float32(8.7287394e-10), np.float32(1.0)], [np.float32(0.50062644), np.float32(0.49937356)], [np.float32(0.00073842396), np.float32(0.99926156)], [np.float32(0.012079006), np.float32(0.987921)], [np.float32(0.19261117), np.float32(0.80738884)], [np.float32(0.40377992), np.float32(0.5962201)], [np.float32(0.16425331), np.float32(0.8357467)], [np.float32(0.002656106), np.float32(0.9973439)], [np.float32(2.3684568e-10), np.float32(1.0)], [np.float32(0.024412936), np.float32(0.97558707)], [np.float32(1.1938337e-05), np.float32(0.9999881)], [np.float32(1.1517369e-06), np.float32(0.99999887)], [np.float32(0.0003482324), np.float32(0.9996518)], [np.float32(3.122653e-05), np.float32(0.99996877)], [np.float32(3.7666914e-18), np.float32(1.0)], [np.float32(1.11384525e-05), np.float32(0.99998885)], [np.float32(3.0159228e-09), np.float32(1.0)], [np.float32(1.4824725e-11), np.float32(1.0)], [np.float32(0.0009687602), np.float32(0.99903125)], [np.float32(2.494855e-05), np.float32(0.999975)], [np.float32(0.0007279179), np.float32(0.9992721)], [np.float32(0.001065461), np.float32(0.99893457)], [np.float32(0.8912555), np.float32(0.1087445)], [np.float32(0.00020853584), np.float32(0.99979144)], [np.float32(3.853301e-07), np.float32(0.99999964)], [np.float32(5.321506e-05), np.float32(0.9999468)], [np.float32(7.356993e-06), np.float32(0.99999267)], [np.float32(4.7216672e-05), np.float32(0.9999528)], [np.float32(0.016969703), np.float32(0.9830303)]]\n",
      "Unseen set\n",
      "      ID        Dx         % Mel     % Nev\n",
      "0      0  Melanoma  6.147470e-01  0.385253\n",
      "1      1  Melanoma  9.999975e-01  0.000003\n",
      "2      2  Melanoma  9.998711e-01  0.000129\n",
      "3      3  Melanoma  9.999850e-01  0.000015\n",
      "4      4  Melanoma  3.203397e-03  0.996797\n",
      "..   ...       ...           ...       ...\n",
      "395  395     Nevus  3.853301e-07  1.000000\n",
      "396  396     Nevus  5.321506e-05  0.999947\n",
      "397  397     Nevus  7.356993e-06  0.999993\n",
      "398  398     Nevus  4.721667e-05  0.999953\n",
      "399  399     Nevus  1.696970e-02  0.983030\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
