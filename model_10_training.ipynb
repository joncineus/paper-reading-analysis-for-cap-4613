{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 10 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 22:55:36.763500: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 22:55:36.776619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756594536.791752   19702 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756594536.796540   19702 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756594536.807992   19702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756594536.808013   19702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756594536.808015   19702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756594536.808017   19702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-30 22:55:36.812468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 9\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 23:02:33.492274: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 9\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756595140.447096   24884 service.cc:152] XLA service 0x7fa108055930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756595140.447138   24884 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-08-30 23:05:40.534309: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756595142.556613   24884 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step\n",
      "[[np.float32(0.99985063), np.float32(0.00014936924)], [np.float32(0.9912032), np.float32(0.008796811)], [np.float32(0.9999963), np.float32(3.695488e-06)], [np.float32(0.87855136), np.float32(0.121448636)], [np.float32(0.99845874), np.float32(0.0015412569)], [np.float32(0.9981059), np.float32(0.0018941164)], [np.float32(0.999997), np.float32(2.9802322e-06)], [np.float32(0.8884527), np.float32(0.11154729)], [np.float32(0.99998033), np.float32(1.9669533e-05)], [np.float32(0.9182589), np.float32(0.081741095)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.64046), np.float32(0.35954)], [np.float32(0.9906861), np.float32(0.009313881)], [np.float32(0.69575095), np.float32(0.30424905)], [np.float32(0.8259201), np.float32(0.1740799)], [np.float32(0.07662196), np.float32(0.92337805)], [np.float32(0.9979911), np.float32(0.002008915)], [np.float32(0.9975414), np.float32(0.0024585724)], [np.float32(0.9911895), np.float32(0.00881052)], [np.float32(0.3983572), np.float32(0.6016428)], [np.float32(0.5713395), np.float32(0.4286605)], [np.float32(0.018171337), np.float32(0.9818287)], [np.float32(0.9999465), np.float32(5.352497e-05)], [np.float32(0.008724595), np.float32(0.9912754)], [np.float32(0.9999783), np.float32(2.169609e-05)], [np.float32(0.9592799), np.float32(0.040720105)], [np.float32(0.044086084), np.float32(0.9559139)], [np.float32(0.9769233), np.float32(0.023076713)], [np.float32(0.80997217), np.float32(0.19002783)], [np.float32(0.9999739), np.float32(2.6106834e-05)], [np.float32(0.886692), np.float32(0.11330801)], [np.float32(0.9954887), np.float32(0.0045112967)], [np.float32(0.9448662), np.float32(0.05513382)], [np.float32(0.13212031), np.float32(0.8678797)], [np.float32(0.93246615), np.float32(0.06753385)], [np.float32(0.9569763), np.float32(0.043023705)], [np.float32(0.99889165), np.float32(0.0011083484)], [np.float32(0.99844235), np.float32(0.0015576482)], [np.float32(0.9654187), np.float32(0.034581304)], [np.float32(0.99999726), np.float32(2.7418137e-06)], [np.float32(0.9998), np.float32(0.00019997358)], [np.float32(0.9866933), np.float32(0.013306677)], [np.float32(0.9994918), np.float32(0.0005081892)], [np.float32(0.039882146), np.float32(0.9601179)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99998415), np.float32(1.5854836e-05)], [np.float32(0.42609227), np.float32(0.57390773)], [np.float32(0.74331254), np.float32(0.25668746)], [np.float32(0.9518447), np.float32(0.048155308)], [np.float32(0.99981934), np.float32(0.00018066168)], [np.float32(0.8445711), np.float32(0.15542889)], [np.float32(0.22699521), np.float32(0.7730048)], [np.float32(0.9719559), np.float32(0.028044105)], [np.float32(0.9326396), np.float32(0.0673604)], [np.float32(0.9992606), np.float32(0.0007393956)], [np.float32(0.9999925), np.float32(7.5101852e-06)], [np.float32(0.9700836), np.float32(0.029916406)], [np.float32(0.010066567), np.float32(0.98993343)], [np.float32(0.9999908), np.float32(9.179115e-06)], [np.float32(0.999895), np.float32(0.000105023384)], [np.float32(0.99729556), np.float32(0.0027044415)], [np.float32(0.7434625), np.float32(0.2565375)], [np.float32(0.006133227), np.float32(0.9938668)], [np.float32(0.99999785), np.float32(2.1457672e-06)], [np.float32(0.9998604), np.float32(0.00013959408)], [np.float32(0.98923326), np.float32(0.010766745)], [np.float32(0.96830946), np.float32(0.031690538)], [np.float32(0.009148673), np.float32(0.99085134)], [np.float32(0.7548644), np.float32(0.2451356)], [np.float32(0.9342238), np.float32(0.06577623)], [np.float32(0.9999162), np.float32(8.380413e-05)], [np.float32(0.9674163), np.float32(0.032583714)], [np.float32(0.9999964), np.float32(3.5762787e-06)], [np.float32(0.94059426), np.float32(0.059405744)], [np.float32(0.9995223), np.float32(0.00047767162)], [np.float32(0.9955669), np.float32(0.0044330955)], [np.float32(0.86310315), np.float32(0.13689685)], [np.float32(0.6403983), np.float32(0.35960168)], [np.float32(0.9944701), np.float32(0.0055298805)], [np.float32(0.34578738), np.float32(0.6542126)], [np.float32(0.99931014), np.float32(0.00068986416)], [np.float32(0.9912202), np.float32(0.008779824)], [np.float32(0.97515714), np.float32(0.024842858)], [np.float32(0.99969804), np.float32(0.00030195713)], [np.float32(0.022393215), np.float32(0.9776068)], [np.float32(0.9999515), np.float32(4.851818e-05)], [np.float32(0.999951), np.float32(4.8995018e-05)], [np.float32(0.99602026), np.float32(0.0039797425)], [np.float32(0.94591993), np.float32(0.05408007)], [np.float32(0.9964826), np.float32(0.0035173893)], [np.float32(0.1481755), np.float32(0.8518245)], [np.float32(0.09062085), np.float32(0.9093791)], [np.float32(0.97732097), np.float32(0.02267903)], [np.float32(0.34861225), np.float32(0.65138775)], [np.float32(0.9997501), np.float32(0.00024992228)], [np.float32(0.34500116), np.float32(0.65499884)], [np.float32(0.99997854), np.float32(2.1457672e-05)], [np.float32(0.99762183), np.float32(0.0023781657)], [np.float32(0.97889435), np.float32(0.021105647)], [np.float32(0.9385267), np.float32(0.06147331)], [np.float32(0.19756283), np.float32(0.8024372)], [np.float32(0.6048638), np.float32(0.39513618)], [np.float32(0.99803716), np.float32(0.0019628406)], [np.float32(0.96897864), np.float32(0.031021357)], [np.float32(0.9995018), np.float32(0.0004981756)], [np.float32(0.11583894), np.float32(0.88416106)], [np.float32(0.9299819), np.float32(0.07001811)], [np.float32(0.99999905), np.float32(9.536743e-07)], [np.float32(0.5697533), np.float32(0.4302467)], [np.float32(0.17337595), np.float32(0.82662404)], [np.float32(0.80979717), np.float32(0.19020283)], [np.float32(0.7693414), np.float32(0.23065859)], [np.float32(0.99689144), np.float32(0.003108561)], [np.float32(0.9142371), np.float32(0.08576292)], [np.float32(0.5443761), np.float32(0.45562392)], [np.float32(0.94028765), np.float32(0.05971235)], [np.float32(0.99073434), np.float32(0.009265661)], [np.float32(3.7542202e-06), np.float32(0.99999624)], [np.float32(0.81042117), np.float32(0.18957883)], [np.float32(0.98174113), np.float32(0.01825887)], [np.float32(0.9999933), np.float32(6.67572e-06)], [np.float32(0.56584305), np.float32(0.43415695)], [np.float32(0.9999944), np.float32(5.6028366e-06)], [np.float32(0.12994444), np.float32(0.87005556)], [np.float32(0.9941017), np.float32(0.005898297)], [np.float32(0.999428), np.float32(0.0005720258)], [np.float32(0.044342127), np.float32(0.9556579)], [np.float32(0.9949256), np.float32(0.005074382)], [np.float32(0.99999595), np.float32(4.053116e-06)], [np.float32(0.9593787), np.float32(0.04062128)], [np.float32(0.047745787), np.float32(0.95225424)], [np.float32(0.8878741), np.float32(0.11212587)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.9999988), np.float32(1.1920929e-06)], [np.float32(0.9999995), np.float32(4.7683716e-07)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9556063), np.float32(0.04439372)], [np.float32(0.9997776), np.float32(0.00022238493)], [np.float32(0.9906777), np.float32(0.009322286)], [np.float32(0.15799598), np.float32(0.842004)], [np.float32(0.9897675), np.float32(0.010232508)], [np.float32(0.7754092), np.float32(0.22459078)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9998877), np.float32(0.00011229515)], [np.float32(0.99836034), np.float32(0.0016396642)], [np.float32(0.7998391), np.float32(0.20016092)], [np.float32(0.8850596), np.float32(0.114940405)], [np.float32(0.9995347), np.float32(0.00046527386)], [np.float32(0.9999572), np.float32(4.2796135e-05)], [np.float32(0.90476865), np.float32(0.095231354)], [np.float32(0.03742099), np.float32(0.962579)], [np.float32(0.03513281), np.float32(0.9648672)], [np.float32(0.9486664), np.float32(0.051333606)], [np.float32(0.6254367), np.float32(0.37456328)], [np.float32(0.9985481), np.float32(0.0014519095)], [np.float32(0.96826965), np.float32(0.031730354)], [np.float32(0.9999143), np.float32(8.571148e-05)], [np.float32(0.95207673), np.float32(0.047923267)], [np.float32(0.6825316), np.float32(0.3174684)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.9717575), np.float32(0.028242528)], [np.float32(0.933036), np.float32(0.06696397)], [np.float32(0.9995307), np.float32(0.00046932697)], [np.float32(0.005673541), np.float32(0.9943265)], [np.float32(0.9985312), np.float32(0.0014687777)], [np.float32(0.61893433), np.float32(0.38106567)], [np.float32(0.99854666), np.float32(0.00145334)], [np.float32(0.93721944), np.float32(0.06278056)], [np.float32(0.38580716), np.float32(0.61419284)], [np.float32(0.99999475), np.float32(5.2452087e-06)], [np.float32(0.9999908), np.float32(9.179115e-06)], [np.float32(0.270407), np.float32(0.72959304)], [np.float32(0.99969757), np.float32(0.00030243397)], [np.float32(0.049365643), np.float32(0.95063436)], [np.float32(0.5538667), np.float32(0.44613332)], [np.float32(0.99774784), np.float32(0.0022521615)], [np.float32(0.82819986), np.float32(0.17180014)], [np.float32(0.9949529), np.float32(0.005047083)], [np.float32(0.953328), np.float32(0.046671987)], [np.float32(0.09857831), np.float32(0.90142167)], [np.float32(0.99005425), np.float32(0.00994575)], [np.float32(0.95523965), np.float32(0.044760346)], [np.float32(0.95114976), np.float32(0.04885024)], [np.float32(0.8855916), np.float32(0.114408374)], [np.float32(0.99872726), np.float32(0.001272738)], [np.float32(0.021044232), np.float32(0.97895575)], [np.float32(0.97933096), np.float32(0.020669043)], [np.float32(0.74107486), np.float32(0.25892514)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.98342013), np.float32(0.016579866)], [np.float32(0.9367708), np.float32(0.0632292)], [np.float32(0.9997919), np.float32(0.00020807981)], [np.float32(0.9999995), np.float32(4.7683716e-07)], [np.float32(0.9776408), np.float32(0.022359192)], [np.float32(0.999984), np.float32(1.5974045e-05)], [np.float32(0.9998721), np.float32(0.00012791157)], [np.float32(0.990576), np.float32(0.009423971)], [np.float32(0.1549469), np.float32(0.8450531)], [np.float32(0.97870797), np.float32(0.02129203)], [np.float32(0.99465793), np.float32(0.0053420663)], [np.float32(4.3898826e-13), np.float32(1.0)], [np.float32(1.4664348e-10), np.float32(1.0)], [np.float32(1.467384e-09), np.float32(1.0)], [np.float32(0.18463294), np.float32(0.81536704)], [np.float32(2.50169e-13), np.float32(1.0)], [np.float32(3.1406037e-11), np.float32(1.0)], [np.float32(0.035266742), np.float32(0.96473324)], [np.float32(1.0831817e-11), np.float32(1.0)], [np.float32(1.1562171e-14), np.float32(1.0)], [np.float32(4.5268664e-09), np.float32(1.0)], [np.float32(0.00024091837), np.float32(0.9997591)], [np.float32(0.49614903), np.float32(0.50385094)], [np.float32(0.001174033), np.float32(0.99882597)], [np.float32(0.032597978), np.float32(0.96740204)], [np.float32(7.541529e-09), np.float32(1.0)], [np.float32(2.8777856e-13), np.float32(1.0)], [np.float32(1.2468206e-06), np.float32(0.99999875)], [np.float32(5.115985e-15), np.float32(1.0)], [np.float32(0.100482605), np.float32(0.8995174)], [np.float32(2.1486968e-16), np.float32(1.0)], [np.float32(6.735411e-08), np.float32(0.99999994)], [np.float32(3.7543458e-30), np.float32(1.0)], [np.float32(0.07392643), np.float32(0.92607355)], [np.float32(1.3725991e-06), np.float32(0.9999986)], [np.float32(1.5159156e-06), np.float32(0.9999985)], [np.float32(0.019122569), np.float32(0.98087746)], [np.float32(0.024543537), np.float32(0.9754565)], [np.float32(3.4288874e-07), np.float32(0.99999964)], [np.float32(0.10854222), np.float32(0.8914578)], [np.float32(0.00040071653), np.float32(0.9995993)], [np.float32(0.97582155), np.float32(0.024178445)], [np.float32(0.95835525), np.float32(0.041644752)], [np.float32(0.011875806), np.float32(0.9881242)], [np.float32(2.5710016e-12), np.float32(1.0)], [np.float32(0.52868223), np.float32(0.47131777)], [np.float32(1.2814076e-15), np.float32(1.0)], [np.float32(2.5379963e-20), np.float32(1.0)], [np.float32(3.0531805e-12), np.float32(1.0)], [np.float32(1.0993084e-14), np.float32(1.0)], [np.float32(8.0288527e-07), np.float32(0.9999992)], [np.float32(1.0845568e-18), np.float32(1.0)], [np.float32(0.004270024), np.float32(0.99573)], [np.float32(0.06984472), np.float32(0.9301553)], [np.float32(3.0090305e-11), np.float32(1.0)], [np.float32(6.8543917e-13), np.float32(1.0)], [np.float32(0.113700055), np.float32(0.88629997)], [np.float32(2.1137654e-10), np.float32(1.0)], [np.float32(0.01572056), np.float32(0.98427945)], [np.float32(3.0076727e-21), np.float32(1.0)], [np.float32(2.8992972e-07), np.float32(0.9999997)], [np.float32(0.00015110272), np.float32(0.9998489)], [np.float32(0.0024295477), np.float32(0.99757046)], [np.float32(6.7362424e-28), np.float32(1.0)], [np.float32(1.3227332e-17), np.float32(1.0)], [np.float32(0.000306138), np.float32(0.9996939)], [np.float32(4.407003e-14), np.float32(1.0)], [np.float32(5.67568e-12), np.float32(1.0)], [np.float32(2.8536044e-17), np.float32(1.0)], [np.float32(0.10962027), np.float32(0.8903797)], [np.float32(0.12765774), np.float32(0.8723422)], [np.float32(1.9097372e-10), np.float32(1.0)], [np.float32(3.224967e-05), np.float32(0.99996775)], [np.float32(1.3137214e-14), np.float32(1.0)], [np.float32(0.25004143), np.float32(0.7499586)], [np.float32(1.5127529e-06), np.float32(0.9999985)], [np.float32(1.0506444e-16), np.float32(1.0)], [np.float32(1.16791105e-14), np.float32(1.0)], [np.float32(2.245771e-09), np.float32(1.0)], [np.float32(0.018416045), np.float32(0.98158395)], [np.float32(1.6647967e-18), np.float32(1.0)], [np.float32(0.3502452), np.float32(0.64975476)], [np.float32(0.04903464), np.float32(0.95096534)], [np.float32(0.0057552103), np.float32(0.9942448)], [np.float32(0.00010687574), np.float32(0.9998931)], [np.float32(2.2470125e-05), np.float32(0.9999775)], [np.float32(1.3932416e-14), np.float32(1.0)], [np.float32(1.3075358e-12), np.float32(1.0)], [np.float32(8.919618e-08), np.float32(0.99999994)], [np.float32(3.414356e-08), np.float32(0.99999994)], [np.float32(4.327263e-15), np.float32(1.0)], [np.float32(0.00015762763), np.float32(0.99984235)], [np.float32(3.8456948e-15), np.float32(1.0)], [np.float32(0.00063663215), np.float32(0.99936336)], [np.float32(5.226297e-06), np.float32(0.99999475)], [np.float32(9.766143e-14), np.float32(1.0)], [np.float32(0.00018251255), np.float32(0.9998175)], [np.float32(0.014323162), np.float32(0.9856768)], [np.float32(1.3630437e-09), np.float32(1.0)], [np.float32(1.3161707e-08), np.float32(1.0)], [np.float32(6.5271963e-13), np.float32(1.0)], [np.float32(2.5215956e-16), np.float32(1.0)], [np.float32(7.873981e-31), np.float32(1.0)], [np.float32(4.0704928e-20), np.float32(1.0)], [np.float32(0.00039217543), np.float32(0.9996078)], [np.float32(1.5070018e-11), np.float32(1.0)], [np.float32(1.9480485e-05), np.float32(0.9999805)], [np.float32(7.276967e-08), np.float32(0.99999994)], [np.float32(6.122282e-06), np.float32(0.99999386)], [np.float32(7.18155e-16), np.float32(1.0)], [np.float32(2.30435e-19), np.float32(1.0)], [np.float32(9.738462e-07), np.float32(0.99999905)], [np.float32(8.406414e-28), np.float32(1.0)], [np.float32(8.5444175e-24), np.float32(1.0)], [np.float32(6.645157e-34), np.float32(1.0)], [np.float32(0.0007965728), np.float32(0.99920344)], [np.float32(2.5907399e-13), np.float32(1.0)], [np.float32(6.8106345e-12), np.float32(1.0)], [np.float32(7.363159e-14), np.float32(1.0)], [np.float32(6.091854e-17), np.float32(1.0)], [np.float32(1.7145616e-16), np.float32(1.0)], [np.float32(0.066653654), np.float32(0.93334633)], [np.float32(1.0429192e-13), np.float32(1.0)], [np.float32(3.499401e-08), np.float32(0.99999994)], [np.float32(6.4513013e-09), np.float32(1.0)], [np.float32(3.0414494e-32), np.float32(1.0)], [np.float32(2.7437252e-09), np.float32(1.0)], [np.float32(0.9984106), np.float32(0.0015894175)], [np.float32(5.420256e-31), np.float32(1.0)], [np.float32(2.111671e-09), np.float32(1.0)], [np.float32(1.7111946e-18), np.float32(1.0)], [np.float32(2.6600596e-21), np.float32(1.0)], [np.float32(0.9973335), np.float32(0.0026664734)], [np.float32(3.866966e-05), np.float32(0.9999613)], [np.float32(0.99862957), np.float32(0.00137043)], [np.float32(3.3478296e-05), np.float32(0.9999665)], [np.float32(0.0018657785), np.float32(0.9981342)], [np.float32(7.938373e-12), np.float32(1.0)], [np.float32(3.8441375e-09), np.float32(1.0)], [np.float32(1.3734964e-08), np.float32(1.0)], [np.float32(1.4879605e-05), np.float32(0.9999851)], [np.float32(0.004290157), np.float32(0.99570984)], [np.float32(1.1037869e-08), np.float32(1.0)], [np.float32(1.9678379e-11), np.float32(1.0)], [np.float32(1.0419078e-12), np.float32(1.0)], [np.float32(0.0654233), np.float32(0.9345767)], [np.float32(3.4623014e-08), np.float32(0.99999994)], [np.float32(0.0021852842), np.float32(0.9978147)], [np.float32(6.787295e-11), np.float32(1.0)], [np.float32(2.0554931e-12), np.float32(1.0)], [np.float32(3.3532994e-13), np.float32(1.0)], [np.float32(3.539503e-08), np.float32(0.99999994)], [np.float32(6.2254774e-10), np.float32(1.0)], [np.float32(0.03272785), np.float32(0.96727216)], [np.float32(4.1716056e-26), np.float32(1.0)], [np.float32(0.5421967), np.float32(0.4578033)], [np.float32(0.0021071546), np.float32(0.99789286)], [np.float32(4.7085975e-09), np.float32(1.0)], [np.float32(4.2826254e-09), np.float32(1.0)], [np.float32(0.004298227), np.float32(0.9957018)], [np.float32(0.06425745), np.float32(0.93574256)], [np.float32(0.06530975), np.float32(0.93469024)], [np.float32(0.0049723466), np.float32(0.99502766)], [np.float32(6.117286e-06), np.float32(0.99999386)], [np.float32(1.6959796e-09), np.float32(1.0)], [np.float32(8.936083e-31), np.float32(1.0)], [np.float32(0.00046762908), np.float32(0.99953234)], [np.float32(1.9190008e-10), np.float32(1.0)], [np.float32(8.75553e-11), np.float32(1.0)], [np.float32(1.4711118e-27), np.float32(1.0)], [np.float32(0.3844585), np.float32(0.61554146)], [np.float32(0.00051510386), np.float32(0.9994849)], [np.float32(1.10586616e-13), np.float32(1.0)], [np.float32(7.311356e-09), np.float32(1.0)], [np.float32(4.7045237e-12), np.float32(1.0)], [np.float32(7.618052e-09), np.float32(1.0)], [np.float32(1.7507733e-06), np.float32(0.9999983)], [np.float32(3.482358e-18), np.float32(1.0)], [np.float32(0.0006490363), np.float32(0.99935097)], [np.float32(0.1106191), np.float32(0.88938093)], [np.float32(5.8121464e-20), np.float32(1.0)], [np.float32(9.1739544e-10), np.float32(1.0)], [np.float32(0.00010266397), np.float32(0.99989736)], [np.float32(0.38956255), np.float32(0.61043745)], [np.float32(0.0022017404), np.float32(0.99779826)], [np.float32(0.0051637515), np.float32(0.9948363)], [np.float32(0.112537734), np.float32(0.88746226)], [np.float32(0.26854905), np.float32(0.7314509)], [np.float32(0.00366421), np.float32(0.9963358)], [np.float32(3.9580886e-26), np.float32(1.0)], [np.float32(2.4184545e-12), np.float32(1.0)], [np.float32(0.120021306), np.float32(0.8799787)], [np.float32(0.002805296), np.float32(0.9971947)], [np.float32(2.2446472e-06), np.float32(0.99999774)], [np.float32(0.08924752), np.float32(0.9107525)], [np.float32(5.960828e-23), np.float32(1.0)], [np.float32(8.136952e-24), np.float32(1.0)], [np.float32(6.733942e-17), np.float32(1.0)], [np.float32(2.8721492e-09), np.float32(1.0)], [np.float32(3.588478e-24), np.float32(1.0)], [np.float32(0.040994473), np.float32(0.95900553)], [np.float32(1.5636675e-06), np.float32(0.99999845)], [np.float32(1.5566515e-08), np.float32(1.0)], [np.float32(0.00020058105), np.float32(0.99979943)], [np.float32(0.0005301865), np.float32(0.9994698)], [np.float32(2.4178251e-25), np.float32(1.0)], [np.float32(8.461409e-14), np.float32(1.0)], [np.float32(4.9379194e-09), np.float32(1.0)], [np.float32(4.217969e-07), np.float32(0.9999996)], [np.float32(3.9705778e-12), np.float32(1.0)], [np.float32(3.531762e-19), np.float32(1.0)]]\n",
      "Unseen set\n",
      "      ID        Dx         % Mel     % Nev\n",
      "0      0  Melanoma  9.998506e-01  0.000149\n",
      "1      1  Melanoma  9.912032e-01  0.008797\n",
      "2      2  Melanoma  9.999963e-01  0.000004\n",
      "3      3  Melanoma  8.785514e-01  0.121449\n",
      "4      4  Melanoma  9.984587e-01  0.001541\n",
      "..   ...       ...           ...       ...\n",
      "395  395     Nevus  8.461409e-14  1.000000\n",
      "396  396     Nevus  4.937919e-09  1.000000\n",
      "397  397     Nevus  4.217969e-07  1.000000\n",
      "398  398     Nevus  3.970578e-12  1.000000\n",
      "399  399     Nevus  3.531762e-19  1.000000\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
