{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 4 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 22:34:32.794907: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 22:34:34.788362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756593275.343776    3234 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756593275.457221    3234 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756593276.586882    3234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593276.587051    3234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593276.587054    3234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756593276.587056    3234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-30 22:34:36.697855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently training on seed: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "learning rate: 7.1e-04\n",
      "num_dense_nodes: 74\n",
      "dropout: 0.24635516452074735\n",
      "optimizer_type: SGD\n",
      "epochs: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755991954.664675    6470 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755991979.323893    7034 service.cc:152] XLA service 0x7f9eec003ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755991979.324173    7034 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-23 23:33:00.184284: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755991983.167855    7034 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "2025-08-23 23:33:11.750049: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:11.898022: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:12.253486: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:12.396879: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/52\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:12\u001b[0m 53s/step - accuracy: 0.5000 - loss: 0.8812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755992011.765758    7034 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6068 - loss: 0.6881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 23:33:47.931215: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:48.078739: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:48.406761: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 23:33:48.550268: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 940ms/step - accuracy: 0.6932 - loss: 0.5901 - val_accuracy: 0.7802 - val_loss: 0.4876\n",
      "Epoch 2/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - accuracy: 0.8502 - loss: 0.3379 - val_accuracy: 0.7778 - val_loss: 0.4601\n",
      "Epoch 3/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.9094 - loss: 0.2166 - val_accuracy: 0.7403 - val_loss: 0.6257\n",
      "Epoch 4/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.9529 - loss: 0.1272 - val_accuracy: 0.8043 - val_loss: 0.5308\n",
      "Epoch 5/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9493 - loss: 0.1358 - val_accuracy: 0.6981 - val_loss: 0.9891\n",
      "Epoch 6/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9517 - loss: 0.1183 - val_accuracy: 0.7234 - val_loss: 0.8269\n",
      "Epoch 7/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9469 - loss: 0.1251 - val_accuracy: 0.7536 - val_loss: 0.8688\n",
      "Epoch 8/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9650 - loss: 0.1056 - val_accuracy: 0.8333 - val_loss: 0.4468\n",
      "Epoch 9/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9807 - loss: 0.0659 - val_accuracy: 0.8659 - val_loss: 0.4493\n",
      "Epoch 10/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9915 - loss: 0.0314 - val_accuracy: 0.8659 - val_loss: 0.4418\n",
      "Epoch 11/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9952 - loss: 0.0218 - val_accuracy: 0.8539 - val_loss: 0.5657\n",
      "Epoch 12/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9879 - loss: 0.0410 - val_accuracy: 0.8611 - val_loss: 0.4693\n",
      "Epoch 13/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9952 - loss: 0.0192 - val_accuracy: 0.8539 - val_loss: 0.4942\n",
      "Epoch 14/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9915 - loss: 0.0242 - val_accuracy: 0.8104 - val_loss: 0.6503\n",
      "\n",
      "Accuracy: 81.04%\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 214.4351\n",
      "Function value obtained: -0.8104\n",
      "Current minimum: -0.8104\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "learning rate: 1.5e-06\n",
      "num_dense_nodes: 103\n",
      "dropout: 0.2983700732616053\n",
      "optimizer_type: SGD\n",
      "epochs: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 760ms/step - accuracy: 0.5193 - loss: 0.7118 - val_accuracy: 0.4988 - val_loss: 0.7332\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5495 - loss: 0.7003 - val_accuracy: 0.5060 - val_loss: 0.7172\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5435 - loss: 0.7112 - val_accuracy: 0.5121 - val_loss: 0.7085\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5495 - loss: 0.7002 - val_accuracy: 0.5447 - val_loss: 0.6959\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5688 - loss: 0.6974 - val_accuracy: 0.5483 - val_loss: 0.6905\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5374 - loss: 0.7003 - val_accuracy: 0.5604 - val_loss: 0.6859\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5374 - loss: 0.7065 - val_accuracy: 0.5580 - val_loss: 0.6832\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.5519 - loss: 0.6925 - val_accuracy: 0.5676 - val_loss: 0.6801\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5338 - loss: 0.7115 - val_accuracy: 0.5676 - val_loss: 0.6778\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5580 - loss: 0.6909 - val_accuracy: 0.5616 - val_loss: 0.6758\n",
      "\n",
      "Accuracy: 56.16%\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 158.3804\n",
      "Function value obtained: -0.5616\n",
      "Current minimum: -0.8104\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "learning rate: 1.0e-05\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.30941461243166224\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 877ms/step - accuracy: 0.6727 - loss: 0.6151 - val_accuracy: 0.6546 - val_loss: 0.6030\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7899 - loss: 0.4855 - val_accuracy: 0.7077 - val_loss: 0.5242\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8671 - loss: 0.3838 - val_accuracy: 0.7452 - val_loss: 0.4736\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8780 - loss: 0.3189 - val_accuracy: 0.8092 - val_loss: 0.4092\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9094 - loss: 0.2579 - val_accuracy: 0.8345 - val_loss: 0.3746\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9215 - loss: 0.2247 - val_accuracy: 0.8454 - val_loss: 0.3404\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9444 - loss: 0.1788 - val_accuracy: 0.8514 - val_loss: 0.3314\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9541 - loss: 0.1527 - val_accuracy: 0.8671 - val_loss: 0.3281\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9529 - loss: 0.1309 - val_accuracy: 0.8587 - val_loss: 0.3314\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9565 - loss: 0.1263 - val_accuracy: 0.8720 - val_loss: 0.3271\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9734 - loss: 0.0883 - val_accuracy: 0.8635 - val_loss: 0.3312\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9855 - loss: 0.0629 - val_accuracy: 0.8732 - val_loss: 0.3311\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9964 - loss: 0.0485 - val_accuracy: 0.8744 - val_loss: 0.3349\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9891 - loss: 0.0499 - val_accuracy: 0.8684 - val_loss: 0.3460\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9867 - loss: 0.0511 - val_accuracy: 0.8732 - val_loss: 0.3474\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9940 - loss: 0.0311 - val_accuracy: 0.8671 - val_loss: 0.3593\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9976 - loss: 0.0243 - val_accuracy: 0.8696 - val_loss: 0.3684\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9879 - loss: 0.0432 - val_accuracy: 0.8768 - val_loss: 0.3626\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9783 - loss: 0.0630 - val_accuracy: 0.8720 - val_loss: 0.3598\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9976 - loss: 0.0179 - val_accuracy: 0.8744 - val_loss: 0.3667\n",
      "\n",
      "Accuracy: 87.44%\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 264.3848\n",
      "Function value obtained: -0.8744\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "learning rate: 4.0e-06\n",
      "num_dense_nodes: 184\n",
      "dropout: 0.4843936223233912\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 873ms/step - accuracy: 0.5350 - loss: 0.7122 - val_accuracy: 0.5954 - val_loss: 0.6869\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.6473 - loss: 0.6142 - val_accuracy: 0.6715 - val_loss: 0.6184\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.6944 - loss: 0.5787 - val_accuracy: 0.7198 - val_loss: 0.5520\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7826 - loss: 0.4901 - val_accuracy: 0.7645 - val_loss: 0.5112\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7814 - loss: 0.4730 - val_accuracy: 0.7886 - val_loss: 0.4712\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8237 - loss: 0.4259 - val_accuracy: 0.8164 - val_loss: 0.4391\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.8454 - loss: 0.4023 - val_accuracy: 0.8261 - val_loss: 0.4170\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.8333 - loss: 0.3699 - val_accuracy: 0.8345 - val_loss: 0.3996\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8659 - loss: 0.3406 - val_accuracy: 0.8382 - val_loss: 0.3858\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8599 - loss: 0.3346 - val_accuracy: 0.8430 - val_loss: 0.3724\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8853 - loss: 0.3068 - val_accuracy: 0.8466 - val_loss: 0.3634\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.8732 - loss: 0.3000 - val_accuracy: 0.8478 - val_loss: 0.3551\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8973 - loss: 0.2581 - val_accuracy: 0.8514 - val_loss: 0.3492\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.8973 - loss: 0.2542 - val_accuracy: 0.8527 - val_loss: 0.3446\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.8973 - loss: 0.2475 - val_accuracy: 0.8527 - val_loss: 0.3423\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9239 - loss: 0.2142 - val_accuracy: 0.8527 - val_loss: 0.3401\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9263 - loss: 0.2027 - val_accuracy: 0.8563 - val_loss: 0.3388\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9179 - loss: 0.2167 - val_accuracy: 0.8563 - val_loss: 0.3371\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9179 - loss: 0.2153 - val_accuracy: 0.8575 - val_loss: 0.3360\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.9469 - loss: 0.1752 - val_accuracy: 0.8575 - val_loss: 0.3339\n",
      "\n",
      "Accuracy: 85.75%\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 269.4299\n",
      "Function value obtained: -0.8575\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "learning rate: 4.2e-03\n",
      "num_dense_nodes: 107\n",
      "dropout: 0.6096716170179315\n",
      "optimizer_type: Adam\n",
      "epochs: 9\n",
      "Epoch 1/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 898ms/step - accuracy: 0.5036 - loss: 1.1796 - val_accuracy: 0.5000 - val_loss: 453780448.0000\n",
      "Epoch 2/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 156ms/step - accuracy: 0.5217 - loss: 0.7018 - val_accuracy: 0.5000 - val_loss: 12031.6904\n",
      "Epoch 3/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5483 - loss: 0.7176 - val_accuracy: 0.4251 - val_loss: 34.6072\n",
      "Epoch 4/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5423 - loss: 0.6658 - val_accuracy: 0.6884 - val_loss: 16.4629\n",
      "Epoch 5/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5592 - loss: 0.6737 - val_accuracy: 0.6014 - val_loss: 2.7118\n",
      "Epoch 6/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5616 - loss: 0.7185 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
      "Epoch 7/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.4976 - loss: 0.6954 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 8/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5000 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 9/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5205 - loss: 0.6935 - val_accuracy: 0.5205 - val_loss: 0.6929\n",
      "\n",
      "Accuracy: 52.05%\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 185.2451\n",
      "Function value obtained: -0.5205\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.1\n",
      "optimizer_type: SGD\n",
      "epochs: 19\n",
      "Epoch 1/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 767ms/step - accuracy: 0.7403 - loss: 0.5275 - val_accuracy: 0.5737 - val_loss: 1.0831\n",
      "Epoch 2/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 148ms/step - accuracy: 0.7947 - loss: 0.4635 - val_accuracy: 0.5000 - val_loss: 88.6605\n",
      "Epoch 3/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7935 - loss: 0.4848 - val_accuracy: 0.5000 - val_loss: 43.1071\n",
      "Epoch 4/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7657 - loss: 0.5028 - val_accuracy: 0.5024 - val_loss: 2.0166\n",
      "Epoch 5/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8007 - loss: 0.4050 - val_accuracy: 0.5000 - val_loss: 13.0662\n",
      "Epoch 6/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8092 - loss: 0.4023 - val_accuracy: 0.5290 - val_loss: 2.3821\n",
      "Epoch 7/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8043 - loss: 0.4325 - val_accuracy: 0.5229 - val_loss: 4.6272\n",
      "Epoch 8/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8333 - loss: 0.3605 - val_accuracy: 0.8200 - val_loss: 0.7210\n",
      "Epoch 9/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8225 - loss: 0.3772 - val_accuracy: 0.8309 - val_loss: 0.6751\n",
      "Epoch 10/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8321 - loss: 0.3703 - val_accuracy: 0.8007 - val_loss: 0.5579\n",
      "Epoch 11/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8490 - loss: 0.3314 - val_accuracy: 0.7947 - val_loss: 0.7240\n",
      "Epoch 12/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8514 - loss: 0.3420 - val_accuracy: 0.8188 - val_loss: 0.4572\n",
      "Epoch 13/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8623 - loss: 0.2877 - val_accuracy: 0.8152 - val_loss: 0.4007\n",
      "Epoch 14/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.8925 - loss: 0.2464 - val_accuracy: 0.8490 - val_loss: 0.3392\n",
      "Epoch 15/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9058 - loss: 0.2109 - val_accuracy: 0.7947 - val_loss: 0.4947\n",
      "Epoch 16/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8937 - loss: 0.2318 - val_accuracy: 0.7911 - val_loss: 0.4531\n",
      "Epoch 17/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9155 - loss: 0.2103 - val_accuracy: 0.8466 - val_loss: 0.3632\n",
      "Epoch 18/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9106 - loss: 0.2120 - val_accuracy: 0.8188 - val_loss: 0.3959\n",
      "Epoch 19/19\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9046 - loss: 0.2181 - val_accuracy: 0.7862 - val_loss: 0.8355\n",
      "\n",
      "Accuracy: 78.62%\n",
      "\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 251.5584\n",
      "Function value obtained: -0.7862\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 904ms/step - accuracy: 0.4771 - loss: 1.1501 - val_accuracy: 0.5000 - val_loss: 865417472.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5302 - loss: 0.6733 - val_accuracy: 0.5000 - val_loss: 3330.9873\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5507 - loss: 0.6821 - val_accuracy: 0.5918 - val_loss: 34.8656\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5700 - loss: 0.6789 - val_accuracy: 0.7862 - val_loss: 30.7789\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5423 - loss: 0.6789 - val_accuracy: 0.4976 - val_loss: 1807.8516\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.6111 - loss: 0.6352 - val_accuracy: 0.7536 - val_loss: 3.2389\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5519 - loss: 0.6917 - val_accuracy: 0.4988 - val_loss: 0.7731\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5543 - loss: 0.6592 - val_accuracy: 0.6884 - val_loss: 2.8368\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.6606 - loss: 0.6501 - val_accuracy: 0.4650 - val_loss: 1.1092\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.6727 - loss: 0.5933 - val_accuracy: 0.7838 - val_loss: 17.1097\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7428 - loss: 0.5452 - val_accuracy: 0.5882 - val_loss: 1152.1970\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7464 - loss: 0.5477 - val_accuracy: 0.5386 - val_loss: 303.0892\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7403 - loss: 0.5945 - val_accuracy: 0.7911 - val_loss: 59.5898\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7754 - loss: 0.5327 - val_accuracy: 0.7729 - val_loss: 85.4199\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7729 - loss: 0.5259 - val_accuracy: 0.8007 - val_loss: 0.9972\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7609 - loss: 0.5362 - val_accuracy: 0.7053 - val_loss: 0.6083\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.7669 - loss: 0.5333 - val_accuracy: 0.5000 - val_loss: 0.8135\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7838 - loss: 0.5021 - val_accuracy: 0.5954 - val_loss: 267720.9688\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7826 - loss: 0.5175 - val_accuracy: 0.7174 - val_loss: 279.4969\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.7778 - loss: 0.5195 - val_accuracy: 0.7295 - val_loss: 0.5581\n",
      "\n",
      "Accuracy: 72.95%\n",
      "\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 267.8313\n",
      "Function value obtained: -0.7295\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "learning rate: 7.1e-04\n",
      "num_dense_nodes: 218\n",
      "dropout: 0.6931886303813132\n",
      "optimizer_type: SGD\n",
      "epochs: 17\n",
      "Epoch 1/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 821ms/step - accuracy: 0.6401 - loss: 0.7276 - val_accuracy: 0.7693 - val_loss: 0.5148\n",
      "Epoch 2/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7886 - loss: 0.4478 - val_accuracy: 0.5338 - val_loss: 0.9089\n",
      "Epoch 3/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.8200 - loss: 0.3828 - val_accuracy: 0.4915 - val_loss: 0.8491\n",
      "Epoch 4/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8345 - loss: 0.3779 - val_accuracy: 0.7222 - val_loss: 0.8522\n",
      "Epoch 5/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8382 - loss: 0.3721 - val_accuracy: 0.5036 - val_loss: 7.9822\n",
      "Epoch 6/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7959 - loss: 0.4843 - val_accuracy: 0.5000 - val_loss: 10.1414\n",
      "Epoch 7/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8116 - loss: 0.4082 - val_accuracy: 0.6039 - val_loss: 3.4037\n",
      "Epoch 8/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8273 - loss: 0.5259 - val_accuracy: 0.5000 - val_loss: 266.8741\n",
      "Epoch 9/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.7947 - loss: 0.5518 - val_accuracy: 0.7186 - val_loss: 6.1187\n",
      "Epoch 10/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.7572 - loss: 0.5085 - val_accuracy: 0.5000 - val_loss: 110.8173\n",
      "Epoch 11/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7681 - loss: 0.5397 - val_accuracy: 0.4988 - val_loss: 70.5728\n",
      "Epoch 12/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7379 - loss: 0.5553 - val_accuracy: 0.5000 - val_loss: 116.2403\n",
      "Epoch 13/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7814 - loss: 0.5381 - val_accuracy: 0.4964 - val_loss: 86.2723\n",
      "Epoch 14/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7802 - loss: 0.5027 - val_accuracy: 0.5000 - val_loss: 293.2033\n",
      "Epoch 15/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7802 - loss: 0.4677 - val_accuracy: 0.5000 - val_loss: 885.5207\n",
      "Epoch 16/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7681 - loss: 0.4963 - val_accuracy: 0.5000 - val_loss: 1390.9574\n",
      "Epoch 17/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7669 - loss: 0.4646 - val_accuracy: 0.5000 - val_loss: 1363.8691\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 221.4929\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "learning rate: 2.8e-03\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.28218841530501193\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 800ms/step - accuracy: 0.7415 - loss: 0.4930 - val_accuracy: 0.4988 - val_loss: 1.5343\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7874 - loss: 0.4373 - val_accuracy: 0.4976 - val_loss: 8.8260\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.7355 - loss: 0.5887 - val_accuracy: 0.5000 - val_loss: 10512.3311\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.7729 - loss: 0.5080 - val_accuracy: 0.5000 - val_loss: 10725.3896\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8237 - loss: 0.4478 - val_accuracy: 0.5000 - val_loss: 774890.5625\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7633 - loss: 0.6007 - val_accuracy: 0.5000 - val_loss: 1045852.6875\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7645 - loss: 0.5301 - val_accuracy: 0.5000 - val_loss: 536974.9375\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7536 - loss: 0.6772 - val_accuracy: 0.5000 - val_loss: 13920.2510\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7983 - loss: 0.4580 - val_accuracy: 0.5000 - val_loss: 59039.4766\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7850 - loss: 0.5031 - val_accuracy: 0.5000 - val_loss: 103440.1328\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7742 - loss: 0.6838 - val_accuracy: 0.5000 - val_loss: 68011.0547\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7862 - loss: 0.5311 - val_accuracy: 0.5000 - val_loss: 148988.0625\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8019 - loss: 0.7587 - val_accuracy: 0.5000 - val_loss: 66497.1328\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7572 - loss: 0.6356 - val_accuracy: 0.5048 - val_loss: 7814.4878\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7790 - loss: 0.5104 - val_accuracy: 0.5048 - val_loss: 5108.3042\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7669 - loss: 0.5089 - val_accuracy: 0.5097 - val_loss: 1484.0275\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8068 - loss: 0.4617 - val_accuracy: 0.4952 - val_loss: 3.3317\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8164 - loss: 0.4408 - val_accuracy: 0.5072 - val_loss: 223.1835\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7959 - loss: 0.4518 - val_accuracy: 0.4698 - val_loss: 252.4464\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8285 - loss: 0.3909 - val_accuracy: 0.5254 - val_loss: 699.4164\n",
      "\n",
      "Accuracy: 52.54%\n",
      "\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 237.5740\n",
      "Function value obtained: -0.5254\n",
      "Current minimum: -0.8744\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "learning rate: 8.2e-05\n",
      "num_dense_nodes: 146\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 18\n",
      "Epoch 1/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 911ms/step - accuracy: 0.8043 - loss: 0.4438 - val_accuracy: 0.7488 - val_loss: 0.5711\n",
      "Epoch 2/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9312 - loss: 0.1794 - val_accuracy: 0.8140 - val_loss: 0.6120\n",
      "Epoch 3/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.9505 - loss: 0.1441 - val_accuracy: 0.8454 - val_loss: 0.4684\n",
      "Epoch 4/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9891 - loss: 0.0566 - val_accuracy: 0.8696 - val_loss: 0.4307\n",
      "Epoch 5/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9891 - loss: 0.0379 - val_accuracy: 0.8587 - val_loss: 0.3964\n",
      "Epoch 6/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9928 - loss: 0.0211 - val_accuracy: 0.8635 - val_loss: 0.4047\n",
      "Epoch 7/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9831 - loss: 0.0344 - val_accuracy: 0.8611 - val_loss: 0.6184\n",
      "Epoch 8/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9879 - loss: 0.0433 - val_accuracy: 0.8599 - val_loss: 0.5236\n",
      "Epoch 9/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9674 - loss: 0.0794 - val_accuracy: 0.8490 - val_loss: 0.6424\n",
      "Epoch 10/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9710 - loss: 0.0740 - val_accuracy: 0.8418 - val_loss: 0.7290\n",
      "Epoch 11/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9964 - loss: 0.0204 - val_accuracy: 0.8732 - val_loss: 0.5150\n",
      "Epoch 12/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.8430 - val_loss: 0.5892\n",
      "Epoch 13/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9964 - loss: 0.0157 - val_accuracy: 0.8454 - val_loss: 0.6541\n",
      "Epoch 14/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9903 - loss: 0.0208 - val_accuracy: 0.8696 - val_loss: 0.5939\n",
      "Epoch 15/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - accuracy: 0.9879 - loss: 0.0478 - val_accuracy: 0.8587 - val_loss: 0.6074\n",
      "Epoch 16/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9867 - loss: 0.0367 - val_accuracy: 0.8865 - val_loss: 0.4849\n",
      "Epoch 17/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9940 - loss: 0.0169 - val_accuracy: 0.8744 - val_loss: 0.5175\n",
      "Epoch 18/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9964 - loss: 0.0103 - val_accuracy: 0.8816 - val_loss: 0.5129\n",
      "\n",
      "Accuracy: 88.16%\n",
      "\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 253.3474\n",
      "Function value obtained: -0.8816\n",
      "Current minimum: -0.8816\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.8\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 930ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 147.9491\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8816\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 151\n",
      "dropout: 0.1\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 842ms/step - accuracy: 0.7609 - loss: 0.4902 - val_accuracy: 0.7729 - val_loss: 0.5255\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.8333 - loss: 0.3902 - val_accuracy: 0.7572 - val_loss: 0.8895\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8345 - loss: 0.3465 - val_accuracy: 0.8382 - val_loss: 0.3729\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.8430 - loss: 0.3302 - val_accuracy: 0.8442 - val_loss: 0.5816\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.8853 - loss: 0.2577 - val_accuracy: 0.8345 - val_loss: 0.4407\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.8780 - loss: 0.2670 - val_accuracy: 0.8200 - val_loss: 0.6477\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.9094 - loss: 0.2188 - val_accuracy: 0.8575 - val_loss: 0.3385\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.9312 - loss: 0.1768 - val_accuracy: 0.8188 - val_loss: 0.5025\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.9396 - loss: 0.1443 - val_accuracy: 0.8478 - val_loss: 0.3632\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9408 - loss: 0.1552 - val_accuracy: 0.8345 - val_loss: 0.8699\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9662 - loss: 0.1111 - val_accuracy: 0.8551 - val_loss: 0.3914\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9746 - loss: 0.0627 - val_accuracy: 0.7850 - val_loss: 0.7706\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9807 - loss: 0.0605 - val_accuracy: 0.8382 - val_loss: 0.8052\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9674 - loss: 0.0800 - val_accuracy: 0.8309 - val_loss: 0.6601\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9722 - loss: 0.0865 - val_accuracy: 0.7645 - val_loss: 0.8065\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9758 - loss: 0.0635 - val_accuracy: 0.8551 - val_loss: 0.6995\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9819 - loss: 0.0606 - val_accuracy: 0.7585 - val_loss: 1.0698\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9734 - loss: 0.0885 - val_accuracy: 0.8527 - val_loss: 0.4639\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9879 - loss: 0.0354 - val_accuracy: 0.8539 - val_loss: 0.5846\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9795 - loss: 0.0728 - val_accuracy: 0.7826 - val_loss: 1.0632\n",
      "\n",
      "Accuracy: 78.26%\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 245.2638\n",
      "Function value obtained: -0.7826\n",
      "Current minimum: -0.8816\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "learning rate: 2.9e-05\n",
      "num_dense_nodes: 64\n",
      "dropout: 0.31277241663353217\n",
      "optimizer_type: SGD\n",
      "epochs: 6\n",
      "Epoch 1/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 831ms/step - accuracy: 0.5169 - loss: 0.7336 - val_accuracy: 0.5604 - val_loss: 0.6815\n",
      "Epoch 2/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.6099 - loss: 0.6520 - val_accuracy: 0.6691 - val_loss: 0.6280\n",
      "Epoch 3/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7585 - loss: 0.5453 - val_accuracy: 0.7126 - val_loss: 0.5728\n",
      "Epoch 4/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7742 - loss: 0.4991 - val_accuracy: 0.7681 - val_loss: 0.5033\n",
      "Epoch 5/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8321 - loss: 0.4292 - val_accuracy: 0.8043 - val_loss: 0.4482\n",
      "Epoch 6/6\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8382 - loss: 0.3829 - val_accuracy: 0.8140 - val_loss: 0.4201\n",
      "\n",
      "Accuracy: 81.40%\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 132.7833\n",
      "Function value obtained: -0.8140\n",
      "Current minimum: -0.8816\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "learning rate: 7.3e-05\n",
      "num_dense_nodes: 202\n",
      "dropout: 0.24753683781297553\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 930ms/step - accuracy: 0.7971 - loss: 0.4333 - val_accuracy: 0.6413 - val_loss: 0.8683\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.9106 - loss: 0.2234 - val_accuracy: 0.7802 - val_loss: 0.5528\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9686 - loss: 0.0933 - val_accuracy: 0.8092 - val_loss: 0.5543\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - accuracy: 0.9758 - loss: 0.0914 - val_accuracy: 0.7899 - val_loss: 0.7868\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9867 - loss: 0.0434 - val_accuracy: 0.8756 - val_loss: 0.4426\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.8611 - val_loss: 0.5510\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9903 - loss: 0.0305 - val_accuracy: 0.8635 - val_loss: 0.5274\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9783 - loss: 0.0560 - val_accuracy: 0.8611 - val_loss: 0.6919\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9783 - loss: 0.0812 - val_accuracy: 0.8563 - val_loss: 0.3861\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9795 - loss: 0.0857 - val_accuracy: 0.8611 - val_loss: 0.3999\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9879 - loss: 0.0386 - val_accuracy: 0.8756 - val_loss: 0.3473\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9915 - loss: 0.0258 - val_accuracy: 0.8829 - val_loss: 0.4146\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9940 - loss: 0.0159 - val_accuracy: 0.8744 - val_loss: 0.5591\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9988 - loss: 0.0078 - val_accuracy: 0.8889 - val_loss: 0.4577\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.8804 - val_loss: 0.4788\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9940 - loss: 0.0123 - val_accuracy: 0.8623 - val_loss: 0.5826\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9928 - loss: 0.0265 - val_accuracy: 0.8659 - val_loss: 0.6320\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9952 - loss: 0.0146 - val_accuracy: 0.8611 - val_loss: 0.5422\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9903 - loss: 0.0283 - val_accuracy: 0.8804 - val_loss: 0.4993\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9964 - loss: 0.0146 - val_accuracy: 0.8877 - val_loss: 0.4206\n",
      "\n",
      "Accuracy: 88.77%\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 276.8126\n",
      "Function value obtained: -0.8877\n",
      "Current minimum: -0.8877\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "learning rate: 1.6e-06\n",
      "num_dense_nodes: 146\n",
      "dropout: 0.27541895463151633\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 838ms/step - accuracy: 0.5036 - loss: 0.7386 - val_accuracy: 0.5085 - val_loss: 0.7672\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5133 - loss: 0.7359 - val_accuracy: 0.5350 - val_loss: 0.7254\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5483 - loss: 0.7139 - val_accuracy: 0.5326 - val_loss: 0.7103\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5556 - loss: 0.6983 - val_accuracy: 0.5374 - val_loss: 0.7016\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5568 - loss: 0.6910 - val_accuracy: 0.5821 - val_loss: 0.6803\n",
      "\n",
      "Accuracy: 58.21%\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 128.9681\n",
      "Function value obtained: -0.5821\n",
      "Current minimum: -0.8877\n",
      "Seed:  3\n",
      "BEST ACCURACY:  {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.8876811861991882, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0}\n",
      "hyper_params  [7.252039034804953e-05, 0.24753683781297553, 0.8454908224918273, 0.9320170511241584, 0.9987720261221676, np.int64(20), np.int64(202), np.str_('Adam')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 3\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 22:35:02.283585: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 3\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756593325.149729    4265 service.cc:152] XLA service 0x7f71f8055930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756593325.150001    4265 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-08-30 22:35:25.335854: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756593327.335868    4265 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step \n",
      "[[np.float32(0.9994867), np.float32(0.0005133152)], [np.float32(0.8885067), np.float32(0.11149329)], [np.float32(0.99999905), np.float32(9.536743e-07)], [np.float32(0.99998), np.float32(2.002716e-05)], [np.float32(0.43372646), np.float32(0.56627357)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99999595), np.float32(4.053116e-06)], [np.float32(0.99887913), np.float32(0.0011208653)], [np.float32(0.9999995), np.float32(4.7683716e-07)], [np.float32(0.8747333), np.float32(0.12526667)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99918574), np.float32(0.00081425905)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9998067), np.float32(0.00019329786)], [np.float32(0.9998907), np.float32(0.00010931492)], [np.float32(0.66833144), np.float32(0.33166856)], [np.float32(0.9996451), np.float32(0.00035488605)], [np.float32(0.7566374), np.float32(0.2433626)], [np.float32(0.99997425), np.float32(2.5749207e-05)], [np.float32(0.096720085), np.float32(0.9032799)], [np.float32(0.043496765), np.float32(0.9565032)], [np.float32(0.042917147), np.float32(0.95708287)], [np.float32(0.9884172), np.float32(0.011582792)], [np.float32(0.0005666551), np.float32(0.99943334)], [np.float32(0.9999069), np.float32(9.3102455e-05)], [np.float32(0.67655146), np.float32(0.32344854)], [np.float32(0.39123926), np.float32(0.6087607)], [np.float32(0.91307896), np.float32(0.086921036)], [np.float32(0.0711982), np.float32(0.9288018)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9956072), np.float32(0.0043928027)], [np.float32(0.96849984), np.float32(0.03150016)], [np.float32(0.95728654), np.float32(0.042713463)], [np.float32(0.48831192), np.float32(0.5116881)], [np.float32(0.69345254), np.float32(0.30654746)], [np.float32(0.7678034), np.float32(0.23219663)], [np.float32(1.0), np.float32(0.0)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999378), np.float32(6.222725e-05)], [np.float32(0.9991621), np.float32(0.0008379221)], [np.float32(0.99999416), np.float32(5.841255e-06)], [np.float32(0.9999976), np.float32(2.3841858e-06)], [np.float32(0.9998191), np.float32(0.0001809001)], [np.float32(0.019402938), np.float32(0.9805971)], [np.float32(0.99916923), np.float32(0.00083076954)], [np.float32(0.032015014), np.float32(0.967985)], [np.float32(0.9736791), np.float32(0.026320875)], [np.float32(0.21599673), np.float32(0.78400326)], [np.float32(0.99815625), np.float32(0.0018437505)], [np.float32(0.9999292), np.float32(7.081032e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.999035), np.float32(0.0009649992)], [np.float32(0.99999404), np.float32(5.9604645e-06)], [np.float32(0.991901), np.float32(0.0080990195)], [np.float32(0.93926716), np.float32(0.06073284)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.95729584), np.float32(0.042704165)], [np.float32(0.09948055), np.float32(0.90051943)], [np.float32(0.9996505), np.float32(0.00034952164)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.1810493), np.float32(0.8189507)], [np.float32(0.7413149), np.float32(0.2586851)], [np.float32(0.10703976), np.float32(0.89296025)], [np.float32(0.99996567), np.float32(3.4332275e-05)], [np.float32(0.99821424), np.float32(0.0017857552)], [np.float32(0.99958354), np.float32(0.00041645765)], [np.float32(0.9932817), np.float32(0.006718278)], [np.float32(4.7590565e-05), np.float32(0.99995244)], [np.float32(0.999964), np.float32(3.6001205e-05)], [np.float32(0.9944353), np.float32(0.0055646896)], [np.float32(0.9615677), np.float32(0.0384323)], [np.float32(0.9999515), np.float32(4.851818e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999926), np.float32(7.390976e-06)], [np.float32(1.0), np.float32(0.0)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.93942904), np.float32(0.060570955)], [np.float32(0.48549855), np.float32(0.51450145)], [np.float32(0.999998), np.float32(2.026558e-06)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.99843246), np.float32(0.0015675426)], [np.float32(0.9999033), np.float32(9.6678734e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.19741063), np.float32(0.80258936)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99999774), np.float32(2.2649765e-06)], [np.float32(0.99998844), np.float32(1.1563301e-05)], [np.float32(0.999246), np.float32(0.00075399876)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99989474), np.float32(0.0001052618)], [np.float32(0.013779732), np.float32(0.98622024)], [np.float32(0.99999654), np.float32(3.4570694e-06)], [np.float32(0.89393556), np.float32(0.10606444)], [np.float32(0.9999938), np.float32(6.198883e-06)], [np.float32(0.9069644), np.float32(0.09303558)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99995494), np.float32(4.506111e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.999642), np.float32(0.0003579855)], [np.float32(0.99542576), np.float32(0.0045742393)], [np.float32(0.95537335), np.float32(0.044626653)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99987745), np.float32(0.00012254715)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.04833466), np.float32(0.95166534)], [np.float32(0.9830299), np.float32(0.016970098)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.8815837), np.float32(0.11841631)], [np.float32(0.9999862), np.float32(1.3828278e-05)], [np.float32(0.42664844), np.float32(0.57335156)], [np.float32(0.7740003), np.float32(0.22599971)], [np.float32(0.9999788), np.float32(2.1219254e-05)], [np.float32(0.9978097), np.float32(0.0021902919)], [np.float32(0.99962425), np.float32(0.00037574768)], [np.float32(0.7285421), np.float32(0.2714579)], [np.float32(0.9998123), np.float32(0.00018769503)], [np.float32(0.020767158), np.float32(0.97923285)], [np.float32(0.99968576), np.float32(0.0003142357)], [np.float32(0.8674126), np.float32(0.13258737)], [np.float32(0.66150653), np.float32(0.33849347)], [np.float32(0.999777), np.float32(0.00022298098)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.49430656), np.float32(0.50569344)], [np.float32(0.9932414), np.float32(0.0067585707)], [np.float32(0.99743205), np.float32(0.002567947)], [np.float32(0.97436476), np.float32(0.025635242)], [np.float32(0.9999863), np.float32(1.3709068e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.60083073), np.float32(0.39916927)], [np.float32(0.99983966), np.float32(0.0001603365)], [np.float32(0.999992), np.float32(7.987022e-06)], [np.float32(1.0), np.float32(0.0)], [np.float32(1.0), np.float32(0.0)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999933), np.float32(6.67572e-06)], [np.float32(0.97435343), np.float32(0.025646567)], [np.float32(0.99590105), np.float32(0.004098952)], [np.float32(0.99424225), np.float32(0.005757749)], [np.float32(0.9656898), np.float32(0.03431022)], [np.float32(0.9998561), np.float32(0.00014388561)], [np.float32(0.9443362), np.float32(0.055663824)], [np.float32(0.9999697), np.float32(3.027916e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999491), np.float32(5.0902367e-05)], [np.float32(0.95985645), np.float32(0.04014355)], [np.float32(0.9993142), np.float32(0.00068581104)], [np.float32(0.99935204), np.float32(0.0006479621)], [np.float32(0.99998987), np.float32(1.013279e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.0744378), np.float32(0.9255622)], [np.float32(0.026480246), np.float32(0.97351974)], [np.float32(0.9999677), np.float32(3.2305717e-05)], [np.float32(0.8020835), np.float32(0.19791651)], [np.float32(0.9999093), np.float32(9.071827e-05)], [np.float32(0.9999893), np.float32(1.0728836e-05)], [np.float32(0.9999993), np.float32(7.1525574e-07)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.9996295), np.float32(0.00037050247)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9844104), np.float32(0.015589595)], [np.float32(0.9998758), np.float32(0.00012421608)], [np.float32(0.9954833), np.float32(0.004516721)], [np.float32(0.19336778), np.float32(0.8066322)], [np.float32(0.99999785), np.float32(2.1457672e-06)], [np.float32(0.97877276), np.float32(0.02122724)], [np.float32(0.99993896), np.float32(6.1035156e-05)], [np.float32(0.99977416), np.float32(0.000225842)], [np.float32(0.03979714), np.float32(0.9602029)], [np.float32(1.0), np.float32(0.0)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9453655), np.float32(0.05463451)], [np.float32(0.9271276), np.float32(0.0728724)], [np.float32(0.99158114), np.float32(0.008418858)], [np.float32(0.99709594), np.float32(0.0029040575)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.014178163), np.float32(0.98582184)], [np.float32(0.8878792), np.float32(0.11212081)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9976502), np.float32(0.002349794)], [np.float32(0.04593417), np.float32(0.9540658)], [np.float32(0.9999635), np.float32(3.6478043e-05)], [np.float32(0.45879635), np.float32(0.5412036)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99933606), np.float32(0.00066393614)], [np.float32(0.8141207), np.float32(0.18587929)], [np.float32(0.999998), np.float32(2.026558e-06)], [np.float32(0.98242724), np.float32(0.01757276)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999721), np.float32(2.7894974e-05)], [np.float32(0.6789431), np.float32(0.3210569)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9976815), np.float32(0.0023185015)], [np.float32(0.9969297), np.float32(0.0030702949)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99925524), np.float32(0.00074476004)], [np.float32(0.9999212), np.float32(7.879734e-05)], [np.float32(0.00094771927), np.float32(0.9990523)], [np.float32(0.96915036), np.float32(0.030849636)], [np.float32(1.0), np.float32(0.0)], [np.float32(6.918943e-05), np.float32(0.9999308)], [np.float32(0.00013658353), np.float32(0.99986345)], [np.float32(0.00930595), np.float32(0.99069405)], [np.float32(0.1853132), np.float32(0.8146868)], [np.float32(1.054903e-09), np.float32(1.0)], [np.float32(2.2055927e-08), np.float32(1.0)], [np.float32(0.39633548), np.float32(0.6036645)], [np.float32(0.0003684951), np.float32(0.9996315)], [np.float32(2.2093427e-07), np.float32(0.99999976)], [np.float32(0.00026916538), np.float32(0.9997308)], [np.float32(0.016029261), np.float32(0.98397076)], [np.float32(0.9999974), np.float32(2.6226044e-06)], [np.float32(0.73707473), np.float32(0.26292527)], [np.float32(0.9880221), np.float32(0.011977911)], [np.float32(0.000112372574), np.float32(0.99988765)], [np.float32(0.00092753477), np.float32(0.9990725)], [np.float32(3.9054985e-06), np.float32(0.99999607)], [np.float32(6.851801e-06), np.float32(0.99999315)], [np.float32(0.34894237), np.float32(0.6510576)], [np.float32(2.0339603e-05), np.float32(0.9999797)], [np.float32(0.0024843863), np.float32(0.9975156)], [np.float32(2.306588e-08), np.float32(1.0)], [np.float32(0.061807748), np.float32(0.93819225)], [np.float32(2.7225233e-05), np.float32(0.99997276)], [np.float32(9.817541e-06), np.float32(0.99999017)], [np.float32(0.036066085), np.float32(0.96393394)], [np.float32(0.8526614), np.float32(0.14733863)], [np.float32(3.277348e-07), np.float32(0.9999997)], [np.float32(0.95776874), np.float32(0.04223126)], [np.float32(0.00013031719), np.float32(0.9998697)], [np.float32(0.99989605), np.float32(0.0001039505)], [np.float32(0.99906033), np.float32(0.0009396672)], [np.float32(0.06915205), np.float32(0.93084794)], [np.float32(0.004654933), np.float32(0.99534506)], [np.float32(0.15126112), np.float32(0.8487389)], [np.float32(2.0422442e-05), np.float32(0.99997956)], [np.float32(7.285456e-06), np.float32(0.9999927)], [np.float32(3.003511e-07), np.float32(0.9999997)], [np.float32(0.00010329106), np.float32(0.9998967)], [np.float32(0.038275994), np.float32(0.961724)], [np.float32(0.000115953284), np.float32(0.99988407)], [np.float32(0.17959909), np.float32(0.8204009)], [np.float32(0.0012935762), np.float32(0.9987064)], [np.float32(5.7256707e-06), np.float32(0.9999943)], [np.float32(1.1738754e-08), np.float32(1.0)], [np.float32(0.1440763), np.float32(0.8559237)], [np.float32(5.066735e-07), np.float32(0.99999946)], [np.float32(0.86256325), np.float32(0.13743675)], [np.float32(6.6394734e-10), np.float32(1.0)], [np.float32(0.0011486439), np.float32(0.99885136)], [np.float32(2.6212505e-05), np.float32(0.9999738)], [np.float32(0.0034871073), np.float32(0.9965129)], [np.float32(1.4769656e-05), np.float32(0.9999852)], [np.float32(0.0001163072), np.float32(0.9998837)], [np.float32(0.0006790228), np.float32(0.999321)], [np.float32(0.0003375455), np.float32(0.99966246)], [np.float32(9.786272e-06), np.float32(0.9999902)], [np.float32(3.1885983e-09), np.float32(1.0)], [np.float32(0.018152941), np.float32(0.98184705)], [np.float32(0.1367614), np.float32(0.8632386)], [np.float32(0.012888627), np.float32(0.9871114)], [np.float32(4.8069855e-05), np.float32(0.99995196)], [np.float32(1.7033404e-05), np.float32(0.99998295)], [np.float32(0.016422892), np.float32(0.98357713)], [np.float32(0.035166893), np.float32(0.9648331)], [np.float32(0.00021825265), np.float32(0.9997817)], [np.float32(8.563483e-07), np.float32(0.99999917)], [np.float32(0.00021649305), np.float32(0.9997835)], [np.float32(0.000877266), np.float32(0.99912274)], [np.float32(1.1094204e-08), np.float32(1.0)], [np.float32(0.52155185), np.float32(0.47844815)], [np.float32(0.0014560914), np.float32(0.9985439)], [np.float32(0.32479134), np.float32(0.6752087)], [np.float32(0.0010826116), np.float32(0.9989174)], [np.float32(0.002550369), np.float32(0.99744964)], [np.float32(1.03257825e-07), np.float32(0.9999999)], [np.float32(0.00014554984), np.float32(0.99985445)], [np.float32(0.00010622963), np.float32(0.9998938)], [np.float32(4.9477203e-05), np.float32(0.9999505)], [np.float32(7.798243e-06), np.float32(0.9999922)], [np.float32(0.0036114086), np.float32(0.9963886)], [np.float32(7.601742e-06), np.float32(0.9999924)], [np.float32(0.00010932964), np.float32(0.9998907)], [np.float32(0.0074366257), np.float32(0.99256337)], [np.float32(7.150537e-07), np.float32(0.9999993)], [np.float32(0.97574484), np.float32(0.024255157)], [np.float32(0.00965576), np.float32(0.9903442)], [np.float32(6.967471e-07), np.float32(0.9999993)], [np.float32(2.957539e-05), np.float32(0.99997044)], [np.float32(0.0015993227), np.float32(0.9984007)], [np.float32(2.002258e-06), np.float32(0.999998)], [np.float32(6.536432e-12), np.float32(1.0)], [np.float32(0.0016359689), np.float32(0.99836403)], [np.float32(0.012864438), np.float32(0.9871356)], [np.float32(0.00073478254), np.float32(0.9992652)], [np.float32(0.009392009), np.float32(0.990608)], [np.float32(0.00012672736), np.float32(0.9998733)], [np.float32(0.000805004), np.float32(0.999195)], [np.float32(0.0015174254), np.float32(0.9984826)], [np.float32(0.003314082), np.float32(0.9966859)], [np.float32(0.00018069353), np.float32(0.9998193)], [np.float32(4.782777e-08), np.float32(0.99999994)], [np.float32(7.672445e-07), np.float32(0.9999992)], [np.float32(8.752846e-06), np.float32(0.99999124)], [np.float32(0.97580916), np.float32(0.024190843)], [np.float32(1.0502102e-07), np.float32(0.9999999)], [np.float32(0.00039543703), np.float32(0.9996046)], [np.float32(6.4999017e-06), np.float32(0.9999935)], [np.float32(6.991719e-06), np.float32(0.999993)], [np.float32(1.0112135e-05), np.float32(0.99998987)], [np.float32(0.024018362), np.float32(0.97598165)], [np.float32(0.00031660742), np.float32(0.9996834)], [np.float32(8.246365e-05), np.float32(0.9999175)], [np.float32(0.012349604), np.float32(0.9876504)], [np.float32(2.8664084e-05), np.float32(0.99997133)], [np.float32(0.0009922374), np.float32(0.99900776)], [np.float32(0.11252584), np.float32(0.8874742)], [np.float32(6.386331e-08), np.float32(0.99999994)], [np.float32(2.258993e-05), np.float32(0.9999774)], [np.float32(0.000102379585), np.float32(0.9998976)], [np.float32(8.799002e-06), np.float32(0.9999912)], [np.float32(0.36478204), np.float32(0.63521796)], [np.float32(0.041505296), np.float32(0.9584947)], [np.float32(0.10923532), np.float32(0.8907647)], [np.float32(0.009719554), np.float32(0.99028045)], [np.float32(0.0010630104), np.float32(0.998937)], [np.float32(0.00090206275), np.float32(0.99909794)], [np.float32(4.2619864e-05), np.float32(0.9999574)], [np.float32(0.00040859645), np.float32(0.9995914)], [np.float32(0.00081014534), np.float32(0.99918985)], [np.float32(0.012747163), np.float32(0.98725283)], [np.float32(0.0009565295), np.float32(0.99904346)], [np.float32(1.457338e-08), np.float32(1.0)], [np.float32(0.0014935781), np.float32(0.9985064)], [np.float32(0.08098819), np.float32(0.91901183)], [np.float32(0.04322439), np.float32(0.9567756)], [np.float32(0.0030418106), np.float32(0.9969582)], [np.float32(7.3064104e-05), np.float32(0.9999269)], [np.float32(0.02107146), np.float32(0.97892857)], [np.float32(5.143674e-07), np.float32(0.99999946)], [np.float32(0.24962208), np.float32(0.7503779)], [np.float32(1.5288999e-05), np.float32(0.9999847)], [np.float32(0.16662055), np.float32(0.83337945)], [np.float32(0.008630789), np.float32(0.9913692)], [np.float32(0.0538521), np.float32(0.9461479)], [np.float32(0.02517134), np.float32(0.97482866)], [np.float32(0.022573214), np.float32(0.97742677)], [np.float32(1.6280779e-06), np.float32(0.9999984)], [np.float32(0.00035240484), np.float32(0.9996476)], [np.float32(0.5373666), np.float32(0.46263337)], [np.float32(0.00016117899), np.float32(0.9998388)], [np.float32(0.24624634), np.float32(0.75375366)], [np.float32(0.0004904886), np.float32(0.9995095)], [np.float32(6.26417e-05), np.float32(0.99993736)], [np.float32(4.9634807e-09), np.float32(1.0)], [np.float32(0.0041339993), np.float32(0.995866)], [np.float32(0.065121405), np.float32(0.9348786)], [np.float32(6.1043204e-10), np.float32(1.0)], [np.float32(3.4473842e-06), np.float32(0.99999654)], [np.float32(0.27596724), np.float32(0.72403276)], [np.float32(0.80937356), np.float32(0.19062644)], [np.float32(0.00057707273), np.float32(0.9994229)], [np.float32(0.6489388), np.float32(0.35106122)], [np.float32(4.8147067e-05), np.float32(0.99995184)], [np.float32(0.0044335444), np.float32(0.9955664)], [np.float32(0.0005861911), np.float32(0.9994138)], [np.float32(1.7882808e-08), np.float32(1.0)], [np.float32(0.00011092678), np.float32(0.9998891)], [np.float32(0.96970963), np.float32(0.030290365)], [np.float32(1.8561959e-06), np.float32(0.99999815)], [np.float32(0.0016168932), np.float32(0.9983831)], [np.float32(0.0003447513), np.float32(0.99965525)], [np.float32(0.9865791), np.float32(0.01342088)], [np.float32(0.0036047383), np.float32(0.9963953)], [np.float32(0.0028355725), np.float32(0.9971644)], [np.float32(0.6855698), np.float32(0.31443018)], [np.float32(0.0072095254), np.float32(0.99279046)], [np.float32(0.29626232), np.float32(0.7037377)], [np.float32(1.1530851e-05), np.float32(0.9999885)], [np.float32(0.017205914), np.float32(0.9827941)], [np.float32(0.829264), np.float32(0.17073601)], [np.float32(0.0014664095), np.float32(0.9985336)], [np.float32(1.3401188e-05), np.float32(0.9999866)], [np.float32(0.044252455), np.float32(0.95574754)], [np.float32(0.00010910011), np.float32(0.9998909)], [np.float32(2.3477644e-06), np.float32(0.9999977)], [np.float32(6.734011e-06), np.float32(0.99999326)], [np.float32(0.00040387042), np.float32(0.9995961)], [np.float32(1.1267129e-08), np.float32(1.0)], [np.float32(0.52555925), np.float32(0.47444075)], [np.float32(5.673977e-06), np.float32(0.99999434)], [np.float32(0.0003267596), np.float32(0.99967325)], [np.float32(0.4429452), np.float32(0.55705476)], [np.float32(0.0005154622), np.float32(0.99948454)], [np.float32(0.0037758495), np.float32(0.99622416)], [np.float32(5.320065e-05), np.float32(0.9999468)], [np.float32(0.0055961655), np.float32(0.99440384)], [np.float32(0.00027616342), np.float32(0.99972385)], [np.float32(0.02748829), np.float32(0.9725117)], [np.float32(6.426165e-08), np.float32(0.99999994)]]\n",
      "Unseen set\n",
      "      ID        Dx         % Mel         % Nev\n",
      "0      0  Melanoma  9.994867e-01  5.133152e-04\n",
      "1      1  Melanoma  8.885067e-01  1.114933e-01\n",
      "2      2  Melanoma  9.999990e-01  9.536743e-07\n",
      "3      3  Melanoma  9.999800e-01  2.002716e-05\n",
      "4      4  Melanoma  4.337265e-01  5.662736e-01\n",
      "..   ...       ...           ...           ...\n",
      "395  395     Nevus  5.320065e-05  9.999468e-01\n",
      "396  396     Nevus  5.596166e-03  9.944038e-01\n",
      "397  397     Nevus  2.761634e-04  9.997239e-01\n",
      "398  398     Nevus  2.748829e-02  9.725117e-01\n",
      "399  399     Nevus  6.426165e-08  9.999999e-01\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
