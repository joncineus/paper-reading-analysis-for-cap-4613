{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 3 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently training on seed: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "learning rate: 1.1e-03\n",
      "num_dense_nodes: 108\n",
      "dropout: 0.44763176561807827\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755982885.551497   14895 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755982921.849458   15253 service.cc:152] XLA service 0x7fbc90003850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755982921.849487   15253 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-23 21:02:02.923206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755982928.336400   15253 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "2025-08-23 21:02:17.559392: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:02:17.706478: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:02:18.051297: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:02:18.194604: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/52\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:12\u001b[0m 72s/step - accuracy: 0.3750 - loss: 0.8006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755982961.177150   15253 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.6848 - loss: 0.6555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:03:00.885176: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:03:01.031567: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:03:01.349369: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-23 21:03:01.492243: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.7295 - loss: 0.5910 - val_accuracy: 0.5000 - val_loss: 50596260.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.7983 - loss: 0.5131 - val_accuracy: 0.5000 - val_loss: 1636163.7500\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.8056 - loss: 0.5046 - val_accuracy: 0.5000 - val_loss: 2825.4402\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.7899 - loss: 0.4702 - val_accuracy: 0.4976 - val_loss: 1721.8790\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.8007 - loss: 0.4424 - val_accuracy: 0.5036 - val_loss: 213.5042\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8297 - loss: 0.4027 - val_accuracy: 0.5000 - val_loss: 235.5789\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.8225 - loss: 0.4072 - val_accuracy: 0.5024 - val_loss: 57.7210\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.8261 - loss: 0.3861 - val_accuracy: 0.5399 - val_loss: 8.0503\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.8273 - loss: 0.4047 - val_accuracy: 0.6534 - val_loss: 7.9370\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8140 - loss: 0.3925 - val_accuracy: 0.7367 - val_loss: 5.9770\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.8176 - loss: 0.3825 - val_accuracy: 0.7923 - val_loss: 3.2086\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8345 - loss: 0.3633 - val_accuracy: 0.7754 - val_loss: 3.2770\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8309 - loss: 0.3740 - val_accuracy: 0.7621 - val_loss: 5.9837\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8394 - loss: 0.3544 - val_accuracy: 0.7826 - val_loss: 4.7467\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.8478 - loss: 0.3574 - val_accuracy: 0.8140 - val_loss: 2.4048\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.8394 - loss: 0.3469 - val_accuracy: 0.8140 - val_loss: 1.4454\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8442 - loss: 0.3427 - val_accuracy: 0.8128 - val_loss: 1.3978\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8478 - loss: 0.3560 - val_accuracy: 0.8309 - val_loss: 1.3078\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8502 - loss: 0.3702 - val_accuracy: 0.7899 - val_loss: 1.0433\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8527 - loss: 0.3329 - val_accuracy: 0.6812 - val_loss: 1.7391\n",
      "\n",
      "Accuracy: 68.12%\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 291.3865\n",
      "Function value obtained: -0.6812\n",
      "Current minimum: -0.6812\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "learning rate: 5.6e-05\n",
      "num_dense_nodes: 53\n",
      "dropout: 0.6319250311231659\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 806ms/step - accuracy: 0.4879 - loss: 0.7847 - val_accuracy: 0.5423 - val_loss: 0.6921\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.6039 - loss: 0.6643 - val_accuracy: 0.6473 - val_loss: 0.6292\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.7174 - loss: 0.5723 - val_accuracy: 0.6727 - val_loss: 0.5801\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.7717 - loss: 0.5015 - val_accuracy: 0.7536 - val_loss: 0.5046\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.7778 - loss: 0.4894 - val_accuracy: 0.8104 - val_loss: 0.4376\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8164 - loss: 0.4223 - val_accuracy: 0.8333 - val_loss: 0.3976\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.8285 - loss: 0.4098 - val_accuracy: 0.8418 - val_loss: 0.3723\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8551 - loss: 0.3613 - val_accuracy: 0.8478 - val_loss: 0.3592\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8527 - loss: 0.3325 - val_accuracy: 0.8539 - val_loss: 0.3447\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8696 - loss: 0.3128 - val_accuracy: 0.8611 - val_loss: 0.3229\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8744 - loss: 0.3159 - val_accuracy: 0.8696 - val_loss: 0.3124\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.9034 - loss: 0.2608 - val_accuracy: 0.8635 - val_loss: 0.3061\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.8925 - loss: 0.2692 - val_accuracy: 0.8647 - val_loss: 0.3018\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.9215 - loss: 0.2168 - val_accuracy: 0.8611 - val_loss: 0.2942\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9203 - loss: 0.2183 - val_accuracy: 0.8659 - val_loss: 0.2949\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9444 - loss: 0.1735 - val_accuracy: 0.8647 - val_loss: 0.2989\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9324 - loss: 0.1818 - val_accuracy: 0.8671 - val_loss: 0.3014\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9493 - loss: 0.1583 - val_accuracy: 0.8696 - val_loss: 0.2971\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9420 - loss: 0.1623 - val_accuracy: 0.8684 - val_loss: 0.3015\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9662 - loss: 0.1184 - val_accuracy: 0.8587 - val_loss: 0.3037\n",
      "\n",
      "Accuracy: 85.87%\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 245.8126\n",
      "Function value obtained: -0.8587\n",
      "Current minimum: -0.8587\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "learning rate: 7.0e-04\n",
      "num_dense_nodes: 196\n",
      "dropout: 0.7710846059584917\n",
      "optimizer_type: SGD\n",
      "epochs: 11\n",
      "Epoch 1/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 810ms/step - accuracy: 0.6159 - loss: 0.6817 - val_accuracy: 0.6341 - val_loss: 0.6028\n",
      "Epoch 2/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.7935 - loss: 0.4484 - val_accuracy: 0.7790 - val_loss: 0.4465\n",
      "Epoch 3/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8394 - loss: 0.3552 - val_accuracy: 0.8116 - val_loss: 0.3844\n",
      "Epoch 4/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8587 - loss: 0.3128 - val_accuracy: 0.8406 - val_loss: 0.3524\n",
      "Epoch 5/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8768 - loss: 0.2778 - val_accuracy: 0.8684 - val_loss: 0.3112\n",
      "Epoch 6/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.9118 - loss: 0.2287 - val_accuracy: 0.8684 - val_loss: 0.3251\n",
      "Epoch 7/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9565 - loss: 0.1522 - val_accuracy: 0.8792 - val_loss: 0.3581\n",
      "Epoch 8/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.9601 - loss: 0.1045 - val_accuracy: 0.8865 - val_loss: 0.3223\n",
      "Epoch 9/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9746 - loss: 0.0799 - val_accuracy: 0.8696 - val_loss: 0.4110\n",
      "Epoch 10/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9565 - loss: 0.1239 - val_accuracy: 0.8442 - val_loss: 0.4139\n",
      "Epoch 11/11\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.9650 - loss: 0.1054 - val_accuracy: 0.8321 - val_loss: 0.4854\n",
      "\n",
      "Accuracy: 83.21%\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 172.7812\n",
      "Function value obtained: -0.8321\n",
      "Current minimum: -0.8587\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "learning rate: 1.8e-06\n",
      "num_dense_nodes: 123\n",
      "dropout: 0.1894496837628786\n",
      "optimizer_type: SGD\n",
      "epochs: 16\n",
      "Epoch 1/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 805ms/step - accuracy: 0.5048 - loss: 0.7142 - val_accuracy: 0.5036 - val_loss: 0.7549\n",
      "Epoch 2/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5133 - loss: 0.7213 - val_accuracy: 0.5024 - val_loss: 0.7417\n",
      "Epoch 3/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.5085 - loss: 0.7128 - val_accuracy: 0.5060 - val_loss: 0.7249\n",
      "Epoch 4/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.5012 - loss: 0.7235 - val_accuracy: 0.5362 - val_loss: 0.7153\n",
      "Epoch 5/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5085 - loss: 0.7100 - val_accuracy: 0.5507 - val_loss: 0.7083\n",
      "Epoch 6/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5217 - loss: 0.7104 - val_accuracy: 0.5399 - val_loss: 0.7065\n",
      "Epoch 7/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.5290 - loss: 0.6964 - val_accuracy: 0.5374 - val_loss: 0.7065\n",
      "Epoch 8/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5423 - loss: 0.7067 - val_accuracy: 0.5362 - val_loss: 0.7043\n",
      "Epoch 9/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.5242 - loss: 0.7054 - val_accuracy: 0.5278 - val_loss: 0.7015\n",
      "Epoch 10/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5181 - loss: 0.7060 - val_accuracy: 0.5374 - val_loss: 0.6988\n",
      "Epoch 11/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5242 - loss: 0.7043 - val_accuracy: 0.5459 - val_loss: 0.6953\n",
      "Epoch 12/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5302 - loss: 0.7020 - val_accuracy: 0.5483 - val_loss: 0.6928\n",
      "Epoch 13/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5386 - loss: 0.7033 - val_accuracy: 0.5556 - val_loss: 0.6909\n",
      "Epoch 14/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5483 - loss: 0.6875 - val_accuracy: 0.5568 - val_loss: 0.6892\n",
      "Epoch 15/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5169 - loss: 0.7027 - val_accuracy: 0.5628 - val_loss: 0.6882\n",
      "Epoch 16/16\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5447 - loss: 0.6870 - val_accuracy: 0.5628 - val_loss: 0.6864\n",
      "\n",
      "Accuracy: 56.28%\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 210.3070\n",
      "Function value obtained: -0.5628\n",
      "Current minimum: -0.8587\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "learning rate: 2.5e-05\n",
      "num_dense_nodes: 80\n",
      "dropout: 0.13201272593171492\n",
      "optimizer_type: Adam\n",
      "epochs: 8\n",
      "Epoch 1/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 997ms/step - accuracy: 0.7428 - loss: 0.5433 - val_accuracy: 0.7077 - val_loss: 0.5233\n",
      "Epoch 2/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8647 - loss: 0.3339 - val_accuracy: 0.7669 - val_loss: 0.4564\n",
      "Epoch 3/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8998 - loss: 0.2330 - val_accuracy: 0.8176 - val_loss: 0.3845\n",
      "Epoch 4/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.9348 - loss: 0.1644 - val_accuracy: 0.8430 - val_loss: 0.3385\n",
      "Epoch 5/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9710 - loss: 0.1012 - val_accuracy: 0.8684 - val_loss: 0.3150\n",
      "Epoch 6/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9855 - loss: 0.0598 - val_accuracy: 0.8671 - val_loss: 0.3164\n",
      "Epoch 7/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9855 - loss: 0.0482 - val_accuracy: 0.8768 - val_loss: 0.3317\n",
      "Epoch 8/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9855 - loss: 0.0394 - val_accuracy: 0.8684 - val_loss: 0.3604\n",
      "\n",
      "Accuracy: 86.84%\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 178.7473\n",
      "Function value obtained: -0.8684\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 225\n",
      "dropout: 0.5263202532723851\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 944ms/step - accuracy: 0.5157 - loss: 1.1155 - val_accuracy: 0.5000 - val_loss: 1453534871552.0000\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - accuracy: 0.5072 - loss: 1.0567 - val_accuracy: 0.5000 - val_loss: 1005278.8125\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4952 - loss: 0.7152 - val_accuracy: 0.5000 - val_loss: 5990.5542\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5568 - loss: 0.6841 - val_accuracy: 0.6630 - val_loss: 510.0914\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.5169 - loss: 0.6703 - val_accuracy: 0.7923 - val_loss: 188.7812\n",
      "\n",
      "Accuracy: 79.23%\n",
      "\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 152.4860\n",
      "Function value obtained: -0.7923\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "learning rate: 2.3e-06\n",
      "num_dense_nodes: 62\n",
      "dropout: 0.7558342357044505\n",
      "optimizer_type: Adam\n",
      "epochs: 9\n",
      "Epoch 1/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 982ms/step - accuracy: 0.4940 - loss: 0.9153 - val_accuracy: 0.5000 - val_loss: 0.9923\n",
      "Epoch 2/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5024 - loss: 0.8493 - val_accuracy: 0.5000 - val_loss: 0.8662\n",
      "Epoch 3/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5483 - loss: 0.7411 - val_accuracy: 0.5012 - val_loss: 0.7867\n",
      "Epoch 4/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5773 - loss: 0.7088 - val_accuracy: 0.5181 - val_loss: 0.7206\n",
      "Epoch 5/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5833 - loss: 0.6963 - val_accuracy: 0.5640 - val_loss: 0.6670\n",
      "Epoch 6/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.5930 - loss: 0.7022 - val_accuracy: 0.6002 - val_loss: 0.6320\n",
      "Epoch 7/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.6087 - loss: 0.6540 - val_accuracy: 0.6353 - val_loss: 0.6012\n",
      "Epoch 8/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.6232 - loss: 0.6527 - val_accuracy: 0.6643 - val_loss: 0.5813\n",
      "Epoch 9/9\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.6558 - loss: 0.6114 - val_accuracy: 0.6993 - val_loss: 0.5647\n",
      "\n",
      "Accuracy: 69.93%\n",
      "\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 187.1825\n",
      "Function value obtained: -0.6993\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "learning rate: 5.9e-03\n",
      "num_dense_nodes: 75\n",
      "dropout: 0.15049207519825217\n",
      "optimizer_type: SGD\n",
      "epochs: 18\n",
      "Epoch 1/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 849ms/step - accuracy: 0.7645 - loss: 0.5061 - val_accuracy: 0.5000 - val_loss: 41.2742\n",
      "Epoch 2/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8092 - loss: 0.4453 - val_accuracy: 0.7234 - val_loss: 0.6847\n",
      "Epoch 3/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8200 - loss: 0.4172 - val_accuracy: 0.5024 - val_loss: 7.9558\n",
      "Epoch 4/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - accuracy: 0.8104 - loss: 0.3982 - val_accuracy: 0.5000 - val_loss: 16.2343\n",
      "Epoch 5/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8031 - loss: 0.4265 - val_accuracy: 0.5399 - val_loss: 1.9949\n",
      "Epoch 6/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.8043 - loss: 0.4146 - val_accuracy: 0.6691 - val_loss: 1.3711\n",
      "Epoch 7/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.8092 - loss: 0.4311 - val_accuracy: 0.6304 - val_loss: 1.8426\n",
      "Epoch 8/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8225 - loss: 0.4157 - val_accuracy: 0.8043 - val_loss: 0.4581\n",
      "Epoch 9/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8442 - loss: 0.3598 - val_accuracy: 0.5664 - val_loss: 1.7714\n",
      "Epoch 10/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8442 - loss: 0.3237 - val_accuracy: 0.8502 - val_loss: 0.4419\n",
      "Epoch 11/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.8575 - loss: 0.3015 - val_accuracy: 0.8418 - val_loss: 0.4395\n",
      "Epoch 12/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8829 - loss: 0.2685 - val_accuracy: 0.8140 - val_loss: 0.6058\n",
      "Epoch 13/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8357 - loss: 0.3436 - val_accuracy: 0.5966 - val_loss: 11.3010\n",
      "Epoch 14/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8406 - loss: 0.3632 - val_accuracy: 0.6039 - val_loss: 0.6402\n",
      "Epoch 15/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8647 - loss: 0.3011 - val_accuracy: 0.7246 - val_loss: 0.5821\n",
      "Epoch 16/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8877 - loss: 0.2593 - val_accuracy: 0.8406 - val_loss: 0.3534\n",
      "Epoch 17/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8998 - loss: 0.2694 - val_accuracy: 0.7778 - val_loss: 0.7770\n",
      "Epoch 18/18\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.9034 - loss: 0.2511 - val_accuracy: 0.6679 - val_loss: 0.5913\n",
      "\n",
      "Accuracy: 66.79%\n",
      "\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 235.1382\n",
      "Function value obtained: -0.6679\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "learning rate: 3.0e-06\n",
      "num_dense_nodes: 111\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 14\n",
      "Epoch 1/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 986ms/step - accuracy: 0.5024 - loss: 0.7620 - val_accuracy: 0.5229 - val_loss: 0.7253\n",
      "Epoch 2/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.6087 - loss: 0.6381 - val_accuracy: 0.5821 - val_loss: 0.6719\n",
      "Epoch 3/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.7126 - loss: 0.5730 - val_accuracy: 0.6643 - val_loss: 0.6126\n",
      "Epoch 4/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8031 - loss: 0.5291 - val_accuracy: 0.7343 - val_loss: 0.5583\n",
      "Epoch 5/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8152 - loss: 0.4885 - val_accuracy: 0.7754 - val_loss: 0.5080\n",
      "Epoch 6/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8357 - loss: 0.4587 - val_accuracy: 0.8019 - val_loss: 0.4713\n",
      "Epoch 7/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8454 - loss: 0.4215 - val_accuracy: 0.8176 - val_loss: 0.4436\n",
      "Epoch 8/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8599 - loss: 0.3932 - val_accuracy: 0.8382 - val_loss: 0.4196\n",
      "Epoch 9/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8647 - loss: 0.3730 - val_accuracy: 0.8418 - val_loss: 0.4008\n",
      "Epoch 10/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8635 - loss: 0.3497 - val_accuracy: 0.8454 - val_loss: 0.3860\n",
      "Epoch 11/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8696 - loss: 0.3374 - val_accuracy: 0.8539 - val_loss: 0.3746\n",
      "Epoch 12/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8877 - loss: 0.2901 - val_accuracy: 0.8490 - val_loss: 0.3653\n",
      "Epoch 13/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9022 - loss: 0.2866 - val_accuracy: 0.8563 - val_loss: 0.3564\n",
      "Epoch 14/14\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.8877 - loss: 0.2866 - val_accuracy: 0.8563 - val_loss: 0.3472\n",
      "\n",
      "Accuracy: 85.63%\n",
      "\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 227.4896\n",
      "Function value obtained: -0.8563\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-06\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.7290406798426325\n",
      "optimizer_type: SGD\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 836ms/step - accuracy: 0.5229 - loss: 0.8276 - val_accuracy: 0.5193 - val_loss: 0.7512\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5133 - loss: 0.8178 - val_accuracy: 0.5314 - val_loss: 0.7206\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5181 - loss: 0.8064 - val_accuracy: 0.5423 - val_loss: 0.7020\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5145 - loss: 0.7858 - val_accuracy: 0.5676 - val_loss: 0.6826\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5459 - loss: 0.7430 - val_accuracy: 0.5990 - val_loss: 0.6615\n",
      "\n",
      "Accuracy: 59.90%\n",
      "\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 127.4350\n",
      "Function value obtained: -0.5990\n",
      "Current minimum: -0.8684\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "learning rate: 8.9e-05\n",
      "num_dense_nodes: 106\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 12\n",
      "Epoch 1/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 984ms/step - accuracy: 0.7597 - loss: 0.4822 - val_accuracy: 0.6341 - val_loss: 0.8691\n",
      "Epoch 2/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8973 - loss: 0.2389 - val_accuracy: 0.8406 - val_loss: 0.3790\n",
      "Epoch 3/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9601 - loss: 0.1059 - val_accuracy: 0.8599 - val_loss: 0.3614\n",
      "Epoch 4/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9746 - loss: 0.0627 - val_accuracy: 0.7971 - val_loss: 0.6635\n",
      "Epoch 5/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9783 - loss: 0.0584 - val_accuracy: 0.8418 - val_loss: 0.6128\n",
      "Epoch 6/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9843 - loss: 0.0370 - val_accuracy: 0.8575 - val_loss: 0.4944\n",
      "Epoch 7/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9903 - loss: 0.0306 - val_accuracy: 0.8768 - val_loss: 0.5052\n",
      "Epoch 8/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9891 - loss: 0.0367 - val_accuracy: 0.8877 - val_loss: 0.5470\n",
      "Epoch 9/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9915 - loss: 0.0256 - val_accuracy: 0.8865 - val_loss: 0.5227\n",
      "Epoch 10/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9903 - loss: 0.0331 - val_accuracy: 0.8623 - val_loss: 0.5949\n",
      "Epoch 11/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.9940 - loss: 0.0284 - val_accuracy: 0.8684 - val_loss: 0.5759\n",
      "Epoch 12/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9891 - loss: 0.0246 - val_accuracy: 0.8720 - val_loss: 0.5478\n",
      "\n",
      "Accuracy: 87.20%\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 216.9321\n",
      "Function value obtained: -0.8720\n",
      "Current minimum: -0.8720\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "learning rate: 9.0e-03\n",
      "num_dense_nodes: 71\n",
      "dropout: 0.10674210916396337\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 962ms/step - accuracy: 0.4952 - loss: 0.9406 - val_accuracy: 0.5000 - val_loss: 29583965421568.0000\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5229 - loss: 0.6893 - val_accuracy: 0.5000 - val_loss: 8519622.0000\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5278 - loss: 0.6905 - val_accuracy: 0.5000 - val_loss: 6706.6123\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5447 - loss: 0.6770 - val_accuracy: 0.4988 - val_loss: 454.9076\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5278 - loss: 0.6902 - val_accuracy: 0.5362 - val_loss: 6.7040\n",
      "\n",
      "Accuracy: 53.62%\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 155.3566\n",
      "Function value obtained: -0.5362\n",
      "Current minimum: -0.8720\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "learning rate: 3.2e-04\n",
      "num_dense_nodes: 96\n",
      "dropout: 0.61158767845632\n",
      "optimizer_type: SGD\n",
      "epochs: 15\n",
      "Epoch 1/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 849ms/step - accuracy: 0.6063 - loss: 0.7044 - val_accuracy: 0.6860 - val_loss: 0.5997\n",
      "Epoch 2/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.7862 - loss: 0.4801 - val_accuracy: 0.7246 - val_loss: 0.5061\n",
      "Epoch 3/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8599 - loss: 0.3659 - val_accuracy: 0.7838 - val_loss: 0.4389\n",
      "Epoch 4/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.8696 - loss: 0.3112 - val_accuracy: 0.8249 - val_loss: 0.3761\n",
      "Epoch 5/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9022 - loss: 0.2645 - val_accuracy: 0.8514 - val_loss: 0.3512\n",
      "Epoch 6/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9227 - loss: 0.1897 - val_accuracy: 0.8551 - val_loss: 0.3178\n",
      "Epoch 7/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9517 - loss: 0.1556 - val_accuracy: 0.8647 - val_loss: 0.3506\n",
      "Epoch 8/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9638 - loss: 0.1128 - val_accuracy: 0.8684 - val_loss: 0.3352\n",
      "Epoch 9/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9638 - loss: 0.1137 - val_accuracy: 0.8708 - val_loss: 0.3793\n",
      "Epoch 10/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.9771 - loss: 0.0907 - val_accuracy: 0.8321 - val_loss: 0.4241\n",
      "Epoch 11/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9710 - loss: 0.0819 - val_accuracy: 0.8514 - val_loss: 0.3825\n",
      "Epoch 12/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.9807 - loss: 0.0691 - val_accuracy: 0.7947 - val_loss: 0.5578\n",
      "Epoch 13/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9831 - loss: 0.0580 - val_accuracy: 0.8502 - val_loss: 0.4055\n",
      "Epoch 14/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9867 - loss: 0.0532 - val_accuracy: 0.8623 - val_loss: 0.4536\n",
      "Epoch 15/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9915 - loss: 0.0352 - val_accuracy: 0.8792 - val_loss: 0.3799\n",
      "\n",
      "Accuracy: 87.92%\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 213.1151\n",
      "Function value obtained: -0.8792\n",
      "Current minimum: -0.8792\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 194\n",
      "dropout: 0.8\n",
      "optimizer_type: Adam\n",
      "epochs: 15\n",
      "Epoch 1/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 944ms/step - accuracy: 0.5060 - loss: 2.6974 - val_accuracy: 0.5000 - val_loss: 41297335287808.0000\n",
      "Epoch 2/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5592 - loss: 0.7934 - val_accuracy: 0.5000 - val_loss: 62969560.0000\n",
      "Epoch 3/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5362 - loss: 0.7409 - val_accuracy: 0.4903 - val_loss: 7338.6304\n",
      "Epoch 4/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.5338 - loss: 0.7055 - val_accuracy: 0.3913 - val_loss: 17.7888\n",
      "Epoch 5/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5338 - loss: 0.6849 - val_accuracy: 0.5278 - val_loss: 0.7318\n",
      "Epoch 6/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5531 - loss: 0.6612 - val_accuracy: 0.5193 - val_loss: 0.7837\n",
      "Epoch 7/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5604 - loss: 0.6666 - val_accuracy: 0.5918 - val_loss: 1.8109\n",
      "Epoch 8/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5435 - loss: 0.6775 - val_accuracy: 0.5145 - val_loss: 0.8675\n",
      "Epoch 9/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5495 - loss: 0.6785 - val_accuracy: 0.5435 - val_loss: 0.9692\n",
      "Epoch 10/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5519 - loss: 0.6697 - val_accuracy: 0.5507 - val_loss: 0.8130\n",
      "Epoch 11/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5580 - loss: 0.6695 - val_accuracy: 0.5447 - val_loss: 0.7790\n",
      "Epoch 12/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.5495 - loss: 0.6669 - val_accuracy: 0.5109 - val_loss: 0.7127\n",
      "Epoch 13/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5531 - loss: 0.6856 - val_accuracy: 0.6618 - val_loss: 3.1810\n",
      "Epoch 14/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5519 - loss: 0.6701 - val_accuracy: 0.6534 - val_loss: 4.4929\n",
      "Epoch 15/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5519 - loss: 0.6685 - val_accuracy: 0.6280 - val_loss: 1.7325\n",
      "\n",
      "Accuracy: 62.80%\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 238.5081\n",
      "Function value obtained: -0.6280\n",
      "Current minimum: -0.8792\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "learning rate: 1.7e-05\n",
      "num_dense_nodes: 202\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 12\n",
      "Epoch 1/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 1s/step - accuracy: 0.7174 - loss: 0.5699 - val_accuracy: 0.6027 - val_loss: 0.6611\n",
      "Epoch 2/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8225 - loss: 0.3952 - val_accuracy: 0.7379 - val_loss: 0.5191\n",
      "Epoch 3/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8829 - loss: 0.2907 - val_accuracy: 0.7874 - val_loss: 0.4240\n",
      "Epoch 4/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9130 - loss: 0.2320 - val_accuracy: 0.8321 - val_loss: 0.3666\n",
      "Epoch 5/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.9493 - loss: 0.1658 - val_accuracy: 0.8539 - val_loss: 0.3436\n",
      "Epoch 6/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9758 - loss: 0.1161 - val_accuracy: 0.8647 - val_loss: 0.3262\n",
      "Epoch 7/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9722 - loss: 0.0843 - val_accuracy: 0.8708 - val_loss: 0.3270\n",
      "Epoch 8/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9867 - loss: 0.0500 - val_accuracy: 0.8829 - val_loss: 0.3209\n",
      "Epoch 9/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9891 - loss: 0.0412 - val_accuracy: 0.8708 - val_loss: 0.3239\n",
      "Epoch 10/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9831 - loss: 0.0572 - val_accuracy: 0.8708 - val_loss: 0.3368\n",
      "Epoch 11/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9855 - loss: 0.0416 - val_accuracy: 0.8514 - val_loss: 0.3542\n",
      "Epoch 12/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9879 - loss: 0.0367 - val_accuracy: 0.8599 - val_loss: 0.3550\n",
      "\n",
      "Accuracy: 85.99%\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 215.2302\n",
      "Function value obtained: -0.8599\n",
      "Current minimum: -0.8792\n",
      "Seed:  2\n",
      "BEST ACCURACY:  {0: 0.0, 1: 0.0, 2: 0.8792270421981812, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0}\n",
      "hyper_params  [0.00031594014883392274, 0.61158767845632, 0.9538596413745806, 0.9388139159620702, 0.9944714838925183, np.int64(15), np.int64(96), np.str_('SGD')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 2\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 2\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756591016.084982   28130 service.cc:152] XLA service 0x7f15d0004c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756591016.085009   28130 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-30 21:56:56.231858: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756591017.631520   28130 cuda_dnn.cc:529] Loaded cuDNN version 91200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/13\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756591023.738133   28130 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 749ms/step\n",
      "[[np.float32(0.99990356), np.float32(9.6440315e-05)], [np.float32(0.99592716), np.float32(0.004072845)], [np.float32(0.7477327), np.float32(0.2522673)], [np.float32(0.99171025), np.float32(0.008289754)], [np.float32(0.89235), np.float32(0.10764998)], [np.float32(0.9999367), np.float32(6.330013e-05)], [np.float32(0.99964225), np.float32(0.00035774708)], [np.float32(0.85999763), np.float32(0.14000237)], [np.float32(0.99223644), np.float32(0.0077635646)], [np.float32(0.9811288), np.float32(0.018871188)], [np.float32(0.9995257), np.float32(0.00047427416)], [np.float32(0.99976355), np.float32(0.00023645163)], [np.float32(0.9992663), np.float32(0.0007336736)], [np.float32(0.9955722), np.float32(0.0044277906)], [np.float32(0.34943017), np.float32(0.6505698)], [np.float32(0.09981816), np.float32(0.90018183)], [np.float32(0.9959383), np.float32(0.004061699)], [np.float32(0.99939895), np.float32(0.00060105324)], [np.float32(0.99762434), np.float32(0.0023756623)], [np.float32(0.86830574), np.float32(0.13169426)], [np.float32(0.9871628), np.float32(0.012837172)], [np.float32(0.070728526), np.float32(0.92927146)], [np.float32(0.95793444), np.float32(0.04206556)], [np.float32(0.026379993), np.float32(0.97362)], [np.float32(0.5554528), np.float32(0.44454718)], [np.float32(0.87332135), np.float32(0.12667865)], [np.float32(0.2485946), np.float32(0.7514054)], [np.float32(0.85772854), np.float32(0.14227146)], [np.float32(0.011519209), np.float32(0.9884808)], [np.float32(0.99963796), np.float32(0.0003620386)], [np.float32(0.74519074), np.float32(0.25480926)], [np.float32(0.68642235), np.float32(0.31357765)], [np.float32(0.96779567), np.float32(0.03220433)], [np.float32(0.98915964), np.float32(0.010840356)], [np.float32(0.9778935), np.float32(0.022106528)], [np.float32(0.9636365), np.float32(0.036363482)], [np.float32(0.9935962), np.float32(0.006403804)], [np.float32(0.8615335), np.float32(0.13846648)], [np.float32(0.99321926), np.float32(0.0067807436)], [np.float32(0.93172437), np.float32(0.06827563)], [np.float32(0.99987936), np.float32(0.0001206398)], [np.float32(0.99996424), np.float32(3.5762787e-05)], [np.float32(0.9984479), np.float32(0.001552105)], [np.float32(0.9601649), np.float32(0.039835095)], [np.float32(0.8196275), np.float32(0.18037248)], [np.float32(0.9896513), np.float32(0.010348678)], [np.float32(0.99993646), np.float32(6.353855e-05)], [np.float32(0.9715014), np.float32(0.02849859)], [np.float32(0.9345647), np.float32(0.06543529)], [np.float32(0.9993493), np.float32(0.0006507039)], [np.float32(0.9999068), np.float32(9.3221664e-05)], [np.float32(0.968309), np.float32(0.031691015)], [np.float32(0.98751754), np.float32(0.012482464)], [np.float32(0.85238314), np.float32(0.14761686)], [np.float32(0.5138917), np.float32(0.4861083)], [np.float32(0.9995092), np.float32(0.00049078465)], [np.float32(0.8011902), np.float32(0.1988098)], [np.float32(0.011026703), np.float32(0.9889733)], [np.float32(0.79676855), np.float32(0.20323145)], [np.float32(0.9989217), np.float32(0.0010783076)], [np.float32(0.99652904), np.float32(0.0034709573)], [np.float32(0.8901995), np.float32(0.10980052)], [np.float32(0.042351), np.float32(0.957649)], [np.float32(0.35207307), np.float32(0.6479269)], [np.float32(0.9625594), np.float32(0.037440598)], [np.float32(0.9991049), np.float32(0.00089508295)], [np.float32(0.9998863), np.float32(0.00011372566)], [np.float32(0.005510418), np.float32(0.9944896)], [np.float32(0.9990717), np.float32(0.00092828274)], [np.float32(0.96614176), np.float32(0.03385824)], [np.float32(0.70387477), np.float32(0.29612523)], [np.float32(0.99126035), np.float32(0.00873965)], [np.float32(0.9978415), np.float32(0.0021585226)], [np.float32(0.80089027), np.float32(0.19910973)], [np.float32(0.9998424), np.float32(0.00015759468)], [np.float32(0.99286395), np.float32(0.007136047)], [np.float32(0.91600907), np.float32(0.08399093)], [np.float32(0.074715644), np.float32(0.9252844)], [np.float32(0.99993014), np.float32(6.9856644e-05)], [np.float32(0.9967679), np.float32(0.0032321215)], [np.float32(0.9987184), np.float32(0.0012816191)], [np.float32(0.45267993), np.float32(0.54732007)], [np.float32(0.33736804), np.float32(0.662632)], [np.float32(0.7276799), np.float32(0.2723201)], [np.float32(0.9956867), np.float32(0.00431329)], [np.float32(0.9999312), np.float32(6.878376e-05)], [np.float32(0.9804766), np.float32(0.019523382)], [np.float32(0.94559354), np.float32(0.054406464)], [np.float32(0.9609542), np.float32(0.03904581)], [np.float32(0.9969914), np.float32(0.003008604)], [np.float32(0.07151944), np.float32(0.92848057)], [np.float32(0.16046819), np.float32(0.8395318)], [np.float32(0.99391913), np.float32(0.006080866)], [np.float32(0.54785776), np.float32(0.45214224)], [np.float32(0.99938214), np.float32(0.00061786175)], [np.float32(0.22224958), np.float32(0.77775043)], [np.float32(0.99979055), np.float32(0.00020945072)], [np.float32(0.8978156), np.float32(0.102184415)], [np.float32(0.99973196), np.float32(0.0002680421)], [np.float32(0.9981869), np.float32(0.0018131137)], [np.float32(0.94200116), np.float32(0.057998836)], [np.float32(0.978312), np.float32(0.021687984)], [np.float32(0.99721247), np.float32(0.0027875304)], [np.float32(0.9919946), np.float32(0.008005381)], [np.float32(0.99574864), np.float32(0.004251361)], [np.float32(0.23948354), np.float32(0.76051646)], [np.float32(0.9392574), np.float32(0.060742617)], [np.float32(0.9996918), np.float32(0.00030821562)], [np.float32(0.95088005), np.float32(0.04911995)], [np.float32(0.99146384), np.float32(0.00853616)], [np.float32(0.0051995814), np.float32(0.99480045)], [np.float32(0.6445276), np.float32(0.3554724)], [np.float32(0.59132206), np.float32(0.40867794)], [np.float32(0.8291772), np.float32(0.1708228)], [np.float32(0.9997434), np.float32(0.000256598)], [np.float32(0.92613304), np.float32(0.07386696)], [np.float32(0.9986829), np.float32(0.0013170838)], [np.float32(0.022026522), np.float32(0.97797346)], [np.float32(0.49029455), np.float32(0.5097054)], [np.float32(0.78775775), np.float32(0.21224225)], [np.float32(0.99828726), np.float32(0.0017127395)], [np.float32(0.9791789), np.float32(0.020821095)], [np.float32(0.99867386), np.float32(0.0013261437)], [np.float32(0.99941534), np.float32(0.00058466196)], [np.float32(0.9974094), np.float32(0.0025905967)], [np.float32(0.99623114), np.float32(0.0037688613)], [np.float32(0.85614735), np.float32(0.14385265)], [np.float32(0.9997272), np.float32(0.00027281046)], [np.float32(0.9994573), np.float32(0.0005427003)], [np.float32(0.7918808), np.float32(0.20811921)], [np.float32(0.26556233), np.float32(0.7344377)], [np.float32(0.99624217), np.float32(0.0037578344)], [np.float32(0.99994123), np.float32(5.877018e-05)], [np.float32(0.99518436), np.float32(0.004815638)], [np.float32(0.999225), np.float32(0.0007749796)], [np.float32(0.9999608), np.float32(3.9219856e-05)], [np.float32(0.7348598), np.float32(0.26514018)], [np.float32(0.2125356), np.float32(0.7874644)], [np.float32(0.107042454), np.float32(0.89295757)], [np.float32(0.9994694), np.float32(0.00053060055)], [np.float32(0.9975414), np.float32(0.0024585724)], [np.float32(0.99454826), np.float32(0.005451739)], [np.float32(0.9850417), np.float32(0.014958322)], [np.float32(0.99701774), np.float32(0.0029822588)], [np.float32(0.6430729), np.float32(0.3569271)], [np.float32(0.7861618), np.float32(0.21383822)], [np.float32(0.7826216), np.float32(0.21737838)], [np.float32(0.9598495), np.float32(0.040150523)], [np.float32(0.99507433), np.float32(0.0049256682)], [np.float32(0.9992543), np.float32(0.0007457137)], [np.float32(0.19397289), np.float32(0.8060271)], [np.float32(0.08969677), np.float32(0.91030324)], [np.float32(0.99986494), np.float32(0.00013506413)], [np.float32(0.10130396), np.float32(0.89869606)], [np.float32(0.99974483), np.float32(0.00025516748)], [np.float32(0.99995077), np.float32(4.9233437e-05)], [np.float32(0.99697053), np.float32(0.0030294657)], [np.float32(0.85171103), np.float32(0.14828897)], [np.float32(0.99836916), np.float32(0.0016308427)], [np.float32(0.9998357), np.float32(0.0001642704)], [np.float32(0.994972), np.float32(0.0050280094)], [np.float32(0.9985745), np.float32(0.0014255047)], [np.float32(0.95723367), np.float32(0.042766333)], [np.float32(0.176658), np.float32(0.82334197)], [np.float32(0.998226), np.float32(0.001774013)], [np.float32(0.6801168), np.float32(0.31988323)], [np.float32(0.99609745), np.float32(0.0039025545)], [np.float32(0.9876466), np.float32(0.01235342)], [np.float32(0.68101734), np.float32(0.31898266)], [np.float32(0.9994683), np.float32(0.00053167343)], [np.float32(0.99960876), np.float32(0.0003912449)], [np.float32(0.7990889), np.float32(0.2009111)], [np.float32(0.99609685), np.float32(0.0039031506)], [np.float32(0.2120183), np.float32(0.7879817)], [np.float32(0.95985067), np.float32(0.04014933)], [np.float32(0.999954), np.float32(4.6014786e-05)], [np.float32(0.99964607), np.float32(0.00035393238)], [np.float32(0.9981375), np.float32(0.0018625259)], [np.float32(0.9992275), np.float32(0.0007724762)], [np.float32(0.86695945), np.float32(0.13304055)], [np.float32(0.9982734), np.float32(0.0017266273)], [np.float32(0.82756585), np.float32(0.17243415)], [np.float32(0.30099666), np.float32(0.69900334)], [np.float32(0.9977495), np.float32(0.0022504926)], [np.float32(0.99814045), np.float32(0.0018595457)], [np.float32(0.6401217), np.float32(0.3598783)], [np.float32(0.89407134), np.float32(0.10592866)], [np.float32(0.8729661), np.float32(0.12703389)], [np.float32(0.99881786), np.float32(0.0011821389)], [np.float32(0.991816), np.float32(0.008184016)], [np.float32(0.79979), np.float32(0.20020998)], [np.float32(0.9997625), np.float32(0.00023752451)], [np.float32(0.9781733), np.float32(0.021826684)], [np.float32(0.9610908), np.float32(0.038909197)], [np.float32(0.99737144), np.float32(0.0026285648)], [np.float32(0.99395), np.float32(0.0060499907)], [np.float32(0.9867346), np.float32(0.013265371)], [np.float32(0.28294295), np.float32(0.71705705)], [np.float32(0.7400447), np.float32(0.2599553)], [np.float32(0.12751068), np.float32(0.87248933)], [np.float32(0.00095483084), np.float32(0.9990452)], [np.float32(0.0001454989), np.float32(0.9998545)], [np.float32(0.001051375), np.float32(0.99894863)], [np.float32(0.010570928), np.float32(0.98942906)], [np.float32(7.084901e-05), np.float32(0.99992913)], [np.float32(0.00012562911), np.float32(0.99987435)], [np.float32(0.12473609), np.float32(0.8752639)], [np.float32(0.06399448), np.float32(0.93600553)], [np.float32(0.02568304), np.float32(0.97431695)], [np.float32(0.0013545402), np.float32(0.9986455)], [np.float32(0.0017141706), np.float32(0.99828583)], [np.float32(0.99882525), np.float32(0.001174748)], [np.float32(0.02987815), np.float32(0.97012186)], [np.float32(0.9322703), np.float32(0.06772971)], [np.float32(0.0032811454), np.float32(0.9967189)], [np.float32(0.036811672), np.float32(0.96318835)], [np.float32(0.0010980568), np.float32(0.99890196)], [np.float32(0.0017885446), np.float32(0.99821144)], [np.float32(0.0046618315), np.float32(0.99533814)], [np.float32(0.0001222487), np.float32(0.99987775)], [np.float32(0.005691819), np.float32(0.9943082)], [np.float32(2.606971e-06), np.float32(0.9999974)], [np.float32(0.049949337), np.float32(0.95005065)], [np.float32(0.088383295), np.float32(0.9116167)], [np.float32(0.0019639425), np.float32(0.9980361)], [np.float32(0.086341605), np.float32(0.9136584)], [np.float32(0.58533597), np.float32(0.41466403)], [np.float32(0.00083184446), np.float32(0.99916816)], [np.float32(0.5056373), np.float32(0.4943627)], [np.float32(0.021085344), np.float32(0.9789147)], [np.float32(0.9978276), np.float32(0.0021724105)], [np.float32(0.91115135), np.float32(0.08884865)], [np.float32(0.001706074), np.float32(0.99829394)], [np.float32(0.031007392), np.float32(0.9689926)], [np.float32(0.39747673), np.float32(0.60252327)], [np.float32(3.5441626e-05), np.float32(0.99996454)], [np.float32(0.00020049483), np.float32(0.9997995)], [np.float32(0.005696679), np.float32(0.99430335)], [np.float32(0.0036332377), np.float32(0.99636674)], [np.float32(0.0052948226), np.float32(0.9947052)], [np.float32(0.021704972), np.float32(0.978295)], [np.float32(0.0033815068), np.float32(0.9966185)], [np.float32(0.09016862), np.float32(0.9098314)], [np.float32(0.0010419358), np.float32(0.99895805)], [np.float32(7.5599255e-06), np.float32(0.99999243)], [np.float32(0.8641526), np.float32(0.13584739)], [np.float32(0.005805421), np.float32(0.99419457)], [np.float32(0.4022553), np.float32(0.5977447)], [np.float32(0.001964095), np.float32(0.9980359)], [np.float32(0.01028887), np.float32(0.9897111)], [np.float32(0.0023551455), np.float32(0.99764484)], [np.float32(0.002008096), np.float32(0.9979919)], [np.float32(0.0025887722), np.float32(0.99741125)], [np.float32(0.0042992043), np.float32(0.9957008)], [np.float32(0.9800858), np.float32(0.01991421)], [np.float32(0.0010927478), np.float32(0.99890727)], [np.float32(0.00030532244), np.float32(0.9996947)], [np.float32(5.4637967e-05), np.float32(0.99994534)], [np.float32(0.18977296), np.float32(0.81022704)], [np.float32(0.58934724), np.float32(0.41065276)], [np.float32(0.05287538), np.float32(0.9471246)], [np.float32(0.004533454), np.float32(0.99546653)], [np.float32(0.021725455), np.float32(0.9782745)], [np.float32(0.98410714), np.float32(0.015892863)], [np.float32(0.15622826), np.float32(0.84377176)], [np.float32(0.00059036486), np.float32(0.9994096)], [np.float32(5.6549085e-05), np.float32(0.99994344)], [np.float32(0.0039450675), np.float32(0.99605495)], [np.float32(0.026427874), np.float32(0.97357213)], [np.float32(0.00019928494), np.float32(0.99980074)], [np.float32(0.90559494), np.float32(0.094405055)], [np.float32(0.009687786), np.float32(0.9903122)], [np.float32(0.016890524), np.float32(0.9831095)], [np.float32(0.01231573), np.float32(0.98768425)], [np.float32(0.03771763), np.float32(0.96228236)], [np.float32(0.0005761157), np.float32(0.99942386)], [np.float32(0.00032590434), np.float32(0.9996741)], [np.float32(0.0048210938), np.float32(0.9951789)], [np.float32(1.0114305e-05), np.float32(0.99998987)], [np.float32(0.0003625712), np.float32(0.9996374)], [np.float32(0.4096649), np.float32(0.59033513)], [np.float32(0.007095085), np.float32(0.9929049)], [np.float32(0.001982598), np.float32(0.99801743)], [np.float32(0.057508763), np.float32(0.94249123)], [np.float32(0.00031839177), np.float32(0.9996816)], [np.float32(0.9995009), np.float32(0.0004991293)], [np.float32(0.0022358552), np.float32(0.99776417)], [np.float32(0.00031835263), np.float32(0.99968165)], [np.float32(4.991534e-05), np.float32(0.9999501)], [np.float32(4.8154645e-05), np.float32(0.99995184)], [np.float32(0.00013152388), np.float32(0.99986845)], [np.float32(4.940545e-06), np.float32(0.99999505)], [np.float32(0.0039242734), np.float32(0.99607575)], [np.float32(0.0132787395), np.float32(0.9867213)], [np.float32(0.00065617985), np.float32(0.9993438)], [np.float32(0.0013781945), np.float32(0.9986218)], [np.float32(0.00609193), np.float32(0.99390805)], [np.float32(0.005884733), np.float32(0.9941153)], [np.float32(0.023929916), np.float32(0.9760701)], [np.float32(0.00010109851), np.float32(0.9998989)], [np.float32(0.0018495648), np.float32(0.9981504)], [np.float32(6.665639e-06), np.float32(0.9999933)], [np.float32(1.8746508e-05), np.float32(0.9999812)], [np.float32(0.00020504971), np.float32(0.99979496)], [np.float32(0.44807243), np.float32(0.55192757)], [np.float32(0.0005260179), np.float32(0.999474)], [np.float32(0.0016314557), np.float32(0.99836856)], [np.float32(1.1197115e-05), np.float32(0.9999888)], [np.float32(0.0035906911), np.float32(0.9964093)], [np.float32(9.76828e-05), np.float32(0.9999023)], [np.float32(0.0665787), np.float32(0.9334213)], [np.float32(0.00023643566), np.float32(0.99976355)], [np.float32(7.945298e-05), np.float32(0.99992055)], [np.float32(0.020419573), np.float32(0.9795804)], [np.float32(0.00022629497), np.float32(0.9997737)], [np.float32(0.010832568), np.float32(0.98916745)], [np.float32(0.29355043), np.float32(0.70644957)], [np.float32(7.843318e-05), np.float32(0.99992156)], [np.float32(8.089417e-05), np.float32(0.9999191)], [np.float32(0.0010590355), np.float32(0.99894094)], [np.float32(9.134998e-05), np.float32(0.9999086)], [np.float32(0.8386934), np.float32(0.16130662)], [np.float32(0.07135032), np.float32(0.92864966)], [np.float32(0.053657636), np.float32(0.94634235)], [np.float32(0.0024026267), np.float32(0.9975974)], [np.float32(0.00808392), np.float32(0.99191606)], [np.float32(0.0007262764), np.float32(0.9992737)], [np.float32(0.0019913106), np.float32(0.99800867)], [np.float32(0.0017296869), np.float32(0.99827033)], [np.float32(2.902318e-05), np.float32(0.999971)], [np.float32(0.028840868), np.float32(0.97115916)], [np.float32(0.00027637495), np.float32(0.9997236)], [np.float32(0.0017013038), np.float32(0.9982987)], [np.float32(0.0007604347), np.float32(0.99923956)], [np.float32(0.0026899725), np.float32(0.99731004)], [np.float32(0.00048358698), np.float32(0.9995164)], [np.float32(0.008345425), np.float32(0.9916546)], [np.float32(0.00029417613), np.float32(0.99970585)], [np.float32(0.0030308017), np.float32(0.9969692)], [np.float32(4.3506578e-05), np.float32(0.9999565)], [np.float32(0.020454854), np.float32(0.9795451)], [np.float32(0.000112218906), np.float32(0.99988776)], [np.float32(0.3356744), np.float32(0.6643256)], [np.float32(0.0003791783), np.float32(0.9996208)], [np.float32(0.030736765), np.float32(0.96926326)], [np.float32(0.6025061), np.float32(0.3974939)], [np.float32(0.055749394), np.float32(0.9442506)], [np.float32(0.20423657), np.float32(0.79576343)], [np.float32(0.0024331037), np.float32(0.9975669)], [np.float32(0.025544625), np.float32(0.97445536)], [np.float32(0.7142144), np.float32(0.28578562)], [np.float32(0.033496596), np.float32(0.9665034)], [np.float32(0.024789155), np.float32(0.97521085)], [np.float32(0.0048372126), np.float32(0.9951628)], [np.float32(0.00015049391), np.float32(0.9998495)], [np.float32(0.015774416), np.float32(0.9842256)], [np.float32(0.042511567), np.float32(0.9574884)], [np.float32(0.0012908396), np.float32(0.99870914)], [np.float32(0.000549274), np.float32(0.99945074)], [np.float32(0.3644053), np.float32(0.6355947)], [np.float32(0.40246457), np.float32(0.59753543)], [np.float32(0.0018213999), np.float32(0.9981786)], [np.float32(0.5771544), np.float32(0.4228456)], [np.float32(4.393586e-05), np.float32(0.9999561)], [np.float32(0.00089257007), np.float32(0.9991074)], [np.float32(0.000119188386), np.float32(0.9998808)], [np.float32(0.0001906184), np.float32(0.9998094)], [np.float32(1.9673209e-05), np.float32(0.99998033)], [np.float32(0.40686455), np.float32(0.5931355)], [np.float32(5.8109057e-05), np.float32(0.9999419)], [np.float32(0.0002950837), np.float32(0.9997049)], [np.float32(7.4474774e-06), np.float32(0.99999255)], [np.float32(0.974996), np.float32(0.02500403)], [np.float32(0.002204492), np.float32(0.9977955)], [np.float32(0.0018858059), np.float32(0.99811417)], [np.float32(0.3117104), np.float32(0.68828964)], [np.float32(0.99508035), np.float32(0.004919648)], [np.float32(0.25841036), np.float32(0.74158967)], [np.float32(0.00037321006), np.float32(0.9996268)], [np.float32(0.0090906415), np.float32(0.99090934)], [np.float32(0.12400264), np.float32(0.87599736)], [np.float32(6.6387205e-05), np.float32(0.9999336)], [np.float32(0.00020371424), np.float32(0.9997963)], [np.float32(0.2351667), np.float32(0.76483333)], [np.float32(0.014259738), np.float32(0.98574024)], [np.float32(0.00010140641), np.float32(0.9998986)], [np.float32(0.002158538), np.float32(0.9978415)], [np.float32(8.039745e-05), np.float32(0.9999196)], [np.float32(2.8981634e-05), np.float32(0.99997103)], [np.float32(0.96632296), np.float32(0.03367704)], [np.float32(0.0073275045), np.float32(0.9926725)], [np.float32(0.0015326397), np.float32(0.9984674)], [np.float32(0.018515557), np.float32(0.9814844)], [np.float32(0.04309815), np.float32(0.95690185)], [np.float32(0.0044993367), np.float32(0.9955007)], [np.float32(0.0014776967), np.float32(0.9985223)], [np.float32(0.003985808), np.float32(0.9960142)], [np.float32(0.063347585), np.float32(0.9366524)], [np.float32(0.20306194), np.float32(0.79693806)], [np.float32(1.672289e-05), np.float32(0.99998325)]]\n",
      "Unseen set\n",
      "      ID        Dx     % Mel     % Nev\n",
      "0      0  Melanoma  0.999904  0.000096\n",
      "1      1  Melanoma  0.995927  0.004073\n",
      "2      2  Melanoma  0.747733  0.252267\n",
      "3      3  Melanoma  0.991710  0.008290\n",
      "4      4  Melanoma  0.892350  0.107650\n",
      "..   ...       ...       ...       ...\n",
      "395  395     Nevus  0.001478  0.998522\n",
      "396  396     Nevus  0.003986  0.996014\n",
      "397  397     Nevus  0.063348  0.936652\n",
      "398  398     Nevus  0.203062  0.796938\n",
      "399  399     Nevus  0.000017  0.999983\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
