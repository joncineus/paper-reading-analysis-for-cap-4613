{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Reading Analysis - Code Implementation\n",
    "### Model 14 Training, Hyperparameter Search and Evaluation\n",
    "### Jonathan Alcineus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 23:46:34.912940: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 23:46:34.937649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756597594.960492   13998 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756597594.967649   13998 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756597594.984550   13998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756597594.984574   13998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756597594.984576   13998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756597594.984578   13998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-30 23:46:34.989844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These handle the file locations and importing the dataframe from the saved datafile from the authors files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# These handle the image processing, editing, or displaying that needs to be performed\n",
    "import cv2 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# These handle training the convolutional neural network (CNN) model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DNNorDermatologist\n"
     ]
    }
   ],
   "source": [
    "# This changes the home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "os.chdir(home_directory)\n",
    "\n",
    "# Then goes to the folder where the data lies\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Ensures that we are in the correct folder\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to build the classifier and the ranges for each model to find the optimal parameters, or searching through hyperparameters\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Real(1e-6, 0.01, \"log-uniform\", name='learning_rate'),\n",
    "          Real(0.1, 0.8, name='dropout'),\n",
    "          Real(0.8, 1.0, name='momentum'),\n",
    "          Real(0.9, 1.0, name='beta_1'),\n",
    "          Real(0.99, 1.0, name='beta_2'),\n",
    "          Integer(low=5,high=20, name = 'epochs'),\n",
    "          Integer(low=50, high=225, name='num_dense_nodes'),\n",
    "          Categorical(categories=['SGD', 'Adam'],\n",
    "                             name='optimizer_type')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The first part to implenment is the creation of random models\n",
    "if not os.path.isdir('suite_of_models'):\n",
    "    os.mkdir('suite_of_models')\n",
    "\n",
    "def make_a_model(learning_rate, dropout, momentum, beta_1, beta_2, num_dense_nodes, optimizer_type):\n",
    "    # Like in the paper the base model for the image classifcation will be imagenet\n",
    "    base_model = InceptionV3(weights='imagenet',input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "    # Fine tune the model with extra dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Selects a type of model optimizer\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_type == \"SGD\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with basic parameters and the batch size for the models\n",
    "batch_size = 16\n",
    "best_accuracy = {} \n",
    "for seed in range(15):\n",
    "  best_accuracy[seed] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently training on seed: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "learning rate: 2.8e-06\n",
      "num_dense_nodes: 175\n",
      "dropout: 0.24425959111873083\n",
      "optimizer_type: SGD\n",
      "epochs: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756037056.308757   41229 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756037082.093169   42299 service.cc:152] XLA service 0x7fb6bc0037b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756037082.093197   42299 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-24 12:04:43.081662: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756037086.301096   42299 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "2025-08-24 12:04:55.024476: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:04:55.170983: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:04:55.513544: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:04:55.656942: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/52\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48:06\u001b[0m 57s/step - accuracy: 0.5625 - loss: 0.6701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756037116.623117   42299 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4928 - loss: 0.7267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 12:05:33.377983: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:05:33.524416: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:05:33.832736: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-24 12:05:33.975248: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 985ms/step - accuracy: 0.4891 - loss: 0.7305 - val_accuracy: 0.5109 - val_loss: 0.7204\n",
      "Epoch 2/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5012 - loss: 0.7179 - val_accuracy: 0.4976 - val_loss: 0.7325\n",
      "Epoch 3/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5024 - loss: 0.7241 - val_accuracy: 0.4758 - val_loss: 0.7323\n",
      "Epoch 4/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5085 - loss: 0.7235 - val_accuracy: 0.4879 - val_loss: 0.7278\n",
      "Epoch 5/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.4807 - loss: 0.7315 - val_accuracy: 0.4964 - val_loss: 0.7233\n",
      "Epoch 6/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5121 - loss: 0.7188 - val_accuracy: 0.4746 - val_loss: 0.7190\n",
      "Epoch 7/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5326 - loss: 0.7184 - val_accuracy: 0.4819 - val_loss: 0.7195\n",
      "Epoch 8/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5060 - loss: 0.7078 - val_accuracy: 0.4928 - val_loss: 0.7130\n",
      "Epoch 9/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.4819 - loss: 0.7220 - val_accuracy: 0.4855 - val_loss: 0.7114\n",
      "Epoch 10/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5278 - loss: 0.7037 - val_accuracy: 0.4795 - val_loss: 0.7095\n",
      "Epoch 11/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.4952 - loss: 0.7159 - val_accuracy: 0.4867 - val_loss: 0.7067\n",
      "Epoch 12/12\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.4988 - loss: 0.7214 - val_accuracy: 0.4940 - val_loss: 0.7041\n",
      "\n",
      "Accuracy: 49.40%\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 197.4138\n",
      "Function value obtained: -0.4940\n",
      "Current minimum: -0.4940\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "learning rate: 1.2e-06\n",
      "num_dense_nodes: 132\n",
      "dropout: 0.3318387907854581\n",
      "optimizer_type: SGD\n",
      "epochs: 17\n",
      "Epoch 1/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 826ms/step - accuracy: 0.4843 - loss: 0.7486 - val_accuracy: 0.4855 - val_loss: 0.7282\n",
      "Epoch 2/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.5060 - loss: 0.7340 - val_accuracy: 0.4879 - val_loss: 0.7217\n",
      "Epoch 3/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - accuracy: 0.4976 - loss: 0.7417 - val_accuracy: 0.5121 - val_loss: 0.7105\n",
      "Epoch 4/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5085 - loss: 0.7359 - val_accuracy: 0.4843 - val_loss: 0.7173\n",
      "Epoch 5/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5109 - loss: 0.7266 - val_accuracy: 0.5060 - val_loss: 0.7176\n",
      "Epoch 6/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5242 - loss: 0.7300 - val_accuracy: 0.5085 - val_loss: 0.7142\n",
      "Epoch 7/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.4952 - loss: 0.7427 - val_accuracy: 0.4928 - val_loss: 0.7143\n",
      "Epoch 8/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.5012 - loss: 0.7316 - val_accuracy: 0.4903 - val_loss: 0.7156\n",
      "Epoch 9/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5085 - loss: 0.7269 - val_accuracy: 0.4891 - val_loss: 0.7146\n",
      "Epoch 10/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5097 - loss: 0.7287 - val_accuracy: 0.4843 - val_loss: 0.7145\n",
      "Epoch 11/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5000 - loss: 0.7452 - val_accuracy: 0.4867 - val_loss: 0.7139\n",
      "Epoch 12/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.4831 - loss: 0.7288 - val_accuracy: 0.4879 - val_loss: 0.7130\n",
      "Epoch 13/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.5085 - loss: 0.7235 - val_accuracy: 0.4952 - val_loss: 0.7129\n",
      "Epoch 14/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.4843 - loss: 0.7383 - val_accuracy: 0.4903 - val_loss: 0.7123\n",
      "Epoch 15/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.5085 - loss: 0.7223 - val_accuracy: 0.4891 - val_loss: 0.7117\n",
      "Epoch 16/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5109 - loss: 0.7215 - val_accuracy: 0.4940 - val_loss: 0.7119\n",
      "Epoch 17/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5145 - loss: 0.7207 - val_accuracy: 0.4891 - val_loss: 0.7115\n",
      "\n",
      "Accuracy: 48.91%\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 225.3055\n",
      "Function value obtained: -0.4891\n",
      "Current minimum: -0.4940\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "learning rate: 8.4e-06\n",
      "num_dense_nodes: 176\n",
      "dropout: 0.5022618510698282\n",
      "optimizer_type: SGD\n",
      "epochs: 8\n",
      "Epoch 1/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 833ms/step - accuracy: 0.5157 - loss: 0.7585 - val_accuracy: 0.4348 - val_loss: 0.7654\n",
      "Epoch 2/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5278 - loss: 0.7450 - val_accuracy: 0.4928 - val_loss: 0.7353\n",
      "Epoch 3/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.4964 - loss: 0.7724 - val_accuracy: 0.5072 - val_loss: 0.7197\n",
      "Epoch 4/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.5012 - loss: 0.7517 - val_accuracy: 0.5278 - val_loss: 0.7067\n",
      "Epoch 5/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5266 - loss: 0.7380 - val_accuracy: 0.5435 - val_loss: 0.6966\n",
      "Epoch 6/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5386 - loss: 0.7207 - val_accuracy: 0.5495 - val_loss: 0.6911\n",
      "Epoch 7/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5435 - loss: 0.7124 - val_accuracy: 0.5386 - val_loss: 0.6860\n",
      "Epoch 8/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5483 - loss: 0.7147 - val_accuracy: 0.5519 - val_loss: 0.6810\n",
      "\n",
      "Accuracy: 55.19%\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 148.8096\n",
      "Function value obtained: -0.5519\n",
      "Current minimum: -0.5519\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "learning rate: 1.6e-04\n",
      "num_dense_nodes: 214\n",
      "dropout: 0.16463032319829368\n",
      "optimizer_type: Adam\n",
      "epochs: 15\n",
      "Epoch 1/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 989ms/step - accuracy: 0.7814 - loss: 0.4789 - val_accuracy: 0.6063 - val_loss: 2.0979\n",
      "Epoch 2/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.8756 - loss: 0.3049 - val_accuracy: 0.7814 - val_loss: 0.7214\n",
      "Epoch 3/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.9336 - loss: 0.1726 - val_accuracy: 0.8539 - val_loss: 0.5272\n",
      "Epoch 4/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9698 - loss: 0.0842 - val_accuracy: 0.8514 - val_loss: 0.6468\n",
      "Epoch 5/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9734 - loss: 0.0807 - val_accuracy: 0.8708 - val_loss: 0.5213\n",
      "Epoch 6/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9807 - loss: 0.0613 - val_accuracy: 0.8744 - val_loss: 0.6327\n",
      "Epoch 7/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9928 - loss: 0.0386 - val_accuracy: 0.8611 - val_loss: 0.6783\n",
      "Epoch 8/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9891 - loss: 0.0339 - val_accuracy: 0.8357 - val_loss: 0.8429\n",
      "Epoch 9/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9879 - loss: 0.0356 - val_accuracy: 0.8490 - val_loss: 0.7528\n",
      "Epoch 10/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9879 - loss: 0.0513 - val_accuracy: 0.8575 - val_loss: 0.8813\n",
      "Epoch 11/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9698 - loss: 0.0649 - val_accuracy: 0.8575 - val_loss: 0.7321\n",
      "Epoch 12/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.9795 - loss: 0.0752 - val_accuracy: 0.8732 - val_loss: 0.7052\n",
      "Epoch 13/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.9879 - loss: 0.0452 - val_accuracy: 0.8647 - val_loss: 0.6201\n",
      "Epoch 14/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9940 - loss: 0.0319 - val_accuracy: 0.8671 - val_loss: 0.6342\n",
      "Epoch 15/15\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9807 - loss: 0.0476 - val_accuracy: 0.8514 - val_loss: 0.5821\n",
      "\n",
      "Accuracy: 85.14%\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 241.4307\n",
      "Function value obtained: -0.8514\n",
      "Current minimum: -0.8514\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "learning rate: 6.7e-05\n",
      "num_dense_nodes: 173\n",
      "dropout: 0.1228780655287722\n",
      "optimizer_type: Adam\n",
      "epochs: 13\n",
      "Epoch 1/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 972ms/step - accuracy: 0.7826 - loss: 0.4622 - val_accuracy: 0.6534 - val_loss: 0.7542\n",
      "Epoch 2/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9022 - loss: 0.2333 - val_accuracy: 0.7814 - val_loss: 0.5270\n",
      "Epoch 3/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9529 - loss: 0.1286 - val_accuracy: 0.7802 - val_loss: 0.5319\n",
      "Epoch 4/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9867 - loss: 0.0540 - val_accuracy: 0.8249 - val_loss: 0.5323\n",
      "Epoch 5/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9734 - loss: 0.0856 - val_accuracy: 0.8382 - val_loss: 0.4436\n",
      "Epoch 6/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9831 - loss: 0.0440 - val_accuracy: 0.8659 - val_loss: 0.4794\n",
      "Epoch 7/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.9903 - loss: 0.0303 - val_accuracy: 0.8780 - val_loss: 0.4339\n",
      "Epoch 8/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9819 - loss: 0.0570 - val_accuracy: 0.8804 - val_loss: 0.3633\n",
      "Epoch 9/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9734 - loss: 0.0617 - val_accuracy: 0.8599 - val_loss: 0.4301\n",
      "Epoch 10/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9855 - loss: 0.0492 - val_accuracy: 0.8768 - val_loss: 0.5101\n",
      "Epoch 11/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9807 - loss: 0.0421 - val_accuracy: 0.8466 - val_loss: 0.5682\n",
      "Epoch 12/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9940 - loss: 0.0231 - val_accuracy: 0.8418 - val_loss: 0.6511\n",
      "Epoch 13/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9988 - loss: 0.0066 - val_accuracy: 0.8635 - val_loss: 0.5477\n",
      "\n",
      "Accuracy: 86.35%\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 221.4425\n",
      "Function value obtained: -0.8635\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-06\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.652138428958663\n",
      "optimizer_type: Adam\n",
      "epochs: 5\n",
      "Epoch 1/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 979ms/step - accuracy: 0.4819 - loss: 0.7624 - val_accuracy: 0.4795 - val_loss: 0.7213\n",
      "Epoch 2/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5145 - loss: 0.7297 - val_accuracy: 0.4891 - val_loss: 0.7172\n",
      "Epoch 3/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.4928 - loss: 0.7486 - val_accuracy: 0.5157 - val_loss: 0.7028\n",
      "Epoch 4/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5507 - loss: 0.7054 - val_accuracy: 0.5882 - val_loss: 0.6805\n",
      "Epoch 5/5\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5737 - loss: 0.6893 - val_accuracy: 0.6244 - val_loss: 0.6632\n",
      "\n",
      "Accuracy: 62.44%\n",
      "\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 152.3688\n",
      "Function value obtained: -0.6244\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 981ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 273.8153\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "learning rate: 5.9e-03\n",
      "num_dense_nodes: 93\n",
      "dropout: 0.5918224038187309\n",
      "optimizer_type: SGD\n",
      "epochs: 8\n",
      "Epoch 1/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 831ms/step - accuracy: 0.7693 - loss: 0.5081 - val_accuracy: 0.5519 - val_loss: 0.7212\n",
      "Epoch 2/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8249 - loss: 0.3918 - val_accuracy: 0.8019 - val_loss: 0.4137\n",
      "Epoch 3/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8406 - loss: 0.3410 - val_accuracy: 0.5857 - val_loss: 1.0272\n",
      "Epoch 4/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8708 - loss: 0.3258 - val_accuracy: 0.8237 - val_loss: 0.4951\n",
      "Epoch 5/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8780 - loss: 0.2575 - val_accuracy: 0.8406 - val_loss: 0.4809\n",
      "Epoch 6/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8925 - loss: 0.2574 - val_accuracy: 0.7959 - val_loss: 0.4179\n",
      "Epoch 7/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9215 - loss: 0.1951 - val_accuracy: 0.7923 - val_loss: 0.7626\n",
      "Epoch 8/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9106 - loss: 0.2110 - val_accuracy: 0.8333 - val_loss: 0.3535\n",
      "\n",
      "Accuracy: 83.33%\n",
      "\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 148.4163\n",
      "Function value obtained: -0.8333\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "learning rate: 8.5e-04\n",
      "num_dense_nodes: 73\n",
      "dropout: 0.12219951744451002\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 853ms/step - accuracy: 0.7210 - loss: 0.5359 - val_accuracy: 0.6522 - val_loss: 0.8611\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8309 - loss: 0.3573 - val_accuracy: 0.6739 - val_loss: 0.8386\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8671 - loss: 0.3203 - val_accuracy: 0.6715 - val_loss: 0.6635\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8466 - loss: 0.3368 - val_accuracy: 0.5411 - val_loss: 0.8079\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8841 - loss: 0.3175 - val_accuracy: 0.5568 - val_loss: 0.8507\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8841 - loss: 0.2795 - val_accuracy: 0.7814 - val_loss: 0.6465\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8901 - loss: 0.2771 - val_accuracy: 0.6244 - val_loss: 1.3722\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8901 - loss: 0.2684 - val_accuracy: 0.5254 - val_loss: 3.0380\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.8901 - loss: 0.2636 - val_accuracy: 0.5193 - val_loss: 1.7625\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9227 - loss: 0.2068 - val_accuracy: 0.7415 - val_loss: 0.6005\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9191 - loss: 0.2101 - val_accuracy: 0.7850 - val_loss: 0.6476\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9396 - loss: 0.1602 - val_accuracy: 0.7464 - val_loss: 1.1909\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9529 - loss: 0.1504 - val_accuracy: 0.7669 - val_loss: 0.6252\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9457 - loss: 0.1331 - val_accuracy: 0.7295 - val_loss: 0.7513\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - accuracy: 0.9517 - loss: 0.1358 - val_accuracy: 0.8237 - val_loss: 0.6373\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9553 - loss: 0.1260 - val_accuracy: 0.7705 - val_loss: 0.9266\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9614 - loss: 0.1061 - val_accuracy: 0.6534 - val_loss: 2.5948\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.9771 - loss: 0.0702 - val_accuracy: 0.7500 - val_loss: 1.5033\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9734 - loss: 0.0755 - val_accuracy: 0.8237 - val_loss: 0.7683\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9698 - loss: 0.0679 - val_accuracy: 0.7114 - val_loss: 1.6563\n",
      "\n",
      "Accuracy: 71.14%\n",
      "\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 248.8071\n",
      "Function value obtained: -0.7114\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 137\n",
      "dropout: 0.1\n",
      "optimizer_type: SGD\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 851ms/step - accuracy: 0.7886 - loss: 0.4792 - val_accuracy: 0.6473 - val_loss: 0.6335\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8490 - loss: 0.3359 - val_accuracy: 0.7645 - val_loss: 0.5536\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8865 - loss: 0.2678 - val_accuracy: 0.8575 - val_loss: 0.3229\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8986 - loss: 0.2505 - val_accuracy: 0.8659 - val_loss: 0.4439\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9275 - loss: 0.1912 - val_accuracy: 0.8382 - val_loss: 0.4250\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9336 - loss: 0.1993 - val_accuracy: 0.7041 - val_loss: 0.7047\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9650 - loss: 0.1036 - val_accuracy: 0.8285 - val_loss: 0.4218\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9614 - loss: 0.1327 - val_accuracy: 0.8357 - val_loss: 0.6233\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9698 - loss: 0.0845 - val_accuracy: 0.7440 - val_loss: 0.7544\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9795 - loss: 0.0603 - val_accuracy: 0.7597 - val_loss: 0.8039\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.9686 - loss: 0.0938 - val_accuracy: 0.8551 - val_loss: 0.6070\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 165ms/step - accuracy: 0.9686 - loss: 0.0744 - val_accuracy: 0.8502 - val_loss: 0.7301\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9855 - loss: 0.0592 - val_accuracy: 0.8056 - val_loss: 0.7061\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9807 - loss: 0.0548 - val_accuracy: 0.8309 - val_loss: 0.9958\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9903 - loss: 0.0394 - val_accuracy: 0.8333 - val_loss: 0.9930\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9783 - loss: 0.0965 - val_accuracy: 0.8019 - val_loss: 0.4554\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9807 - loss: 0.0553 - val_accuracy: 0.7367 - val_loss: 0.8016\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9867 - loss: 0.0442 - val_accuracy: 0.8647 - val_loss: 0.5110\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9940 - loss: 0.0207 - val_accuracy: 0.8647 - val_loss: 0.4613\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9988 - loss: 0.0096 - val_accuracy: 0.8527 - val_loss: 0.6387\n",
      "\n",
      "Accuracy: 85.27%\n",
      "\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 248.0008\n",
      "Function value obtained: -0.8527\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "learning rate: 2.2e-05\n",
      "num_dense_nodes: 193\n",
      "dropout: 0.3890895357315216\n",
      "optimizer_type: Adam\n",
      "epochs: 8\n",
      "Epoch 1/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 977ms/step - accuracy: 0.6775 - loss: 0.6040 - val_accuracy: 0.5725 - val_loss: 0.6864\n",
      "Epoch 2/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.8225 - loss: 0.3818 - val_accuracy: 0.7246 - val_loss: 0.5709\n",
      "Epoch 3/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8696 - loss: 0.3315 - val_accuracy: 0.7693 - val_loss: 0.5339\n",
      "Epoch 4/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9010 - loss: 0.2297 - val_accuracy: 0.8128 - val_loss: 0.4399\n",
      "Epoch 5/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.9215 - loss: 0.1834 - val_accuracy: 0.8345 - val_loss: 0.3945\n",
      "Epoch 6/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9505 - loss: 0.1368 - val_accuracy: 0.8418 - val_loss: 0.3767\n",
      "Epoch 7/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9674 - loss: 0.1016 - val_accuracy: 0.8478 - val_loss: 0.3599\n",
      "Epoch 8/8\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9855 - loss: 0.0685 - val_accuracy: 0.8539 - val_loss: 0.3574\n",
      "\n",
      "Accuracy: 85.39%\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 182.8424\n",
      "Function value obtained: -0.8539\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "learning rate: 4.3e-05\n",
      "num_dense_nodes: 50\n",
      "dropout: 0.8\n",
      "optimizer_type: Adam\n",
      "epochs: 20\n",
      "Epoch 1/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 971ms/step - accuracy: 0.4915 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 272.7097\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 133\n",
      "dropout: 0.8\n",
      "optimizer_type: SGD\n",
      "epochs: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 860ms/step - accuracy: 0.7017 - loss: 0.6076 - val_accuracy: 0.5000 - val_loss: 121.4468\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.6896 - loss: 0.7298 - val_accuracy: 0.5000 - val_loss: 32.8925\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5556 - loss: 0.7693 - val_accuracy: 0.5000 - val_loss: 6554.5356\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.5882 - loss: 0.6603 - val_accuracy: 0.4686 - val_loss: 72.0430\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 165ms/step - accuracy: 0.6703 - loss: 0.5929 - val_accuracy: 0.5423 - val_loss: 13.0662\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7017 - loss: 0.6069 - val_accuracy: 0.5169 - val_loss: 1.1814\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7114 - loss: 0.6018 - val_accuracy: 0.5012 - val_loss: 0.8271\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7150 - loss: 0.5873 - val_accuracy: 0.5978 - val_loss: 2.7030\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7452 - loss: 0.5278 - val_accuracy: 0.5121 - val_loss: 14.3156\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7101 - loss: 0.5517 - val_accuracy: 0.6147 - val_loss: 1.3309\n",
      "\n",
      "Accuracy: 61.47%\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 170.7510\n",
      "Function value obtained: -0.6147\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "learning rate: 1.3e-05\n",
      "num_dense_nodes: 198\n",
      "dropout: 0.1\n",
      "optimizer_type: Adam\n",
      "epochs: 13\n",
      "Epoch 1/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 1s/step - accuracy: 0.7138 - loss: 0.5820 - val_accuracy: 0.5785 - val_loss: 0.6725\n",
      "Epoch 2/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8502 - loss: 0.4075 - val_accuracy: 0.6920 - val_loss: 0.5628\n",
      "Epoch 3/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.8647 - loss: 0.3273 - val_accuracy: 0.7850 - val_loss: 0.4604\n",
      "Epoch 4/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9094 - loss: 0.2500 - val_accuracy: 0.8261 - val_loss: 0.3961\n",
      "Epoch 5/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9058 - loss: 0.2259 - val_accuracy: 0.8237 - val_loss: 0.3845\n",
      "Epoch 6/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9481 - loss: 0.1577 - val_accuracy: 0.8442 - val_loss: 0.3599\n",
      "Epoch 7/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9807 - loss: 0.1166 - val_accuracy: 0.8478 - val_loss: 0.3708\n",
      "Epoch 8/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9795 - loss: 0.0933 - val_accuracy: 0.8514 - val_loss: 0.3729\n",
      "Epoch 9/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9819 - loss: 0.0703 - val_accuracy: 0.8563 - val_loss: 0.3734\n",
      "Epoch 10/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9867 - loss: 0.0517 - val_accuracy: 0.8587 - val_loss: 0.3836\n",
      "Epoch 11/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9928 - loss: 0.0387 - val_accuracy: 0.8527 - val_loss: 0.4032\n",
      "Epoch 12/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.9831 - loss: 0.0510 - val_accuracy: 0.8539 - val_loss: 0.3990\n",
      "Epoch 13/13\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.9795 - loss: 0.0570 - val_accuracy: 0.8611 - val_loss: 0.3999\n",
      "\n",
      "Accuracy: 86.11%\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 226.6839\n",
      "Function value obtained: -0.8611\n",
      "Current minimum: -0.8635\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "learning rate: 1.0e-02\n",
      "num_dense_nodes: 107\n",
      "dropout: 0.17242430950687537\n",
      "optimizer_type: SGD\n",
      "epochs: 17\n",
      "Epoch 1/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 867ms/step - accuracy: 0.7560 - loss: 0.4708 - val_accuracy: 0.5242 - val_loss: 1.7218\n",
      "Epoch 2/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.8309 - loss: 0.3762 - val_accuracy: 0.6981 - val_loss: 0.6232\n",
      "Epoch 3/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.8635 - loss: 0.3231 - val_accuracy: 0.8357 - val_loss: 0.3511\n",
      "Epoch 4/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9094 - loss: 0.2078 - val_accuracy: 0.6667 - val_loss: 1.2356\n",
      "Epoch 5/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.9082 - loss: 0.2242 - val_accuracy: 0.8285 - val_loss: 0.4630\n",
      "Epoch 6/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - accuracy: 0.9481 - loss: 0.1415 - val_accuracy: 0.8406 - val_loss: 0.4762\n",
      "Epoch 7/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9614 - loss: 0.1161 - val_accuracy: 0.8551 - val_loss: 0.5689\n",
      "Epoch 8/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9505 - loss: 0.1399 - val_accuracy: 0.8176 - val_loss: 0.5264\n",
      "Epoch 9/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9529 - loss: 0.1278 - val_accuracy: 0.8309 - val_loss: 0.5433\n",
      "Epoch 10/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9758 - loss: 0.1034 - val_accuracy: 0.7234 - val_loss: 0.8451\n",
      "Epoch 11/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9722 - loss: 0.0881 - val_accuracy: 0.8563 - val_loss: 0.4536\n",
      "Epoch 12/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.9819 - loss: 0.0511 - val_accuracy: 0.8164 - val_loss: 0.5462\n",
      "Epoch 13/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9903 - loss: 0.0262 - val_accuracy: 0.8551 - val_loss: 1.1297\n",
      "Epoch 14/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9903 - loss: 0.0406 - val_accuracy: 0.8309 - val_loss: 0.6347\n",
      "Epoch 15/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9746 - loss: 0.0856 - val_accuracy: 0.7911 - val_loss: 0.5960\n",
      "Epoch 16/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9903 - loss: 0.0372 - val_accuracy: 0.7935 - val_loss: 0.7276\n",
      "Epoch 17/17\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9964 - loss: 0.0164 - val_accuracy: 0.8309 - val_loss: 0.6282\n",
      "\n",
      "Accuracy: 83.09%\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 227.5980\n",
      "Function value obtained: -0.8309\n",
      "Current minimum: -0.8635\n",
      "Seed:  13\n",
      "BEST ACCURACY:  {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.8635265827178955, 14: 0.0}\n",
      "hyper_params  [6.662778440610853e-05, 0.1228780655287722, 0.9196296522257404, 0.9378436151274099, 0.9943673789033859, np.int64(13), np.int64(173), 'Adam']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on seed 0 for this cell\n",
    "\n",
    "seed = 13\n",
    "\n",
    "print('We are currently training on seed:', seed) \n",
    "# for each iteration of the hyperparameter search, return a set of parameters\n",
    "# and feed them into the relevant parts\n",
    "# run training of the model for this seed, save with seed num\n",
    "X_train = np.load(f'paper_reading_small_data/trial_{seed}_X_train.npy', allow_pickle=True)\n",
    "y_train = np.load(f'paper_reading_small_data/trial_{seed}_y_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'paper_reading_small_data/trial_{seed}_X_test.npy', allow_pickle=True)\n",
    "y_test = np.load(f'paper_reading_small_data/trial_{seed}_y_test.npy', allow_pickle=True)\n",
    "\n",
    "path_best_model = 'inception_saved_trial_{}.keras'.format(seed)\n",
    "  \n",
    "@use_named_args(dimensions=space)\n",
    "def fitness(learning_rate, dropout, momentum, beta_1, beta_2,\n",
    "              num_dense_nodes, optimizer_type, epochs):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('dropout:', dropout)\n",
    "    print('optimizer_type:', optimizer_type)\n",
    "    print('epochs:', epochs)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_a_model(learning_rate=learning_rate, \n",
    "                         dropout=dropout, \n",
    "                         momentum=momentum, \n",
    "                         beta_1=beta_1, beta_2=beta_2,\n",
    "                         num_dense_nodes=num_dense_nodes, \n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data= (X_test,y_test))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    # auc_val = history.history['val_auc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy[seed]:\n",
    "      # Save the new model to harddisk in the recommended Keras format\n",
    "      model_path = os.path.join('DataSplitted', path_best_model)\n",
    "      model.save(model_path)\n",
    "    \n",
    "\n",
    "      # Update the classification accuracy.\n",
    "      best_accuracy[seed] = accuracy\n",
    "      # best_auc = auc_val\n",
    "          \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    import gc\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "      tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except:\n",
    "      pass  # in case older TF version\n",
    "    return -accuracy\n",
    "\n",
    "  \n",
    "#This conducts the hyperparameter search over each data split for details see: https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=space,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15,\n",
    "\t\t\t    n_random_starts = 5,\n",
    "                            verbose = True)\n",
    "print('Seed: ',seed)\n",
    "print(\"BEST ACCURACY: \", best_accuracy)\n",
    "print('hyper_params ', search_result.x)\n",
    "\n",
    "del X_train, y_train, X_test, y_test \n",
    "\n",
    "import gc\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GradCAM and Kernel SHAP Experiments\n",
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# Library with the methods that I needed\n",
    "import gradcam_shap\n",
    "import scipy\n",
    "\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756597615.023909   13998 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "os.chdir('DataSplitted')\n",
    "seed = 13\n",
    "model = load_model(f'inception_saved_trial_{seed}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Activation name=activation, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Activation name=activation_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Activation name=activation_2, built=True>, <MaxPooling2D name=max_pooling2d, built=True>, <Conv2D name=conv2d_3, built=True>, <BatchNormalization name=batch_normalization_3, built=True>, <Activation name=activation_3, built=True>, <Conv2D name=conv2d_4, built=True>, <BatchNormalization name=batch_normalization_4, built=True>, <Activation name=activation_4, built=True>, <MaxPooling2D name=max_pooling2d_1, built=True>, <Conv2D name=conv2d_8, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Activation name=activation_8, built=True>, <Conv2D name=conv2d_6, built=True>, <Conv2D name=conv2d_9, built=True>, <BatchNormalization name=batch_normalization_6, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Activation name=activation_6, built=True>, <Activation name=activation_9, built=True>, <AveragePooling2D name=average_pooling2d, built=True>, <Conv2D name=conv2d_5, built=True>, <Conv2D name=conv2d_7, built=True>, <Conv2D name=conv2d_10, built=True>, <Conv2D name=conv2d_11, built=True>, <BatchNormalization name=batch_normalization_5, built=True>, <BatchNormalization name=batch_normalization_7, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Activation name=activation_5, built=True>, <Activation name=activation_7, built=True>, <Activation name=activation_10, built=True>, <Activation name=activation_11, built=True>, <Concatenate name=mixed0, built=True>, <Conv2D name=conv2d_15, built=True>, <BatchNormalization name=batch_normalization_15, built=True>, <Activation name=activation_15, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_16, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <BatchNormalization name=batch_normalization_16, built=True>, <Activation name=activation_13, built=True>, <Activation name=activation_16, built=True>, <AveragePooling2D name=average_pooling2d_1, built=True>, <Conv2D name=conv2d_12, built=True>, <Conv2D name=conv2d_14, built=True>, <Conv2D name=conv2d_17, built=True>, <Conv2D name=conv2d_18, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <BatchNormalization name=batch_normalization_14, built=True>, <BatchNormalization name=batch_normalization_17, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Activation name=activation_12, built=True>, <Activation name=activation_14, built=True>, <Activation name=activation_17, built=True>, <Activation name=activation_18, built=True>, <Concatenate name=mixed1, built=True>, <Conv2D name=conv2d_22, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Activation name=activation_22, built=True>, <Conv2D name=conv2d_20, built=True>, <Conv2D name=conv2d_23, built=True>, <BatchNormalization name=batch_normalization_20, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Activation name=activation_20, built=True>, <Activation name=activation_23, built=True>, <AveragePooling2D name=average_pooling2d_2, built=True>, <Conv2D name=conv2d_19, built=True>, <Conv2D name=conv2d_21, built=True>, <Conv2D name=conv2d_24, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <BatchNormalization name=batch_normalization_21, built=True>, <BatchNormalization name=batch_normalization_24, built=True>, <BatchNormalization name=batch_normalization_25, built=True>, <Activation name=activation_19, built=True>, <Activation name=activation_21, built=True>, <Activation name=activation_24, built=True>, <Activation name=activation_25, built=True>, <Concatenate name=mixed2, built=True>, <Conv2D name=conv2d_27, built=True>, <BatchNormalization name=batch_normalization_27, built=True>, <Activation name=activation_27, built=True>, <Conv2D name=conv2d_28, built=True>, <BatchNormalization name=batch_normalization_28, built=True>, <Activation name=activation_28, built=True>, <Conv2D name=conv2d_26, built=True>, <Conv2D name=conv2d_29, built=True>, <BatchNormalization name=batch_normalization_26, built=True>, <BatchNormalization name=batch_normalization_29, built=True>, <Activation name=activation_26, built=True>, <Activation name=activation_29, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Concatenate name=mixed3, built=True>, <Conv2D name=conv2d_34, built=True>, <BatchNormalization name=batch_normalization_34, built=True>, <Activation name=activation_34, built=True>, <Conv2D name=conv2d_35, built=True>, <BatchNormalization name=batch_normalization_35, built=True>, <Activation name=activation_35, built=True>, <Conv2D name=conv2d_31, built=True>, <Conv2D name=conv2d_36, built=True>, <BatchNormalization name=batch_normalization_31, built=True>, <BatchNormalization name=batch_normalization_36, built=True>, <Activation name=activation_31, built=True>, <Activation name=activation_36, built=True>, <Conv2D name=conv2d_32, built=True>, <Conv2D name=conv2d_37, built=True>, <BatchNormalization name=batch_normalization_32, built=True>, <BatchNormalization name=batch_normalization_37, built=True>, <Activation name=activation_32, built=True>, <Activation name=activation_37, built=True>, <AveragePooling2D name=average_pooling2d_3, built=True>, <Conv2D name=conv2d_30, built=True>, <Conv2D name=conv2d_33, built=True>, <Conv2D name=conv2d_38, built=True>, <Conv2D name=conv2d_39, built=True>, <BatchNormalization name=batch_normalization_30, built=True>, <BatchNormalization name=batch_normalization_33, built=True>, <BatchNormalization name=batch_normalization_38, built=True>, <BatchNormalization name=batch_normalization_39, built=True>, <Activation name=activation_30, built=True>, <Activation name=activation_33, built=True>, <Activation name=activation_38, built=True>, <Activation name=activation_39, built=True>, <Concatenate name=mixed4, built=True>, <Conv2D name=conv2d_44, built=True>, <BatchNormalization name=batch_normalization_44, built=True>, <Activation name=activation_44, built=True>, <Conv2D name=conv2d_45, built=True>, <BatchNormalization name=batch_normalization_45, built=True>, <Activation name=activation_45, built=True>, <Conv2D name=conv2d_41, built=True>, <Conv2D name=conv2d_46, built=True>, <BatchNormalization name=batch_normalization_41, built=True>, <BatchNormalization name=batch_normalization_46, built=True>, <Activation name=activation_41, built=True>, <Activation name=activation_46, built=True>, <Conv2D name=conv2d_42, built=True>, <Conv2D name=conv2d_47, built=True>, <BatchNormalization name=batch_normalization_42, built=True>, <BatchNormalization name=batch_normalization_47, built=True>, <Activation name=activation_42, built=True>, <Activation name=activation_47, built=True>, <AveragePooling2D name=average_pooling2d_4, built=True>, <Conv2D name=conv2d_40, built=True>, <Conv2D name=conv2d_43, built=True>, <Conv2D name=conv2d_48, built=True>, <Conv2D name=conv2d_49, built=True>, <BatchNormalization name=batch_normalization_40, built=True>, <BatchNormalization name=batch_normalization_43, built=True>, <BatchNormalization name=batch_normalization_48, built=True>, <BatchNormalization name=batch_normalization_49, built=True>, <Activation name=activation_40, built=True>, <Activation name=activation_43, built=True>, <Activation name=activation_48, built=True>, <Activation name=activation_49, built=True>, <Concatenate name=mixed5, built=True>, <Conv2D name=conv2d_54, built=True>, <BatchNormalization name=batch_normalization_54, built=True>, <Activation name=activation_54, built=True>, <Conv2D name=conv2d_55, built=True>, <BatchNormalization name=batch_normalization_55, built=True>, <Activation name=activation_55, built=True>, <Conv2D name=conv2d_51, built=True>, <Conv2D name=conv2d_56, built=True>, <BatchNormalization name=batch_normalization_51, built=True>, <BatchNormalization name=batch_normalization_56, built=True>, <Activation name=activation_51, built=True>, <Activation name=activation_56, built=True>, <Conv2D name=conv2d_52, built=True>, <Conv2D name=conv2d_57, built=True>, <BatchNormalization name=batch_normalization_52, built=True>, <BatchNormalization name=batch_normalization_57, built=True>, <Activation name=activation_52, built=True>, <Activation name=activation_57, built=True>, <AveragePooling2D name=average_pooling2d_5, built=True>, <Conv2D name=conv2d_50, built=True>, <Conv2D name=conv2d_53, built=True>, <Conv2D name=conv2d_58, built=True>, <Conv2D name=conv2d_59, built=True>, <BatchNormalization name=batch_normalization_50, built=True>, <BatchNormalization name=batch_normalization_53, built=True>, <BatchNormalization name=batch_normalization_58, built=True>, <BatchNormalization name=batch_normalization_59, built=True>, <Activation name=activation_50, built=True>, <Activation name=activation_53, built=True>, <Activation name=activation_58, built=True>, <Activation name=activation_59, built=True>, <Concatenate name=mixed6, built=True>, <Conv2D name=conv2d_64, built=True>, <BatchNormalization name=batch_normalization_64, built=True>, <Activation name=activation_64, built=True>, <Conv2D name=conv2d_65, built=True>, <BatchNormalization name=batch_normalization_65, built=True>, <Activation name=activation_65, built=True>, <Conv2D name=conv2d_61, built=True>, <Conv2D name=conv2d_66, built=True>, <BatchNormalization name=batch_normalization_61, built=True>, <BatchNormalization name=batch_normalization_66, built=True>, <Activation name=activation_61, built=True>, <Activation name=activation_66, built=True>, <Conv2D name=conv2d_62, built=True>, <Conv2D name=conv2d_67, built=True>, <BatchNormalization name=batch_normalization_62, built=True>, <BatchNormalization name=batch_normalization_67, built=True>, <Activation name=activation_62, built=True>, <Activation name=activation_67, built=True>, <AveragePooling2D name=average_pooling2d_6, built=True>, <Conv2D name=conv2d_60, built=True>, <Conv2D name=conv2d_63, built=True>, <Conv2D name=conv2d_68, built=True>, <Conv2D name=conv2d_69, built=True>, <BatchNormalization name=batch_normalization_60, built=True>, <BatchNormalization name=batch_normalization_63, built=True>, <BatchNormalization name=batch_normalization_68, built=True>, <BatchNormalization name=batch_normalization_69, built=True>, <Activation name=activation_60, built=True>, <Activation name=activation_63, built=True>, <Activation name=activation_68, built=True>, <Activation name=activation_69, built=True>, <Concatenate name=mixed7, built=True>, <Conv2D name=conv2d_72, built=True>, <BatchNormalization name=batch_normalization_72, built=True>, <Activation name=activation_72, built=True>, <Conv2D name=conv2d_73, built=True>, <BatchNormalization name=batch_normalization_73, built=True>, <Activation name=activation_73, built=True>, <Conv2D name=conv2d_70, built=True>, <Conv2D name=conv2d_74, built=True>, <BatchNormalization name=batch_normalization_70, built=True>, <BatchNormalization name=batch_normalization_74, built=True>, <Activation name=activation_70, built=True>, <Activation name=activation_74, built=True>, <Conv2D name=conv2d_71, built=True>, <Conv2D name=conv2d_75, built=True>, <BatchNormalization name=batch_normalization_71, built=True>, <BatchNormalization name=batch_normalization_75, built=True>, <Activation name=activation_71, built=True>, <Activation name=activation_75, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Concatenate name=mixed8, built=True>, <Conv2D name=conv2d_80, built=True>, <BatchNormalization name=batch_normalization_80, built=True>, <Activation name=activation_80, built=True>, <Conv2D name=conv2d_77, built=True>, <Conv2D name=conv2d_81, built=True>, <BatchNormalization name=batch_normalization_77, built=True>, <BatchNormalization name=batch_normalization_81, built=True>, <Activation name=activation_77, built=True>, <Activation name=activation_81, built=True>, <Conv2D name=conv2d_78, built=True>, <Conv2D name=conv2d_79, built=True>, <Conv2D name=conv2d_82, built=True>, <Conv2D name=conv2d_83, built=True>, <AveragePooling2D name=average_pooling2d_7, built=True>, <Conv2D name=conv2d_76, built=True>, <BatchNormalization name=batch_normalization_78, built=True>, <BatchNormalization name=batch_normalization_79, built=True>, <BatchNormalization name=batch_normalization_82, built=True>, <BatchNormalization name=batch_normalization_83, built=True>, <Conv2D name=conv2d_84, built=True>, <BatchNormalization name=batch_normalization_76, built=True>, <Activation name=activation_78, built=True>, <Activation name=activation_79, built=True>, <Activation name=activation_82, built=True>, <Activation name=activation_83, built=True>, <BatchNormalization name=batch_normalization_84, built=True>, <Activation name=activation_76, built=True>, <Concatenate name=mixed9_0, built=True>, <Concatenate name=concatenate, built=True>, <Activation name=activation_84, built=True>, <Concatenate name=mixed9, built=True>, <Conv2D name=conv2d_89, built=True>, <BatchNormalization name=batch_normalization_89, built=True>, <Activation name=activation_89, built=True>, <Conv2D name=conv2d_86, built=True>, <Conv2D name=conv2d_90, built=True>, <BatchNormalization name=batch_normalization_86, built=True>, <BatchNormalization name=batch_normalization_90, built=True>, <Activation name=activation_86, built=True>, <Activation name=activation_90, built=True>, <Conv2D name=conv2d_87, built=True>, <Conv2D name=conv2d_88, built=True>, <Conv2D name=conv2d_91, built=True>, <Conv2D name=conv2d_92, built=True>, <AveragePooling2D name=average_pooling2d_8, built=True>, <Conv2D name=conv2d_85, built=True>, <BatchNormalization name=batch_normalization_87, built=True>, <BatchNormalization name=batch_normalization_88, built=True>, <BatchNormalization name=batch_normalization_91, built=True>, <BatchNormalization name=batch_normalization_92, built=True>, <Conv2D name=conv2d_93, built=True>, <BatchNormalization name=batch_normalization_85, built=True>, <Activation name=activation_87, built=True>, <Activation name=activation_88, built=True>, <Activation name=activation_91, built=True>, <Activation name=activation_92, built=True>, <BatchNormalization name=batch_normalization_93, built=True>, <Activation name=activation_85, built=True>, <Concatenate name=mixed9_1, built=True>, <Concatenate name=concatenate_1, built=True>, <Activation name=activation_93, built=True>, <Concatenate name=mixed10, built=True>, <GlobalAveragePooling2D name=global_average_pooling2d, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "from vis.utils import utils\n",
    "from keras import layers, activations\n",
    "\n",
    "#Assorted modifications for model compatibility with gradCAM\n",
    "gmodel = copy.deepcopy(model)\n",
    "\n",
    "print(gmodel.layers)\n",
    "\n",
    "layer_idx = utils.find_layer_idx(gmodel,'dense_1')\n",
    "\n",
    "#swap with softmax with linear classifier for the reasons mentioned above\n",
    "gmodel.layers[layer_idx].activation = activations.linear\n",
    "gmodel = utils.apply_modifications(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('paper-reading-analysis')\n",
    "%run gradcam_shap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756597637.753436   14592 service.cc:152] XLA service 0x7f13b4003530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756597637.753465   14592 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-08-30 23:47:17.870730: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756597639.000240   14592 cuda_dnn.cc:529] Loaded cuDNN version 91200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/13\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756597645.028540   14592 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 745ms/step\n",
      "[[np.float32(0.967342), np.float32(0.03265798)], [np.float32(0.9085426), np.float32(0.09145743)], [np.float32(0.99983835), np.float32(0.0001616478)], [np.float32(0.99811137), np.float32(0.0018886328)], [np.float32(0.9889803), np.float32(0.011019707)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99940956), np.float32(0.0005904436)], [np.float32(0.9999851), np.float32(1.4901161e-05)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.8355498), np.float32(0.16445023)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.99963045), np.float32(0.0003695488)], [np.float32(0.9999969), np.float32(3.0994415e-06)], [np.float32(0.9970835), np.float32(0.0029165149)], [np.float32(0.89792293), np.float32(0.10207707)], [np.float32(0.38728955), np.float32(0.6127105)], [np.float32(0.9998212), np.float32(0.00017881393)], [np.float32(0.99833894), np.float32(0.0016610622)], [np.float32(0.9998795), np.float32(0.00012052059)], [np.float32(0.5091615), np.float32(0.49083853)], [np.float32(0.97766405), np.float32(0.022335947)], [np.float32(0.0395727), np.float32(0.9604273)], [np.float32(0.9988362), np.float32(0.0011637807)], [np.float32(1.1291911e-06), np.float32(0.99999887)], [np.float32(0.99597657), np.float32(0.0040234327)], [np.float32(0.7930981), np.float32(0.20690191)], [np.float32(0.8724637), np.float32(0.1275363)], [np.float32(0.99918574), np.float32(0.00081425905)], [np.float32(0.48044237), np.float32(0.5195576)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9057786), np.float32(0.09422141)], [np.float32(0.9999802), np.float32(1.9788742e-05)], [np.float32(0.988193), np.float32(0.0118070245)], [np.float32(0.94566774), np.float32(0.054332256)], [np.float32(5.5781634e-06), np.float32(0.9999944)], [np.float32(0.9988676), np.float32(0.0011324286)], [np.float32(0.99487877), np.float32(0.005121231)], [np.float32(0.99933845), np.float32(0.00066155195)], [np.float32(0.542051), np.float32(0.45794898)], [np.float32(0.977164), np.float32(0.02283603)], [np.float32(0.9999956), np.float32(4.4107437e-06)], [np.float32(0.9991947), np.float32(0.00080531836)], [np.float32(0.9999932), np.float32(6.7949295e-06)], [np.float32(0.056438398), np.float32(0.9435616)], [np.float32(0.9990195), np.float32(0.0009804964)], [np.float32(0.9960746), np.float32(0.003925383)], [np.float32(0.9998256), np.float32(0.00017440319)], [np.float32(0.13973357), np.float32(0.86026645)], [np.float32(0.9989507), np.float32(0.0010492802)], [np.float32(0.9886114), np.float32(0.0113886)], [np.float32(0.99996173), np.float32(3.8266182e-05)], [np.float32(0.0007507485), np.float32(0.9992493)], [np.float32(0.99999344), np.float32(6.556511e-06)], [np.float32(0.8623105), np.float32(0.13768947)], [np.float32(0.9746499), np.float32(0.025350094)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9999037), np.float32(9.6321106e-05)], [np.float32(0.00022179291), np.float32(0.9997782)], [np.float32(0.9737422), np.float32(0.026257813)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.20417672), np.float32(0.7958233)], [np.float32(0.7162717), np.float32(0.2837283)], [np.float32(0.17953199), np.float32(0.820468)], [np.float32(0.9477289), np.float32(0.052271128)], [np.float32(0.9998325), np.float32(0.00016748905)], [np.float32(0.9999571), np.float32(4.2915344e-05)], [np.float32(0.9991942), np.float32(0.0008057952)], [np.float32(4.410033e-06), np.float32(0.9999956)], [np.float32(0.43535924), np.float32(0.56464076)], [np.float32(0.038000554), np.float32(0.9619994)], [np.float32(0.9967631), np.float32(0.0032368898)], [np.float32(0.991803), np.float32(0.00819701)], [np.float32(0.99985385), np.float32(0.00014615059)], [np.float32(0.9999989), np.float32(1.0728836e-06)], [np.float32(0.9989274), np.float32(0.0010725856)], [np.float32(0.9979515), np.float32(0.0020484924)], [np.float32(0.99443096), np.float32(0.005569041)], [np.float32(0.20118615), np.float32(0.7988138)], [np.float32(0.9997646), np.float32(0.00023537874)], [np.float32(0.9998903), np.float32(0.00010967255)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.2340304), np.float32(0.76596963)], [np.float32(0.74801034), np.float32(0.25198966)], [np.float32(0.99932617), np.float32(0.0006738305)], [np.float32(0.14074545), np.float32(0.85925454)], [np.float32(0.9999989), np.float32(1.0728836e-06)], [np.float32(0.9999491), np.float32(5.0902367e-05)], [np.float32(0.9999856), np.float32(1.4424324e-05)], [np.float32(0.99974006), np.float32(0.00025993586)], [np.float32(0.98623115), np.float32(0.013768852)], [np.float32(0.87615496), np.float32(0.12384504)], [np.float32(0.007916521), np.float32(0.9920835)], [np.float32(0.9998989), np.float32(0.00010108948)], [np.float32(0.90559435), np.float32(0.09440565)], [np.float32(0.9999608), np.float32(3.9219856e-05)], [np.float32(0.46949142), np.float32(0.5305086)], [np.float32(0.99965537), np.float32(0.00034463406)], [np.float32(0.9999924), np.float32(7.6293945e-06)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.97259367), np.float32(0.027406335)], [np.float32(0.9930942), np.float32(0.006905794)], [np.float32(0.9695449), np.float32(0.030455112)], [np.float32(0.99999607), np.float32(3.9339066e-06)], [np.float32(0.99712783), np.float32(0.002872169)], [np.float32(0.99414307), np.float32(0.005856931)], [np.float32(0.9999988), np.float32(1.1920929e-06)], [np.float32(0.99992), np.float32(7.998943e-05)], [np.float32(0.87611073), np.float32(0.12388927)], [np.float32(0.99999964), np.float32(3.5762787e-07)], [np.float32(0.78924865), np.float32(0.21075135)], [np.float32(0.7266054), np.float32(0.27339458)], [np.float32(0.75202316), np.float32(0.24797684)], [np.float32(0.9935219), np.float32(0.006478071)], [np.float32(0.9969036), np.float32(0.0030964017)], [np.float32(0.99683124), np.float32(0.0031687617)], [np.float32(0.9995565), np.float32(0.00044351816)], [np.float32(0.0069035897), np.float32(0.9930964)], [np.float32(0.07773244), np.float32(0.92226756)], [np.float32(0.97283214), np.float32(0.027167857)], [np.float32(0.9999088), np.float32(9.119511e-05)], [np.float32(0.9386209), np.float32(0.061379075)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.998968), np.float32(0.0010319948)], [np.float32(0.9096734), np.float32(0.09032661)], [np.float32(0.9999846), np.float32(1.5377998e-05)], [np.float32(0.14901313), np.float32(0.85098684)], [np.float32(0.99998987), np.float32(1.013279e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9977615), np.float32(0.002238512)], [np.float32(0.012199257), np.float32(0.9878007)], [np.float32(0.99991345), np.float32(8.6545944e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9987256), np.float32(0.0012744069)], [np.float32(0.99995303), np.float32(4.696846e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.94841725), np.float32(0.051582754)], [np.float32(0.9990206), np.float32(0.0009794235)], [np.float32(0.83815205), np.float32(0.16184795)], [np.float32(0.3408332), np.float32(0.6591668)], [np.float32(0.9975643), np.float32(0.0024356842)], [np.float32(0.9999645), np.float32(3.552437e-05)], [np.float32(0.98691475), np.float32(0.013085246)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.98739254), np.float32(0.012607455)], [np.float32(0.998586), np.float32(0.001414001)], [np.float32(0.9983266), np.float32(0.0016734004)], [np.float32(0.9999794), np.float32(2.0623207e-05)], [np.float32(0.99999857), np.float32(1.4305115e-06)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.7482445), np.float32(0.25175548)], [np.float32(0.090374894), np.float32(0.9096251)], [np.float32(0.9938374), np.float32(0.006162584)], [np.float32(0.020588687), np.float32(0.9794113)], [np.float32(0.9958191), np.float32(0.004180908)], [np.float32(0.7675309), np.float32(0.23246908)], [np.float32(0.9995491), np.float32(0.00045090914)], [np.float32(0.80333906), np.float32(0.19666094)], [np.float32(0.9999082), np.float32(9.179115e-05)], [np.float32(1.0), np.float32(0.0)], [np.float32(0.9209084), np.float32(0.07909161)], [np.float32(0.9999032), np.float32(9.679794e-05)], [np.float32(0.9997895), np.float32(0.0002105236)], [np.float32(0.92447156), np.float32(0.07552844)], [np.float32(0.99884003), np.float32(0.001159966)], [np.float32(0.2594827), np.float32(0.74051726)], [np.float32(0.99987936), np.float32(0.0001206398)], [np.float32(0.99856216), np.float32(0.0014378428)], [np.float32(0.9728607), np.float32(0.027139306)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.9999999), np.float32(1.1920929e-07)], [np.float32(0.57323086), np.float32(0.42676914)], [np.float32(0.9374269), np.float32(0.062573075)], [np.float32(0.95524716), np.float32(0.044752836)], [np.float32(0.9997304), np.float32(0.0002695918)], [np.float32(0.9999318), np.float32(6.818771e-05)], [np.float32(0.68577564), np.float32(0.31422436)], [np.float32(0.06392385), np.float32(0.93607616)], [np.float32(0.999225), np.float32(0.0007749796)], [np.float32(0.99443305), np.float32(0.0055669546)], [np.float32(0.99996674), np.float32(3.325939e-05)], [np.float32(0.98875356), np.float32(0.011246443)], [np.float32(0.9823528), np.float32(0.017647207)], [np.float32(0.99982655), np.float32(0.00017344952)], [np.float32(0.99998987), np.float32(1.013279e-05)], [np.float32(0.002643039), np.float32(0.99735695)], [np.float32(0.9678164), np.float32(0.032183588)], [np.float32(0.92018366), np.float32(0.07981634)], [np.float32(0.9999336), np.float32(6.6399574e-05)], [np.float32(0.9996912), np.float32(0.00030881166)], [np.float32(7.1825407e-06), np.float32(0.9999928)], [np.float32(0.9999932), np.float32(6.7949295e-06)], [np.float32(0.99999547), np.float32(4.529953e-06)], [np.float32(0.9996837), np.float32(0.00031632185)], [np.float32(0.99999976), np.float32(2.3841858e-07)], [np.float32(0.96092355), np.float32(0.039076447)], [np.float32(0.99968594), np.float32(0.00031405687)], [np.float32(5.1430634e-05), np.float32(0.99994856)], [np.float32(0.95613116), np.float32(0.04386884)], [np.float32(0.9999852), np.float32(1.4781952e-05)], [np.float32(5.109576e-06), np.float32(0.9999949)], [np.float32(1.7405137e-07), np.float32(0.9999998)], [np.float32(0.005005639), np.float32(0.99499434)], [np.float32(0.00026455824), np.float32(0.9997354)], [np.float32(8.939832e-07), np.float32(0.9999991)], [np.float32(2.9833015e-12), np.float32(1.0)], [np.float32(0.5735878), np.float32(0.42641222)], [np.float32(2.0449124e-07), np.float32(0.9999998)], [np.float32(4.8875637e-09), np.float32(1.0)], [np.float32(7.3688665e-05), np.float32(0.9999263)], [np.float32(0.012441531), np.float32(0.9875585)], [np.float32(0.9997514), np.float32(0.00024861097)], [np.float32(1.8167098e-05), np.float32(0.9999818)], [np.float32(0.99998486), np.float32(1.513958e-05)], [np.float32(1.8191367e-11), np.float32(1.0)], [np.float32(0.00036038196), np.float32(0.99963963)], [np.float32(6.697632e-08), np.float32(0.99999994)], [np.float32(1.0230161e-05), np.float32(0.99998975)], [np.float32(0.0038912336), np.float32(0.9961088)], [np.float32(4.4152885e-06), np.float32(0.9999956)], [np.float32(4.0676034e-05), np.float32(0.99995935)], [np.float32(8.9667856e-11), np.float32(1.0)], [np.float32(0.37923408), np.float32(0.6207659)], [np.float32(7.1104245e-05), np.float32(0.9999289)], [np.float32(1.9209729e-06), np.float32(0.9999981)], [np.float32(0.089962654), np.float32(0.91003734)], [np.float32(0.99994254), np.float32(5.7458878e-05)], [np.float32(2.0276265e-14), np.float32(1.0)], [np.float32(0.892939), np.float32(0.10706103)], [np.float32(0.0062043844), np.float32(0.99379563)], [np.float32(0.99999404), np.float32(5.9604645e-06)], [np.float32(0.7980788), np.float32(0.20192122)], [np.float32(0.1163637), np.float32(0.8836363)], [np.float32(0.00033402944), np.float32(0.999666)], [np.float32(0.9959085), np.float32(0.0040915012)], [np.float32(8.599144e-06), np.float32(0.9999914)], [np.float32(7.076872e-13), np.float32(1.0)], [np.float32(5.1941583e-06), np.float32(0.9999948)], [np.float32(7.3669423e-13), np.float32(1.0)], [np.float32(0.013292424), np.float32(0.98670757)], [np.float32(7.376004e-06), np.float32(0.9999926)], [np.float32(0.0017867219), np.float32(0.9982133)], [np.float32(4.26709e-05), np.float32(0.9999573)], [np.float32(8.959495e-09), np.float32(1.0)], [np.float32(5.6537272e-15), np.float32(1.0)], [np.float32(0.56127775), np.float32(0.43872225)], [np.float32(2.1248236e-07), np.float32(0.99999976)], [np.float32(0.28307223), np.float32(0.71692777)], [np.float32(3.2975568e-05), np.float32(0.99996704)], [np.float32(2.452004e-08), np.float32(1.0)], [np.float32(3.131683e-05), np.float32(0.9999687)], [np.float32(3.9788294e-05), np.float32(0.9999602)], [np.float32(7.3415276e-07), np.float32(0.9999993)], [np.float32(0.0001512616), np.float32(0.9998487)], [np.float32(0.002956407), np.float32(0.9970436)], [np.float32(2.3791434e-05), np.float32(0.9999762)], [np.float32(4.6636852e-12), np.float32(1.0)], [np.float32(6.584686e-11), np.float32(1.0)], [np.float32(0.8475096), np.float32(0.15249038)], [np.float32(0.9614324), np.float32(0.038567603)], [np.float32(0.00028945104), np.float32(0.99971056)], [np.float32(0.107188545), np.float32(0.8928115)], [np.float32(1.2168846e-07), np.float32(0.9999999)], [np.float32(0.009716153), np.float32(0.99028385)], [np.float32(3.303e-06), np.float32(0.9999967)], [np.float32(6.825343e-08), np.float32(0.99999994)], [np.float32(3.3680215e-14), np.float32(1.0)], [np.float32(0.01417763), np.float32(0.9858224)], [np.float32(4.9707446e-06), np.float32(0.99999505)], [np.float32(5.076308e-11), np.float32(1.0)], [np.float32(0.99949443), np.float32(0.0005055666)], [np.float32(0.00020834703), np.float32(0.9997917)], [np.float32(7.09668e-05), np.float32(0.999929)], [np.float32(0.0001918653), np.float32(0.99980813)], [np.float32(0.00013921277), np.float32(0.99986076)], [np.float32(7.581749e-07), np.float32(0.9999992)], [np.float32(9.509361e-07), np.float32(0.99999905)], [np.float32(1.739172e-12), np.float32(1.0)], [np.float32(1.6131982e-10), np.float32(1.0)], [np.float32(1.0415255e-06), np.float32(0.999999)], [np.float32(0.019024959), np.float32(0.98097503)], [np.float32(1.1367274e-06), np.float32(0.99999887)], [np.float32(0.004003306), np.float32(0.9959967)], [np.float32(4.2476936e-06), np.float32(0.99999577)], [np.float32(5.9167805e-06), np.float32(0.9999941)], [np.float32(0.90280735), np.float32(0.097192645)], [np.float32(0.0074641355), np.float32(0.9925359)], [np.float32(1.9037366e-06), np.float32(0.9999981)], [np.float32(5.098014e-11), np.float32(1.0)], [np.float32(1.5362544e-05), np.float32(0.9999846)], [np.float32(5.5427074e-10), np.float32(1.0)], [np.float32(8.602739e-11), np.float32(1.0)], [np.float32(8.1891145e-08), np.float32(0.99999994)], [np.float32(0.00033462452), np.float32(0.9996654)], [np.float32(9.0398417e-10), np.float32(1.0)], [np.float32(0.0007049139), np.float32(0.9992951)], [np.float32(3.081965e-07), np.float32(0.9999997)], [np.float32(5.2915298e-06), np.float32(0.9999947)], [np.float32(0.00013589009), np.float32(0.9998641)], [np.float32(0.040509682), np.float32(0.9594903)], [np.float32(3.8181966e-05), np.float32(0.9999618)], [np.float32(2.9515788e-15), np.float32(1.0)], [np.float32(5.0987235e-11), np.float32(1.0)], [np.float32(3.0864394e-11), np.float32(1.0)], [np.float32(0.9976889), np.float32(0.0023111105)], [np.float32(7.114748e-11), np.float32(1.0)], [np.float32(2.6070409e-06), np.float32(0.9999974)], [np.float32(1.555327e-09), np.float32(1.0)], [np.float32(1.5588016e-07), np.float32(0.9999998)], [np.float32(0.00029313433), np.float32(0.99970686)], [np.float32(0.06451232), np.float32(0.9354877)], [np.float32(1.9846918e-06), np.float32(0.99999803)], [np.float32(3.9521136e-11), np.float32(1.0)], [np.float32(0.0014697971), np.float32(0.9985302)], [np.float32(2.3003689e-10), np.float32(1.0)], [np.float32(0.00015179142), np.float32(0.9998482)], [np.float32(0.4747977), np.float32(0.5252023)], [np.float32(7.342463e-06), np.float32(0.99999267)], [np.float32(9.476766e-06), np.float32(0.9999905)], [np.float32(1.4417261e-11), np.float32(1.0)], [np.float32(9.4887245e-09), np.float32(1.0)], [np.float32(0.024529416), np.float32(0.9754706)], [np.float32(0.0006670614), np.float32(0.99933296)], [np.float32(0.010582564), np.float32(0.98941743)], [np.float32(0.0938929), np.float32(0.90610707)], [np.float32(2.371572e-07), np.float32(0.99999976)], [np.float32(5.8576893e-07), np.float32(0.9999994)], [np.float32(6.530696e-06), np.float32(0.99999344)], [np.float32(0.00020605867), np.float32(0.99979395)], [np.float32(1.270933e-06), np.float32(0.99999875)], [np.float32(0.040628124), np.float32(0.95937186)], [np.float32(8.420551e-06), np.float32(0.9999916)], [np.float32(3.6407453e-08), np.float32(0.99999994)], [np.float32(0.00016603751), np.float32(0.99983394)], [np.float32(2.7879716e-07), np.float32(0.9999997)], [np.float32(0.000324937), np.float32(0.99967504)], [np.float32(5.9027956e-09), np.float32(1.0)], [np.float32(2.226278e-07), np.float32(0.99999976)], [np.float32(0.00015717048), np.float32(0.9998428)], [np.float32(1.6154028e-10), np.float32(1.0)], [np.float32(8.607883e-06), np.float32(0.9999914)], [np.float32(2.7303471e-07), np.float32(0.9999997)], [np.float32(0.5684731), np.float32(0.4315269)], [np.float32(1.7802206e-06), np.float32(0.9999982)], [np.float32(0.27947405), np.float32(0.720526)], [np.float32(0.0021682954), np.float32(0.9978317)], [np.float32(0.06990923), np.float32(0.9300908)], [np.float32(0.0018869989), np.float32(0.998113)], [np.float32(0.0008835744), np.float32(0.9991164)], [np.float32(0.25121552), np.float32(0.7487845)], [np.float32(0.0003484918), np.float32(0.9996515)], [np.float32(0.4402148), np.float32(0.5597852)], [np.float32(0.00036430827), np.float32(0.9996357)], [np.float32(7.6304204e-05), np.float32(0.9999237)], [np.float32(4.854624e-05), np.float32(0.9999515)], [np.float32(0.022883443), np.float32(0.9771166)], [np.float32(0.0003392979), np.float32(0.99966073)], [np.float32(7.6812096e-10), np.float32(1.0)], [np.float32(3.9898775e-11), np.float32(1.0)], [np.float32(0.93779594), np.float32(0.062204063)], [np.float32(0.40906894), np.float32(0.59093106)], [np.float32(0.0001184326), np.float32(0.99988157)], [np.float32(0.00018605095), np.float32(0.999814)], [np.float32(1.8471807e-08), np.float32(1.0)], [np.float32(0.0001825143), np.float32(0.9998175)], [np.float32(0.00014315895), np.float32(0.9998568)], [np.float32(3.8511e-10), np.float32(1.0)], [np.float32(6.591541e-09), np.float32(1.0)], [np.float32(0.8827315), np.float32(0.1172685)], [np.float32(3.4510272e-08), np.float32(0.99999994)], [np.float32(1.160442e-09), np.float32(1.0)], [np.float32(2.7919702e-06), np.float32(0.9999972)], [np.float32(0.006121351), np.float32(0.99387866)], [np.float32(7.183444e-05), np.float32(0.9999282)], [np.float32(0.00064793346), np.float32(0.99935204)], [np.float32(0.50562), np.float32(0.49438)], [np.float32(0.027040005), np.float32(0.97296)], [np.float32(0.10569949), np.float32(0.8943005)], [np.float32(1.1419788e-06), np.float32(0.99999887)], [np.float32(7.261373e-05), np.float32(0.9999274)], [np.float32(0.97118956), np.float32(0.028810441)], [np.float32(0.0008081745), np.float32(0.9991918)], [np.float32(3.3492218e-09), np.float32(1.0)], [np.float32(0.08877251), np.float32(0.91122746)], [np.float32(1.9607583e-07), np.float32(0.9999998)], [np.float32(3.2400274e-07), np.float32(0.9999997)], [np.float32(4.7365415e-08), np.float32(0.99999994)], [np.float32(5.8307392e-05), np.float32(0.9999417)], [np.float32(7.449076e-17), np.float32(1.0)], [np.float32(0.0009994397), np.float32(0.99900055)], [np.float32(5.835442e-12), np.float32(1.0)], [np.float32(0.00046957104), np.float32(0.99953043)], [np.float32(0.0005233056), np.float32(0.9994767)], [np.float32(0.03399081), np.float32(0.9660092)], [np.float32(3.349503e-09), np.float32(1.0)], [np.float32(5.7416988e-11), np.float32(1.0)], [np.float32(2.7986002e-06), np.float32(0.9999972)], [np.float32(3.385377e-05), np.float32(0.99996614)], [np.float32(0.043879036), np.float32(0.95612097)], [np.float32(1.6858523e-07), np.float32(0.9999998)]]\n",
      "Unseen set\n",
      "      ID        Dx         % Mel     % Nev\n",
      "0      0  Melanoma  9.673420e-01  0.032658\n",
      "1      1  Melanoma  9.085426e-01  0.091457\n",
      "2      2  Melanoma  9.998384e-01  0.000162\n",
      "3      3  Melanoma  9.981114e-01  0.001889\n",
      "4      4  Melanoma  9.889803e-01  0.011020\n",
      "..   ...       ...           ...       ...\n",
      "395  395     Nevus  5.741699e-11  1.000000\n",
      "396  396     Nevus  2.798600e-06  0.999997\n",
      "397  397     Nevus  3.385377e-05  0.999966\n",
      "398  398     Nevus  4.387904e-02  0.956121\n",
      "399  399     Nevus  1.685852e-07  1.000000\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_directory)\n",
    "os.chdir('DNNorDermatologist')\n",
    "\n",
    "# Get the test dataset of 400 - 200 nevi and 200 melanoma\n",
    "test_df = pd.read_pickle('NvAndMelNoDuplicatesFullSizeTestSet.zip')\n",
    "\n",
    "# Change the idx column to be '0' where the diagnosis of the lesion was\n",
    "# nevi, and '1' when the diagnosis is diagnosis\n",
    "test_df['idx'] = np.where(test_df['id'] == 'mel', 1 , 0)\n",
    "\n",
    "# Save a new table 'features' to be test_df, without the idx column\n",
    "features=test_df.drop(columns=['idx'], axis = 1)\n",
    "# Create a new table with just the correct diagnosis (0 for melanoma (or nevi), 1 for nevi (or melanoma))\n",
    "target=test_df['idx']\n",
    "\n",
    "# Change features to be a numpy array of image pixel data ((R, G, B))\n",
    "features = np.asarray(features['image'].tolist())\n",
    "\n",
    "# I want to resize the images \n",
    "features = np.array([cv2.resize(image, (224, 224)) for image in features])\n",
    "\n",
    "# Normalise this data in an alternate table to be values from 0 ... 1\n",
    "# e.g. 255 -> 1, 0 --> 0\n",
    "# Normalises for original prediction and evaluation of model, the SHAP funciton below requires non normalised data\n",
    "# TODO: Standarise this so SHAP takes normalised\n",
    "\n",
    "features2 = features / 255\n",
    "\n",
    "# Convert the data to one-hot encoding\n",
    "target_cat = to_categorical(target, num_classes = 2)\n",
    "\n",
    "# Get predictions for image data\n",
    "# e.g.\n",
    "# Index 0 : [0.9222, 0.0778]\n",
    "# Index 1 : [0.4500, 0.5500]\n",
    "# etc..\n",
    "# This represents likelihood of melanoma and nevi respectively (according to the model)\n",
    "y_pred = model.predict(features2, verbose=1)\n",
    "y_pred = [[value[0], 1-value[0]] for value in y_pred]\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Create a new dataframe with entries for each element of the test set\n",
    "# Include an ID, diagnosis, and % likelihoods for each diagnosis from the model\n",
    "df = pd.DataFrame(columns=['ID', 'Dx', '% Mel', '% Nev'],index=[i for i in range(400)])\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Create dictionaries to contain actual diagnosis and probabilities from the model\n",
    "dx_d = {}\n",
    "Pmel = {}\n",
    "Pnev = {}\n",
    "# Take the actual diagnoses from where we retrieved them earlier\n",
    "y_test_cat = target_cat\n",
    "\n",
    "# For each element in the test set:\n",
    "for ind in range(400):\n",
    "    # Append the diagnosis and predictions to their respective dictionaries\n",
    "    if y_test_cat[ind][1] == 1.0:\n",
    "        diagnosis = 'Melanoma'\n",
    "    elif y_test_cat[ind][0] == 1.0:\n",
    "        diagnosis = 'Nevus'\n",
    "    dx_d[ind] = diagnosis\n",
    "    Pmel[ind] = y_pred[ind][0]\n",
    "    Pnev[ind] = y_pred[ind][1]\n",
    "    \n",
    "# Take the above dictionaries and insert them into the data frame\n",
    "df['Dx'] = df['ID'].map(dx_d)\n",
    "df['% Mel'] = df['ID'].map(Pmel)\n",
    "df['% Nev'] = df['ID'].map(Pnev)\n",
    "\n",
    "# Change the prediction likelihoods to be floats \n",
    "df = df.astype({\"% Mel\": float, \"% Nev\": float})\n",
    "\n",
    "#df = df.iloc[id_list]\n",
    "\n",
    "# Print the first 5 entries in the data frame\n",
    "print('Unseen set') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('paper-reading-analysis')\n",
    "\n",
    "# I want examine the results, so I will just save them\n",
    "df.to_csv(f'predictions_model_{seed}.csv')\n",
    "\n",
    "print(seed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
